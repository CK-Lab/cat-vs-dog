#coding=utf-8
import os,glob,shutil
from keras.models import *
from keras.layers import *
from keras.applications import *
from keras.preprocessing.image import *
from keras.utils import plot_model
from keras.optimizers import SGD
import numpy as np
from keras.applications.resnet50 import ResNet50, preprocess_input
from keras.preprocessing import image
IMAGE_SIZE    = (256, 256)
CROP_LENGTH   = 224

def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]
def crop_generator(batches, crop_length):
    '''
    Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator
    '''
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops, batch_y)

def mklink():
    train_dir="../data/train"
    files=os.listdir(train_dir)
    train_cat=filter(lambda x:x[:3]=="cat",files)
    train_dog=filter(lambda x:x[:3]=="dog",files)
    for file in train_cat:
        #os.syslink(train_dir+"/"+file,"train2/cat/"+file)
        shutil.copyfile(train_dir+"/"+file,"../data/train2/cat/"+file)
    for file in train_dog:
        #os.syslink(train_dir+"/"+file,"train2/dog/"+file)
        shutil.copyfile(train_dir+"/"+file,"../data/train2/dog/"+file)

def simple_net():
    model=Sequential()
    model.add(Convolution2D(4,5,5,input_shape=(224,224,3)))
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Convolution2D(8,3,3))
    model.add(Activation("relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Flatten())
    model.add(Dense(128))
    model.add(Activation("relu"))
    model.add(Dropout(0.5))
    model.add(Dense(1))
    model.add(Activation("sigmoid"))
    return model

def train():
    #base_model = InceptionResNetV2(weights='imagenet', include_top=False)
    base_model = ResNet50(weights='imagenet', include_top=False)
    x = base_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(2, activation='softmax')(x)
    model = Model(inputs=base_model.input, outputs=predictions)
    #for layer in model.layers[:25]:
        #layer.trainable = False
    sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9)
    model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['accuracy'])
    #model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])
    train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input,
                                   rotation_range=40,
                                   width_shift_range=0.2,
                                   height_shift_range=0.2,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   channel_shift_range=10,
                                   horizontal_flip=True,
                                   fill_mode='nearest')  
    train_generator=train_datagen.flow_from_directory("../data/train2",target_size=(224,224),batch_size=32)
    print(train_generator.class_indices)
    model.fit_generator(train_generator,samples_per_epoch=25000,nb_epoch=100)
    #json_string = model.to_json()
    #open('model.json','w').write(json_string)
    #model.save_weights("model.h5")
    model.save("model.h5")

def evaluate():
    #model = model_from_json(open('model.json').read())
    #model.load_weights('model.h5')
    model=load_model('model.h5')
    sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9)
    model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['accuracy'])
    test_datagen=ImageDataGenerator(preprocessing_function=preprocess_input)
    validation_generator=test_datagen.flow_from_directory("../data/train2",target_size=(224,224),batch_size=50)
    score=model.evaluate_generator(validation_generator,5000)
    print(score[1])
    plot_model(model,to_file="model.png")

def test_one_image(imgpath="../data/train/cat.0.jpg"):
    net = load_model('model.h5')
    cls_list = ['cats', 'dogs']
    img=image.load_img(imgpath, target_size=(224,224))
    x = image.img_to_array(img)
    x = preprocess_input(x)
    x = np.expand_dims(x, axis=0)
    pred = net.predict(x)[0]
    top_inds = pred.argsort()[::-1][:]
    for i in top_inds:
        print('    {:.3f}  {}'.format(pred[i], cls_list[i]))

if __name__=="__main__":
    mklink()
    train()
    evaluate()
    test_one_image()