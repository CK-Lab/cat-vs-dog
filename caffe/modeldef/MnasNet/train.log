I0601 18:37:36.697553  6142 caffe.cpp:219] Using GPUs 0
I0601 18:37:36.723745  6142 caffe.cpp:224] GPU 0: GeForce GTX 980 Ti
I0601 18:37:37.075378  6142 solver.cpp:44] Initializing solver from parameters: 
train_net: "modeldef/MnasNet/train.prototxt"
test_net: "modeldef/MnasNet/test.prototxt"
test_iter: 25
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 1000
snapshot_prefix: "trainedmodels/MnasNet"
solver_mode: GPU
device_id: 0
random_seed: 831486
train_state {
  level: 0
  stage: ""
}
stepvalue: 32000
stepvalue: 48000
stepvalue: 60000
iter_size: 8
type: "Nesterov"
I0601 18:37:37.076045  6142 solver.cpp:77] Creating training net from train_net file: modeldef/MnasNet/train.prototxt
I0601 18:37:37.079419  6142 net.cpp:51] Initializing net from parameters: 
name: "MnasNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: true
    crop_size: 224
  }
  data_param {
    source: "lmdb/train_lmdb"
    batch_size: 8
    backend: LMDB
  }
  image_data_param {
    shuffle: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/sep/ReLU"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv3_1/sep1"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv3_1/sep1"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1/sep1/scale"
  type: "Scale"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep1"
  top: "conv3_1/dw"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep2"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_1/sep2/scale"
  type: "Scale"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
}
layer {
  name: "conv3_2/sep1"
  type: "Convolution"
  bottom: "conv3_1/sep2"
  top: "conv3_2/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2/sep1/scale"
  type: "Scale"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep1"
  top: "conv3_2/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep2"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep2"
  top: "conv3_2/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_2/sep2/scale"
  type: "Scale"
  bottom: "conv3_2/sep2"
  top: "conv3_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv3_1/sep2"
  bottom: "conv3_2/sep2"
  top: "conv3_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv3_2/Eltwise1"
  top: "conv3_2/Eltwise1"
}
layer {
  name: "conv3_3/sep1"
  type: "Convolution"
  bottom: "conv3_2/Eltwise1"
  top: "conv3_3/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3/sep1/scale"
  type: "Scale"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
}
layer {
  name: "conv3_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_3/sep1"
  top: "conv3_3/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3/dw/scale"
  type: "Scale"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
}
layer {
  name: "conv3_3/sep2"
  type: "Convolution"
  bottom: "conv3_3/dw"
  top: "conv3_3/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_3/sep2"
  top: "conv3_3/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv3_3/sep2/scale"
  type: "Scale"
  bottom: "conv3_3/sep2"
  top: "conv3_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv3_2/Eltwise1"
  bottom: "conv3_3/sep2"
  top: "conv3_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv3_3/Eltwise1"
  top: "conv3_3/Eltwise1"
}
layer {
  name: "conv4_1/sep1"
  type: "Convolution"
  bottom: "conv3_3/Eltwise1"
  top: "conv4_1/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1/sep1/scale"
  type: "Scale"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep1"
  top: "conv4_1/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep2"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_1/sep2/scale"
  type: "Scale"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
}
layer {
  name: "conv4_2/sep1"
  type: "Convolution"
  bottom: "conv4_1/sep2"
  top: "conv4_2/sep1"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2/sep1/scale"
  type: "Scale"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep1"
  top: "conv4_2/dw"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep2"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep2"
  top: "conv4_2/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_2/sep2/scale"
  type: "Scale"
  bottom: "conv4_2/sep2"
  top: "conv4_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv4_1/sep2"
  bottom: "conv4_2/sep2"
  top: "conv4_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv4_2/Eltwise1"
  top: "conv4_2/Eltwise1"
}
layer {
  name: "conv4_3/sep1"
  type: "Convolution"
  bottom: "conv4_2/Eltwise1"
  top: "conv4_3/sep1"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3/sep1/scale"
  type: "Scale"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
}
layer {
  name: "conv4_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_3/sep1"
  top: "conv4_3/dw"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3/dw/scale"
  type: "Scale"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
}
layer {
  name: "conv4_3/sep2"
  type: "Convolution"
  bottom: "conv4_3/dw"
  top: "conv4_3/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_3/sep2"
  top: "conv4_3/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv4_3/sep2/scale"
  type: "Scale"
  bottom: "conv4_3/sep2"
  top: "conv4_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv4_2/Eltwise1"
  bottom: "conv4_3/sep2"
  top: "conv4_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv4_3/Eltwise1"
  top: "conv4_3/Eltwise1"
}
layer {
  name: "conv5_1/sep1"
  type: "Convolution"
  bottom: "conv4_3/Eltwise1"
  top: "conv5_1/sep1"
  convolution_param {
    num_output: 240
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1/sep1/scale"
  type: "Scale"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep1"
  top: "conv5_1/dw"
  convolution_param {
    num_output: 240
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep2"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_1/sep2/scale"
  type: "Scale"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
}
layer {
  name: "conv5_2/sep1"
  type: "Convolution"
  bottom: "conv5_1/sep2"
  top: "conv5_2/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2/sep1/scale"
  type: "Scale"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep1"
  top: "conv5_2/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep2"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep2"
  top: "conv5_2/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_2/sep2/scale"
  type: "Scale"
  bottom: "conv5_2/sep2"
  top: "conv5_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv5_1/sep2"
  bottom: "conv5_2/sep2"
  top: "conv5_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv5_2/Eltwise1"
  top: "conv5_2/Eltwise1"
}
layer {
  name: "conv5_3/sep1"
  type: "Convolution"
  bottom: "conv5_2/Eltwise1"
  top: "conv5_3/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3/sep1/scale"
  type: "Scale"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep1"
  top: "conv5_3/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep2"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep2"
  top: "conv5_3/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv5_3/sep2/scale"
  type: "Scale"
  bottom: "conv5_3/sep2"
  top: "conv5_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv5_2/Eltwise1"
  bottom: "conv5_3/sep2"
  top: "conv5_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv5_3/Eltwise1"
  top: "conv5_3/Eltwise1"
}
layer {
  name: "conv6_1/sep1"
  type: "Convolution"
  bottom: "conv5_3/Eltwise1"
  top: "conv6_1/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_1/sep1/scale"
  type: "Scale"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
}
layer {
  name: "conv6_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv6_1/sep1"
  top: "conv6_1/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_1/dw/scale"
  type: "Scale"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
}
layer {
  name: "conv6_1/sep2"
  type: "Convolution"
  bottom: "conv6_1/dw"
  top: "conv6_1/sep2"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_1/sep2/scale"
  type: "Scale"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
}
layer {
  name: "conv6_2/sep1"
  type: "Convolution"
  bottom: "conv6_1/sep2"
  top: "conv6_2/sep1"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_2/sep1/scale"
  type: "Scale"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
}
layer {
  name: "conv6_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv6_2/sep1"
  top: "conv6_2/dw"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_2/dw/scale"
  type: "Scale"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
}
layer {
  name: "conv6_2/sep2"
  type: "Convolution"
  bottom: "conv6_2/dw"
  top: "conv6_2/sep2"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv6_2/sep2"
  top: "conv6_2/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv6_2/sep2/scale"
  type: "Scale"
  bottom: "conv6_2/sep2"
  top: "conv6_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv6_1/sep2"
  bottom: "conv6_2/sep2"
  top: "conv6_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv6_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv6_2/Eltwise1"
  top: "conv6_2/Eltwise1"
}
layer {
  name: "conv7_1/sep1"
  type: "Convolution"
  bottom: "conv6_2/Eltwise1"
  top: "conv7_1/sep1"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_1/sep1/scale"
  type: "Scale"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
}
layer {
  name: "conv7_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_1/sep1"
  top: "conv7_1/dw"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_1/dw/scale"
  type: "Scale"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
}
layer {
  name: "conv7_1/sep2"
  type: "Convolution"
  bottom: "conv7_1/dw"
  top: "conv7_1/sep2"
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_1/sep2/scale"
  type: "Scale"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
}
layer {
  name: "conv7_2/sep1"
  type: "Convolution"
  bottom: "conv7_1/sep2"
  top: "conv7_2/sep1"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_2/sep1/scale"
  type: "Scale"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
}
layer {
  name: "conv7_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_2/sep1"
  top: "conv7_2/dw"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_2/dw/scale"
  type: "Scale"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
}
layer {
  name: "conv7_2/sep2"
  type: "Convolution"
  bottom: "conv7_2/dw"
  top: "conv7_2/sep2"
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv7_2/sep2"
  top: "conv7_2/sep2"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_2/sep2/scale"
  type: "Scale"
  bottom: "conv7_2/sep2"
  top: "conv7_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv7_1/sep2"
  bottom: "conv7_2/sep2"
  top: "conv7_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv7_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv7_2/Eltwise1"
  top: "conv7_2/Eltwise1"
}
layer {
  name: "conv7_3/sep1"
  type: "Convolution"
  bottom: "conv7_2/Eltwise1"
  top: "conv7_3/sep1"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "conv7_3/sep1/scale"
  type: "Scale"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
}
layer {
  name: "conv7_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_3/sep1"
  top: "conv7_3/dw"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 2
    kernel_size: 
I0601 18:37:37.080441  6142 layer_factory.cpp:63] Creating layer data
I0601 18:37:37.081041  6142 db_lmdb.cpp:40] Opened lmdb lmdb/train_lmdb
I0601 18:37:37.081089  6142 net.cpp:84] Creating Layer data
I0601 18:37:37.081100  6142 net.cpp:380] data -> data
I0601 18:37:37.081142  6142 net.cpp:380] data -> label
I0601 18:37:37.082295  6142 data_layer.cpp:45] output data size: 8,3,224,224
I0601 18:37:37.096004  6142 net.cpp:122] Setting up data
I0601 18:37:37.096058  6142 net.cpp:129] Top shape: 8 3 224 224 (1204224)
I0601 18:37:37.096068  6142 net.cpp:129] Top shape: 8 (8)
I0601 18:37:37.096073  6142 net.cpp:137] Memory required for data: 4816928
I0601 18:37:37.096088  6142 layer_factory.cpp:63] Creating layer conv1
I0601 18:37:37.096123  6142 net.cpp:84] Creating Layer conv1
I0601 18:37:37.096133  6142 net.cpp:406] conv1 <- data
I0601 18:37:37.096153  6142 net.cpp:380] conv1 -> conv1
I0601 18:37:37.994716  6142 net.cpp:122] Setting up conv1
I0601 18:37:37.994760  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.994767  6142 net.cpp:137] Memory required for data: 17661984
I0601 18:37:37.994798  6142 layer_factory.cpp:63] Creating layer conv1/bn
I0601 18:37:37.994822  6142 net.cpp:84] Creating Layer conv1/bn
I0601 18:37:37.994829  6142 net.cpp:406] conv1/bn <- conv1
I0601 18:37:37.994839  6142 net.cpp:367] conv1/bn -> conv1 (in-place)
I0601 18:37:37.995136  6142 net.cpp:122] Setting up conv1/bn
I0601 18:37:37.995152  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.995158  6142 net.cpp:137] Memory required for data: 30507040
I0601 18:37:37.995174  6142 layer_factory.cpp:63] Creating layer conv1/scale
I0601 18:37:37.995193  6142 net.cpp:84] Creating Layer conv1/scale
I0601 18:37:37.995198  6142 net.cpp:406] conv1/scale <- conv1
I0601 18:37:37.995206  6142 net.cpp:367] conv1/scale -> conv1 (in-place)
I0601 18:37:37.995275  6142 layer_factory.cpp:63] Creating layer conv1/scale
I0601 18:37:37.995450  6142 net.cpp:122] Setting up conv1/scale
I0601 18:37:37.995463  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.995498  6142 net.cpp:137] Memory required for data: 43352096
I0601 18:37:37.995512  6142 layer_factory.cpp:63] Creating layer conv1/ReLU
I0601 18:37:37.995522  6142 net.cpp:84] Creating Layer conv1/ReLU
I0601 18:37:37.995528  6142 net.cpp:406] conv1/ReLU <- conv1
I0601 18:37:37.995535  6142 net.cpp:367] conv1/ReLU -> conv1 (in-place)
I0601 18:37:37.996307  6142 net.cpp:122] Setting up conv1/ReLU
I0601 18:37:37.996330  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.996336  6142 net.cpp:137] Memory required for data: 56197152
I0601 18:37:37.996342  6142 layer_factory.cpp:63] Creating layer conv2_1/dw
I0601 18:37:37.996354  6142 net.cpp:84] Creating Layer conv2_1/dw
I0601 18:37:37.996361  6142 net.cpp:406] conv2_1/dw <- conv1
I0601 18:37:37.996369  6142 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0601 18:37:37.996565  6142 net.cpp:122] Setting up conv2_1/dw
I0601 18:37:37.996583  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.996589  6142 net.cpp:137] Memory required for data: 69042208
I0601 18:37:37.996598  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/bn
I0601 18:37:37.996606  6142 net.cpp:84] Creating Layer conv2_1/dw/bn
I0601 18:37:37.996613  6142 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0601 18:37:37.996620  6142 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0601 18:37:37.996888  6142 net.cpp:122] Setting up conv2_1/dw/bn
I0601 18:37:37.996901  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.996906  6142 net.cpp:137] Memory required for data: 81887264
I0601 18:37:37.996922  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/scale
I0601 18:37:37.996930  6142 net.cpp:84] Creating Layer conv2_1/dw/scale
I0601 18:37:37.996935  6142 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0601 18:37:37.996942  6142 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0601 18:37:37.996996  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/scale
I0601 18:37:37.997165  6142 net.cpp:122] Setting up conv2_1/dw/scale
I0601 18:37:37.997179  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.997184  6142 net.cpp:137] Memory required for data: 94732320
I0601 18:37:37.997193  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/ReLU
I0601 18:37:37.997203  6142 net.cpp:84] Creating Layer conv2_1/dw/ReLU
I0601 18:37:37.997210  6142 net.cpp:406] conv2_1/dw/ReLU <- conv2_1/dw
I0601 18:37:37.997216  6142 net.cpp:367] conv2_1/dw/ReLU -> conv2_1/dw (in-place)
I0601 18:37:37.997967  6142 net.cpp:122] Setting up conv2_1/dw/ReLU
I0601 18:37:37.997992  6142 net.cpp:129] Top shape: 8 32 112 112 (3211264)
I0601 18:37:37.997997  6142 net.cpp:137] Memory required for data: 107577376
I0601 18:37:37.998003  6142 layer_factory.cpp:63] Creating layer conv2_1/sep
I0601 18:37:37.998015  6142 net.cpp:84] Creating Layer conv2_1/sep
I0601 18:37:37.998021  6142 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0601 18:37:37.998030  6142 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0601 18:37:38.000546  6142 net.cpp:122] Setting up conv2_1/sep
I0601 18:37:38.000572  6142 net.cpp:129] Top shape: 8 16 112 112 (1605632)
I0601 18:37:38.000578  6142 net.cpp:137] Memory required for data: 113999904
I0601 18:37:38.000588  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/bn
I0601 18:37:38.000598  6142 net.cpp:84] Creating Layer conv2_1/sep/bn
I0601 18:37:38.000603  6142 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0601 18:37:38.000612  6142 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0601 18:37:38.000890  6142 net.cpp:122] Setting up conv2_1/sep/bn
I0601 18:37:38.000903  6142 net.cpp:129] Top shape: 8 16 112 112 (1605632)
I0601 18:37:38.000910  6142 net.cpp:137] Memory required for data: 120422432
I0601 18:37:38.000921  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/scale
I0601 18:37:38.000931  6142 net.cpp:84] Creating Layer conv2_1/sep/scale
I0601 18:37:38.000936  6142 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0601 18:37:38.000942  6142 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0601 18:37:38.000998  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/scale
I0601 18:37:38.001188  6142 net.cpp:122] Setting up conv2_1/sep/scale
I0601 18:37:38.001199  6142 net.cpp:129] Top shape: 8 16 112 112 (1605632)
I0601 18:37:38.001204  6142 net.cpp:137] Memory required for data: 126844960
I0601 18:37:38.001219  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/ReLU
I0601 18:37:38.001228  6142 net.cpp:84] Creating Layer conv2_1/sep/ReLU
I0601 18:37:38.001233  6142 net.cpp:406] conv2_1/sep/ReLU <- conv2_1/sep
I0601 18:37:38.001241  6142 net.cpp:367] conv2_1/sep/ReLU -> conv2_1/sep (in-place)
I0601 18:37:38.002003  6142 net.cpp:122] Setting up conv2_1/sep/ReLU
I0601 18:37:38.002027  6142 net.cpp:129] Top shape: 8 16 112 112 (1605632)
I0601 18:37:38.002033  6142 net.cpp:137] Memory required for data: 133267488
I0601 18:37:38.002038  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1
I0601 18:37:38.002051  6142 net.cpp:84] Creating Layer conv3_1/sep1
I0601 18:37:38.002058  6142 net.cpp:406] conv3_1/sep1 <- conv2_1/sep
I0601 18:37:38.002068  6142 net.cpp:380] conv3_1/sep1 -> conv3_1/sep1
I0601 18:37:38.004948  6142 net.cpp:122] Setting up conv3_1/sep1
I0601 18:37:38.004974  6142 net.cpp:129] Top shape: 8 48 112 112 (4816896)
I0601 18:37:38.004981  6142 net.cpp:137] Memory required for data: 152535072
I0601 18:37:38.004989  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/bn
I0601 18:37:38.004999  6142 net.cpp:84] Creating Layer conv3_1/sep1/bn
I0601 18:37:38.005005  6142 net.cpp:406] conv3_1/sep1/bn <- conv3_1/sep1
I0601 18:37:38.005014  6142 net.cpp:367] conv3_1/sep1/bn -> conv3_1/sep1 (in-place)
I0601 18:37:38.005290  6142 net.cpp:122] Setting up conv3_1/sep1/bn
I0601 18:37:38.005304  6142 net.cpp:129] Top shape: 8 48 112 112 (4816896)
I0601 18:37:38.005309  6142 net.cpp:137] Memory required for data: 171802656
I0601 18:37:38.005321  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/scale
I0601 18:37:38.005331  6142 net.cpp:84] Creating Layer conv3_1/sep1/scale
I0601 18:37:38.005336  6142 net.cpp:406] conv3_1/sep1/scale <- conv3_1/sep1
I0601 18:37:38.005343  6142 net.cpp:367] conv3_1/sep1/scale -> conv3_1/sep1 (in-place)
I0601 18:37:38.005398  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/scale
I0601 18:37:38.005559  6142 net.cpp:122] Setting up conv3_1/sep1/scale
I0601 18:37:38.005573  6142 net.cpp:129] Top shape: 8 48 112 112 (4816896)
I0601 18:37:38.005579  6142 net.cpp:137] Memory required for data: 191070240
I0601 18:37:38.005589  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/ReLU
I0601 18:37:38.005599  6142 net.cpp:84] Creating Layer conv3_1/sep1/ReLU
I0601 18:37:38.005604  6142 net.cpp:406] conv3_1/sep1/ReLU <- conv3_1/sep1
I0601 18:37:38.005612  6142 net.cpp:367] conv3_1/sep1/ReLU -> conv3_1/sep1 (in-place)
I0601 18:37:38.006175  6142 net.cpp:122] Setting up conv3_1/sep1/ReLU
I0601 18:37:38.006194  6142 net.cpp:129] Top shape: 8 48 112 112 (4816896)
I0601 18:37:38.006201  6142 net.cpp:137] Memory required for data: 210337824
I0601 18:37:38.006206  6142 layer_factory.cpp:63] Creating layer conv3_1/dw
I0601 18:37:38.006217  6142 net.cpp:84] Creating Layer conv3_1/dw
I0601 18:37:38.006222  6142 net.cpp:406] conv3_1/dw <- conv3_1/sep1
I0601 18:37:38.006230  6142 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0601 18:37:38.006400  6142 net.cpp:122] Setting up conv3_1/dw
I0601 18:37:38.006418  6142 net.cpp:129] Top shape: 8 48 56 56 (1204224)
I0601 18:37:38.006424  6142 net.cpp:137] Memory required for data: 215154720
I0601 18:37:38.006433  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/bn
I0601 18:37:38.006441  6142 net.cpp:84] Creating Layer conv3_1/dw/bn
I0601 18:37:38.006446  6142 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0601 18:37:38.006454  6142 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0601 18:37:38.006716  6142 net.cpp:122] Setting up conv3_1/dw/bn
I0601 18:37:38.006728  6142 net.cpp:129] Top shape: 8 48 56 56 (1204224)
I0601 18:37:38.006733  6142 net.cpp:137] Memory required for data: 219971616
I0601 18:37:38.006744  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/scale
I0601 18:37:38.006775  6142 net.cpp:84] Creating Layer conv3_1/dw/scale
I0601 18:37:38.006781  6142 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0601 18:37:38.006788  6142 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0601 18:37:38.006844  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/scale
I0601 18:37:38.006992  6142 net.cpp:122] Setting up conv3_1/dw/scale
I0601 18:37:38.007002  6142 net.cpp:129] Top shape: 8 48 56 56 (1204224)
I0601 18:37:38.007007  6142 net.cpp:137] Memory required for data: 224788512
I0601 18:37:38.007017  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/ReLU
I0601 18:37:38.007025  6142 net.cpp:84] Creating Layer conv3_1/dw/ReLU
I0601 18:37:38.007030  6142 net.cpp:406] conv3_1/dw/ReLU <- conv3_1/dw
I0601 18:37:38.007037  6142 net.cpp:367] conv3_1/dw/ReLU -> conv3_1/dw (in-place)
I0601 18:37:38.007792  6142 net.cpp:122] Setting up conv3_1/dw/ReLU
I0601 18:37:38.007817  6142 net.cpp:129] Top shape: 8 48 56 56 (1204224)
I0601 18:37:38.007822  6142 net.cpp:137] Memory required for data: 229605408
I0601 18:37:38.007828  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2
I0601 18:37:38.007840  6142 net.cpp:84] Creating Layer conv3_1/sep2
I0601 18:37:38.007848  6142 net.cpp:406] conv3_1/sep2 <- conv3_1/dw
I0601 18:37:38.007856  6142 net.cpp:380] conv3_1/sep2 -> conv3_1/sep2
I0601 18:37:38.010304  6142 net.cpp:122] Setting up conv3_1/sep2
I0601 18:37:38.010329  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.010335  6142 net.cpp:137] Memory required for data: 232013856
I0601 18:37:38.010344  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/bn
I0601 18:37:38.010354  6142 net.cpp:84] Creating Layer conv3_1/sep2/bn
I0601 18:37:38.010360  6142 net.cpp:406] conv3_1/sep2/bn <- conv3_1/sep2
I0601 18:37:38.010368  6142 net.cpp:367] conv3_1/sep2/bn -> conv3_1/sep2 (in-place)
I0601 18:37:38.010635  6142 net.cpp:122] Setting up conv3_1/sep2/bn
I0601 18:37:38.010648  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.010654  6142 net.cpp:137] Memory required for data: 234422304
I0601 18:37:38.010669  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/scale
I0601 18:37:38.010679  6142 net.cpp:84] Creating Layer conv3_1/sep2/scale
I0601 18:37:38.010684  6142 net.cpp:406] conv3_1/sep2/scale <- conv3_1/sep2
I0601 18:37:38.010691  6142 net.cpp:367] conv3_1/sep2/scale -> conv3_1/sep2 (in-place)
I0601 18:37:38.010746  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/scale
I0601 18:37:38.010897  6142 net.cpp:122] Setting up conv3_1/sep2/scale
I0601 18:37:38.010910  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.010915  6142 net.cpp:137] Memory required for data: 236830752
I0601 18:37:38.010923  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/ReLU
I0601 18:37:38.010932  6142 net.cpp:84] Creating Layer conv3_1/sep2/ReLU
I0601 18:37:38.010937  6142 net.cpp:406] conv3_1/sep2/ReLU <- conv3_1/sep2
I0601 18:37:38.010944  6142 net.cpp:367] conv3_1/sep2/ReLU -> conv3_1/sep2 (in-place)
I0601 18:37:38.011721  6142 net.cpp:122] Setting up conv3_1/sep2/ReLU
I0601 18:37:38.011745  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.011751  6142 net.cpp:137] Memory required for data: 239239200
I0601 18:37:38.011757  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.011775  6142 net.cpp:84] Creating Layer conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.011780  6142 net.cpp:406] conv3_1/sep2_conv3_1/sep2/ReLU_0_split <- conv3_1/sep2
I0601 18:37:38.011790  6142 net.cpp:380] conv3_1/sep2_conv3_1/sep2/ReLU_0_split -> conv3_1/sep2_conv3_1/sep2/ReLU_0_split_0
I0601 18:37:38.011802  6142 net.cpp:380] conv3_1/sep2_conv3_1/sep2/ReLU_0_split -> conv3_1/sep2_conv3_1/sep2/ReLU_0_split_1
I0601 18:37:38.011863  6142 net.cpp:122] Setting up conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.011873  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.011880  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.011885  6142 net.cpp:137] Memory required for data: 244056096
I0601 18:37:38.011909  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1
I0601 18:37:38.011921  6142 net.cpp:84] Creating Layer conv3_2/sep1
I0601 18:37:38.011927  6142 net.cpp:406] conv3_2/sep1 <- conv3_1/sep2_conv3_1/sep2/ReLU_0_split_0
I0601 18:37:38.011936  6142 net.cpp:380] conv3_2/sep1 -> conv3_2/sep1
I0601 18:37:38.015100  6142 net.cpp:122] Setting up conv3_2/sep1
I0601 18:37:38.015125  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.015130  6142 net.cpp:137] Memory required for data: 251281440
I0601 18:37:38.015139  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/bn
I0601 18:37:38.015149  6142 net.cpp:84] Creating Layer conv3_2/sep1/bn
I0601 18:37:38.015156  6142 net.cpp:406] conv3_2/sep1/bn <- conv3_2/sep1
I0601 18:37:38.015166  6142 net.cpp:367] conv3_2/sep1/bn -> conv3_2/sep1 (in-place)
I0601 18:37:38.015458  6142 net.cpp:122] Setting up conv3_2/sep1/bn
I0601 18:37:38.015472  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.015477  6142 net.cpp:137] Memory required for data: 258506784
I0601 18:37:38.015488  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/scale
I0601 18:37:38.015497  6142 net.cpp:84] Creating Layer conv3_2/sep1/scale
I0601 18:37:38.015503  6142 net.cpp:406] conv3_2/sep1/scale <- conv3_2/sep1
I0601 18:37:38.015512  6142 net.cpp:367] conv3_2/sep1/scale -> conv3_2/sep1 (in-place)
I0601 18:37:38.015565  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/scale
I0601 18:37:38.015734  6142 net.cpp:122] Setting up conv3_2/sep1/scale
I0601 18:37:38.015748  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.015753  6142 net.cpp:137] Memory required for data: 265732128
I0601 18:37:38.015761  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/ReLU
I0601 18:37:38.015769  6142 net.cpp:84] Creating Layer conv3_2/sep1/ReLU
I0601 18:37:38.015775  6142 net.cpp:406] conv3_2/sep1/ReLU <- conv3_2/sep1
I0601 18:37:38.015784  6142 net.cpp:367] conv3_2/sep1/ReLU -> conv3_2/sep1 (in-place)
I0601 18:37:38.016492  6142 net.cpp:122] Setting up conv3_2/sep1/ReLU
I0601 18:37:38.016515  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.016520  6142 net.cpp:137] Memory required for data: 272957472
I0601 18:37:38.016525  6142 layer_factory.cpp:63] Creating layer conv3_2/dw
I0601 18:37:38.016535  6142 net.cpp:84] Creating Layer conv3_2/dw
I0601 18:37:38.016541  6142 net.cpp:406] conv3_2/dw <- conv3_2/sep1
I0601 18:37:38.016552  6142 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0601 18:37:38.016739  6142 net.cpp:122] Setting up conv3_2/dw
I0601 18:37:38.016757  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.016763  6142 net.cpp:137] Memory required for data: 280182816
I0601 18:37:38.016770  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/bn
I0601 18:37:38.016780  6142 net.cpp:84] Creating Layer conv3_2/dw/bn
I0601 18:37:38.016786  6142 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0601 18:37:38.016795  6142 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0601 18:37:38.017081  6142 net.cpp:122] Setting up conv3_2/dw/bn
I0601 18:37:38.017093  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.017098  6142 net.cpp:137] Memory required for data: 287408160
I0601 18:37:38.017109  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/scale
I0601 18:37:38.017123  6142 net.cpp:84] Creating Layer conv3_2/dw/scale
I0601 18:37:38.017128  6142 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0601 18:37:38.017136  6142 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0601 18:37:38.017191  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/scale
I0601 18:37:38.017359  6142 net.cpp:122] Setting up conv3_2/dw/scale
I0601 18:37:38.017371  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.017377  6142 net.cpp:137] Memory required for data: 294633504
I0601 18:37:38.017386  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/ReLU
I0601 18:37:38.017398  6142 net.cpp:84] Creating Layer conv3_2/dw/ReLU
I0601 18:37:38.017403  6142 net.cpp:406] conv3_2/dw/ReLU <- conv3_2/dw
I0601 18:37:38.017410  6142 net.cpp:367] conv3_2/dw/ReLU -> conv3_2/dw (in-place)
I0601 18:37:38.018324  6142 net.cpp:122] Setting up conv3_2/dw/ReLU
I0601 18:37:38.018347  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.018352  6142 net.cpp:137] Memory required for data: 301858848
I0601 18:37:38.018358  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2
I0601 18:37:38.018373  6142 net.cpp:84] Creating Layer conv3_2/sep2
I0601 18:37:38.018378  6142 net.cpp:406] conv3_2/sep2 <- conv3_2/dw
I0601 18:37:38.018390  6142 net.cpp:380] conv3_2/sep2 -> conv3_2/sep2
I0601 18:37:38.021404  6142 net.cpp:122] Setting up conv3_2/sep2
I0601 18:37:38.021430  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.021435  6142 net.cpp:137] Memory required for data: 304267296
I0601 18:37:38.021443  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/bn
I0601 18:37:38.021456  6142 net.cpp:84] Creating Layer conv3_2/sep2/bn
I0601 18:37:38.021462  6142 net.cpp:406] conv3_2/sep2/bn <- conv3_2/sep2
I0601 18:37:38.021471  6142 net.cpp:367] conv3_2/sep2/bn -> conv3_2/sep2 (in-place)
I0601 18:37:38.021766  6142 net.cpp:122] Setting up conv3_2/sep2/bn
I0601 18:37:38.021780  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.021785  6142 net.cpp:137] Memory required for data: 306675744
I0601 18:37:38.021796  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/scale
I0601 18:37:38.021806  6142 net.cpp:84] Creating Layer conv3_2/sep2/scale
I0601 18:37:38.021811  6142 net.cpp:406] conv3_2/sep2/scale <- conv3_2/sep2
I0601 18:37:38.021818  6142 net.cpp:367] conv3_2/sep2/scale -> conv3_2/sep2 (in-place)
I0601 18:37:38.021879  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/scale
I0601 18:37:38.022049  6142 net.cpp:122] Setting up conv3_2/sep2/scale
I0601 18:37:38.022064  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.022069  6142 net.cpp:137] Memory required for data: 309084192
I0601 18:37:38.022078  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise1
I0601 18:37:38.022097  6142 net.cpp:84] Creating Layer conv3_2/Eltwise1
I0601 18:37:38.022104  6142 net.cpp:406] conv3_2/Eltwise1 <- conv3_1/sep2_conv3_1/sep2/ReLU_0_split_1
I0601 18:37:38.022110  6142 net.cpp:406] conv3_2/Eltwise1 <- conv3_2/sep2
I0601 18:37:38.022119  6142 net.cpp:380] conv3_2/Eltwise1 -> conv3_2/Eltwise1
I0601 18:37:38.022163  6142 net.cpp:122] Setting up conv3_2/Eltwise1
I0601 18:37:38.022173  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.022177  6142 net.cpp:137] Memory required for data: 311492640
I0601 18:37:38.022182  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise/ReLU
I0601 18:37:38.022195  6142 net.cpp:84] Creating Layer conv3_2/Eltwise/ReLU
I0601 18:37:38.022202  6142 net.cpp:406] conv3_2/Eltwise/ReLU <- conv3_2/Eltwise1
I0601 18:37:38.022208  6142 net.cpp:367] conv3_2/Eltwise/ReLU -> conv3_2/Eltwise1 (in-place)
I0601 18:37:38.022917  6142 net.cpp:122] Setting up conv3_2/Eltwise/ReLU
I0601 18:37:38.022938  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.022943  6142 net.cpp:137] Memory required for data: 313901088
I0601 18:37:38.022948  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.022958  6142 net.cpp:84] Creating Layer conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.022963  6142 net.cpp:406] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split <- conv3_2/Eltwise1
I0601 18:37:38.022974  6142 net.cpp:380] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split -> conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.022985  6142 net.cpp:380] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split -> conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.023048  6142 net.cpp:122] Setting up conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.023069  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.023077  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.023082  6142 net.cpp:137] Memory required for data: 318717984
I0601 18:37:38.023087  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1
I0601 18:37:38.023104  6142 net.cpp:84] Creating Layer conv3_3/sep1
I0601 18:37:38.023128  6142 net.cpp:406] conv3_3/sep1 <- conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.023138  6142 net.cpp:380] conv3_3/sep1 -> conv3_3/sep1
I0601 18:37:38.026813  6142 net.cpp:122] Setting up conv3_3/sep1
I0601 18:37:38.026839  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.026845  6142 net.cpp:137] Memory required for data: 325943328
I0601 18:37:38.026854  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/bn
I0601 18:37:38.026867  6142 net.cpp:84] Creating Layer conv3_3/sep1/bn
I0601 18:37:38.026873  6142 net.cpp:406] conv3_3/sep1/bn <- conv3_3/sep1
I0601 18:37:38.026882  6142 net.cpp:367] conv3_3/sep1/bn -> conv3_3/sep1 (in-place)
I0601 18:37:38.027197  6142 net.cpp:122] Setting up conv3_3/sep1/bn
I0601 18:37:38.027213  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.027218  6142 net.cpp:137] Memory required for data: 333168672
I0601 18:37:38.027230  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/scale
I0601 18:37:38.027240  6142 net.cpp:84] Creating Layer conv3_3/sep1/scale
I0601 18:37:38.027245  6142 net.cpp:406] conv3_3/sep1/scale <- conv3_3/sep1
I0601 18:37:38.027251  6142 net.cpp:367] conv3_3/sep1/scale -> conv3_3/sep1 (in-place)
I0601 18:37:38.027310  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/scale
I0601 18:37:38.028134  6142 net.cpp:122] Setting up conv3_3/sep1/scale
I0601 18:37:38.028157  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.028162  6142 net.cpp:137] Memory required for data: 340394016
I0601 18:37:38.028173  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/ReLU
I0601 18:37:38.028182  6142 net.cpp:84] Creating Layer conv3_3/sep1/ReLU
I0601 18:37:38.028188  6142 net.cpp:406] conv3_3/sep1/ReLU <- conv3_3/sep1
I0601 18:37:38.028199  6142 net.cpp:367] conv3_3/sep1/ReLU -> conv3_3/sep1 (in-place)
I0601 18:37:38.029099  6142 net.cpp:122] Setting up conv3_3/sep1/ReLU
I0601 18:37:38.029126  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.029131  6142 net.cpp:137] Memory required for data: 347619360
I0601 18:37:38.029137  6142 layer_factory.cpp:63] Creating layer conv3_3/dw
I0601 18:37:38.029148  6142 net.cpp:84] Creating Layer conv3_3/dw
I0601 18:37:38.029155  6142 net.cpp:406] conv3_3/dw <- conv3_3/sep1
I0601 18:37:38.029165  6142 net.cpp:380] conv3_3/dw -> conv3_3/dw
I0601 18:37:38.029356  6142 net.cpp:122] Setting up conv3_3/dw
I0601 18:37:38.029376  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.029381  6142 net.cpp:137] Memory required for data: 354844704
I0601 18:37:38.029388  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/bn
I0601 18:37:38.029400  6142 net.cpp:84] Creating Layer conv3_3/dw/bn
I0601 18:37:38.029407  6142 net.cpp:406] conv3_3/dw/bn <- conv3_3/dw
I0601 18:37:38.029415  6142 net.cpp:367] conv3_3/dw/bn -> conv3_3/dw (in-place)
I0601 18:37:38.029722  6142 net.cpp:122] Setting up conv3_3/dw/bn
I0601 18:37:38.029736  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.029740  6142 net.cpp:137] Memory required for data: 362070048
I0601 18:37:38.029752  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/scale
I0601 18:37:38.029763  6142 net.cpp:84] Creating Layer conv3_3/dw/scale
I0601 18:37:38.029768  6142 net.cpp:406] conv3_3/dw/scale <- conv3_3/dw
I0601 18:37:38.029776  6142 net.cpp:367] conv3_3/dw/scale -> conv3_3/dw (in-place)
I0601 18:37:38.029835  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/scale
I0601 18:37:38.030010  6142 net.cpp:122] Setting up conv3_3/dw/scale
I0601 18:37:38.030022  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.030027  6142 net.cpp:137] Memory required for data: 369295392
I0601 18:37:38.030047  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/ReLU
I0601 18:37:38.030055  6142 net.cpp:84] Creating Layer conv3_3/dw/ReLU
I0601 18:37:38.030061  6142 net.cpp:406] conv3_3/dw/ReLU <- conv3_3/dw
I0601 18:37:38.030068  6142 net.cpp:367] conv3_3/dw/ReLU -> conv3_3/dw (in-place)
I0601 18:37:38.030779  6142 net.cpp:122] Setting up conv3_3/dw/ReLU
I0601 18:37:38.030819  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.030825  6142 net.cpp:137] Memory required for data: 376520736
I0601 18:37:38.030831  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2
I0601 18:37:38.030845  6142 net.cpp:84] Creating Layer conv3_3/sep2
I0601 18:37:38.030851  6142 net.cpp:406] conv3_3/sep2 <- conv3_3/dw
I0601 18:37:38.030860  6142 net.cpp:380] conv3_3/sep2 -> conv3_3/sep2
I0601 18:37:38.033907  6142 net.cpp:122] Setting up conv3_3/sep2
I0601 18:37:38.033931  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.033937  6142 net.cpp:137] Memory required for data: 378929184
I0601 18:37:38.033946  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/bn
I0601 18:37:38.033958  6142 net.cpp:84] Creating Layer conv3_3/sep2/bn
I0601 18:37:38.033965  6142 net.cpp:406] conv3_3/sep2/bn <- conv3_3/sep2
I0601 18:37:38.033975  6142 net.cpp:367] conv3_3/sep2/bn -> conv3_3/sep2 (in-place)
I0601 18:37:38.034273  6142 net.cpp:122] Setting up conv3_3/sep2/bn
I0601 18:37:38.034287  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.034292  6142 net.cpp:137] Memory required for data: 381337632
I0601 18:37:38.034303  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/scale
I0601 18:37:38.034314  6142 net.cpp:84] Creating Layer conv3_3/sep2/scale
I0601 18:37:38.034320  6142 net.cpp:406] conv3_3/sep2/scale <- conv3_3/sep2
I0601 18:37:38.034327  6142 net.cpp:367] conv3_3/sep2/scale -> conv3_3/sep2 (in-place)
I0601 18:37:38.034385  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/scale
I0601 18:37:38.034557  6142 net.cpp:122] Setting up conv3_3/sep2/scale
I0601 18:37:38.034570  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.034575  6142 net.cpp:137] Memory required for data: 383746080
I0601 18:37:38.034584  6142 layer_factory.cpp:63] Creating layer conv3_3/Eltwise1
I0601 18:37:38.034593  6142 net.cpp:84] Creating Layer conv3_3/Eltwise1
I0601 18:37:38.034600  6142 net.cpp:406] conv3_3/Eltwise1 <- conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.034606  6142 net.cpp:406] conv3_3/Eltwise1 <- conv3_3/sep2
I0601 18:37:38.034618  6142 net.cpp:380] conv3_3/Eltwise1 -> conv3_3/Eltwise1
I0601 18:37:38.034653  6142 net.cpp:122] Setting up conv3_3/Eltwise1
I0601 18:37:38.034662  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.034667  6142 net.cpp:137] Memory required for data: 386154528
I0601 18:37:38.034672  6142 layer_factory.cpp:63] Creating layer conv3_3/Eltwise/ReLU
I0601 18:37:38.034683  6142 net.cpp:84] Creating Layer conv3_3/Eltwise/ReLU
I0601 18:37:38.034688  6142 net.cpp:406] conv3_3/Eltwise/ReLU <- conv3_3/Eltwise1
I0601 18:37:38.034696  6142 net.cpp:367] conv3_3/Eltwise/ReLU -> conv3_3/Eltwise1 (in-place)
I0601 18:37:38.035424  6142 net.cpp:122] Setting up conv3_3/Eltwise/ReLU
I0601 18:37:38.035445  6142 net.cpp:129] Top shape: 8 24 56 56 (602112)
I0601 18:37:38.035450  6142 net.cpp:137] Memory required for data: 388562976
I0601 18:37:38.035456  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1
I0601 18:37:38.035470  6142 net.cpp:84] Creating Layer conv4_1/sep1
I0601 18:37:38.035476  6142 net.cpp:406] conv4_1/sep1 <- conv3_3/Eltwise1
I0601 18:37:38.035488  6142 net.cpp:380] conv4_1/sep1 -> conv4_1/sep1
I0601 18:37:38.038502  6142 net.cpp:122] Setting up conv4_1/sep1
I0601 18:37:38.038525  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.038532  6142 net.cpp:137] Memory required for data: 395788320
I0601 18:37:38.038540  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/bn
I0601 18:37:38.038552  6142 net.cpp:84] Creating Layer conv4_1/sep1/bn
I0601 18:37:38.038559  6142 net.cpp:406] conv4_1/sep1/bn <- conv4_1/sep1
I0601 18:37:38.038568  6142 net.cpp:367] conv4_1/sep1/bn -> conv4_1/sep1 (in-place)
I0601 18:37:38.038868  6142 net.cpp:122] Setting up conv4_1/sep1/bn
I0601 18:37:38.038882  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.038887  6142 net.cpp:137] Memory required for data: 403013664
I0601 18:37:38.038898  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/scale
I0601 18:37:38.038929  6142 net.cpp:84] Creating Layer conv4_1/sep1/scale
I0601 18:37:38.038936  6142 net.cpp:406] conv4_1/sep1/scale <- conv4_1/sep1
I0601 18:37:38.038944  6142 net.cpp:367] conv4_1/sep1/scale -> conv4_1/sep1 (in-place)
I0601 18:37:38.039007  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/scale
I0601 18:37:38.039192  6142 net.cpp:122] Setting up conv4_1/sep1/scale
I0601 18:37:38.039204  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.039209  6142 net.cpp:137] Memory required for data: 410239008
I0601 18:37:38.039218  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/ReLU
I0601 18:37:38.039229  6142 net.cpp:84] Creating Layer conv4_1/sep1/ReLU
I0601 18:37:38.039235  6142 net.cpp:406] conv4_1/sep1/ReLU <- conv4_1/sep1
I0601 18:37:38.039242  6142 net.cpp:367] conv4_1/sep1/ReLU -> conv4_1/sep1 (in-place)
I0601 18:37:38.040679  6142 net.cpp:122] Setting up conv4_1/sep1/ReLU
I0601 18:37:38.040704  6142 net.cpp:129] Top shape: 8 72 56 56 (1806336)
I0601 18:37:38.040709  6142 net.cpp:137] Memory required for data: 417464352
I0601 18:37:38.040715  6142 layer_factory.cpp:63] Creating layer conv4_1/dw
I0601 18:37:38.040727  6142 net.cpp:84] Creating Layer conv4_1/dw
I0601 18:37:38.040735  6142 net.cpp:406] conv4_1/dw <- conv4_1/sep1
I0601 18:37:38.040745  6142 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0601 18:37:38.040963  6142 net.cpp:122] Setting up conv4_1/dw
I0601 18:37:38.040982  6142 net.cpp:129] Top shape: 8 72 28 28 (451584)
I0601 18:37:38.040987  6142 net.cpp:137] Memory required for data: 419270688
I0601 18:37:38.040995  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/bn
I0601 18:37:38.041007  6142 net.cpp:84] Creating Layer conv4_1/dw/bn
I0601 18:37:38.041013  6142 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0601 18:37:38.041020  6142 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0601 18:37:38.041323  6142 net.cpp:122] Setting up conv4_1/dw/bn
I0601 18:37:38.041337  6142 net.cpp:129] Top shape: 8 72 28 28 (451584)
I0601 18:37:38.041342  6142 net.cpp:137] Memory required for data: 421077024
I0601 18:37:38.041353  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/scale
I0601 18:37:38.041363  6142 net.cpp:84] Creating Layer conv4_1/dw/scale
I0601 18:37:38.041368  6142 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0601 18:37:38.041375  6142 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0601 18:37:38.041438  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/scale
I0601 18:37:38.041608  6142 net.cpp:122] Setting up conv4_1/dw/scale
I0601 18:37:38.041621  6142 net.cpp:129] Top shape: 8 72 28 28 (451584)
I0601 18:37:38.041626  6142 net.cpp:137] Memory required for data: 422883360
I0601 18:37:38.041635  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/ReLU
I0601 18:37:38.041646  6142 net.cpp:84] Creating Layer conv4_1/dw/ReLU
I0601 18:37:38.041651  6142 net.cpp:406] conv4_1/dw/ReLU <- conv4_1/dw
I0601 18:37:38.041658  6142 net.cpp:367] conv4_1/dw/ReLU -> conv4_1/dw (in-place)
I0601 18:37:38.042366  6142 net.cpp:122] Setting up conv4_1/dw/ReLU
I0601 18:37:38.042389  6142 net.cpp:129] Top shape: 8 72 28 28 (451584)
I0601 18:37:38.042395  6142 net.cpp:137] Memory required for data: 424689696
I0601 18:37:38.042400  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2
I0601 18:37:38.042413  6142 net.cpp:84] Creating Layer conv4_1/sep2
I0601 18:37:38.042419  6142 net.cpp:406] conv4_1/sep2 <- conv4_1/dw
I0601 18:37:38.042428  6142 net.cpp:380] conv4_1/sep2 -> conv4_1/sep2
I0601 18:37:38.045652  6142 net.cpp:122] Setting up conv4_1/sep2
I0601 18:37:38.045677  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.045683  6142 net.cpp:137] Memory required for data: 425693216
I0601 18:37:38.045692  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/bn
I0601 18:37:38.045706  6142 net.cpp:84] Creating Layer conv4_1/sep2/bn
I0601 18:37:38.045711  6142 net.cpp:406] conv4_1/sep2/bn <- conv4_1/sep2
I0601 18:37:38.045719  6142 net.cpp:367] conv4_1/sep2/bn -> conv4_1/sep2 (in-place)
I0601 18:37:38.046032  6142 net.cpp:122] Setting up conv4_1/sep2/bn
I0601 18:37:38.046066  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.046073  6142 net.cpp:137] Memory required for data: 426696736
I0601 18:37:38.046085  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/scale
I0601 18:37:38.046094  6142 net.cpp:84] Creating Layer conv4_1/sep2/scale
I0601 18:37:38.046100  6142 net.cpp:406] conv4_1/sep2/scale <- conv4_1/sep2
I0601 18:37:38.046108  6142 net.cpp:367] conv4_1/sep2/scale -> conv4_1/sep2 (in-place)
I0601 18:37:38.046175  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/scale
I0601 18:37:38.046345  6142 net.cpp:122] Setting up conv4_1/sep2/scale
I0601 18:37:38.046361  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.046366  6142 net.cpp:137] Memory required for data: 427700256
I0601 18:37:38.046375  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/ReLU
I0601 18:37:38.046391  6142 net.cpp:84] Creating Layer conv4_1/sep2/ReLU
I0601 18:37:38.046397  6142 net.cpp:406] conv4_1/sep2/ReLU <- conv4_1/sep2
I0601 18:37:38.046404  6142 net.cpp:367] conv4_1/sep2/ReLU -> conv4_1/sep2 (in-place)
I0601 18:37:38.047335  6142 net.cpp:122] Setting up conv4_1/sep2/ReLU
I0601 18:37:38.047359  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.047365  6142 net.cpp:137] Memory required for data: 428703776
I0601 18:37:38.047372  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.047384  6142 net.cpp:84] Creating Layer conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.047390  6142 net.cpp:406] conv4_1/sep2_conv4_1/sep2/ReLU_0_split <- conv4_1/sep2
I0601 18:37:38.047399  6142 net.cpp:380] conv4_1/sep2_conv4_1/sep2/ReLU_0_split -> conv4_1/sep2_conv4_1/sep2/ReLU_0_split_0
I0601 18:37:38.047412  6142 net.cpp:380] conv4_1/sep2_conv4_1/sep2/ReLU_0_split -> conv4_1/sep2_conv4_1/sep2/ReLU_0_split_1
I0601 18:37:38.047479  6142 net.cpp:122] Setting up conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.047488  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.047495  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.047500  6142 net.cpp:137] Memory required for data: 430710816
I0601 18:37:38.047505  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1
I0601 18:37:38.047518  6142 net.cpp:84] Creating Layer conv4_2/sep1
I0601 18:37:38.047524  6142 net.cpp:406] conv4_2/sep1 <- conv4_1/sep2_conv4_1/sep2/ReLU_0_split_0
I0601 18:37:38.047535  6142 net.cpp:380] conv4_2/sep1 -> conv4_2/sep1
I0601 18:37:38.050472  6142 net.cpp:122] Setting up conv4_2/sep1
I0601 18:37:38.050495  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.050501  6142 net.cpp:137] Memory required for data: 433721376
I0601 18:37:38.050510  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/bn
I0601 18:37:38.050520  6142 net.cpp:84] Creating Layer conv4_2/sep1/bn
I0601 18:37:38.050526  6142 net.cpp:406] conv4_2/sep1/bn <- conv4_2/sep1
I0601 18:37:38.050537  6142 net.cpp:367] conv4_2/sep1/bn -> conv4_2/sep1 (in-place)
I0601 18:37:38.050839  6142 net.cpp:122] Setting up conv4_2/sep1/bn
I0601 18:37:38.050853  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.050858  6142 net.cpp:137] Memory required for data: 436731936
I0601 18:37:38.050870  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/scale
I0601 18:37:38.050879  6142 net.cpp:84] Creating Layer conv4_2/sep1/scale
I0601 18:37:38.050884  6142 net.cpp:406] conv4_2/sep1/scale <- conv4_2/sep1
I0601 18:37:38.050894  6142 net.cpp:367] conv4_2/sep1/scale -> conv4_2/sep1 (in-place)
I0601 18:37:38.050948  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/scale
I0601 18:37:38.051134  6142 net.cpp:122] Setting up conv4_2/sep1/scale
I0601 18:37:38.051149  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.051154  6142 net.cpp:137] Memory required for data: 439742496
I0601 18:37:38.051163  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/ReLU
I0601 18:37:38.051172  6142 net.cpp:84] Creating Layer conv4_2/sep1/ReLU
I0601 18:37:38.051177  6142 net.cpp:406] conv4_2/sep1/ReLU <- conv4_2/sep1
I0601 18:37:38.051206  6142 net.cpp:367] conv4_2/sep1/ReLU -> conv4_2/sep1 (in-place)
I0601 18:37:38.052109  6142 net.cpp:122] Setting up conv4_2/sep1/ReLU
I0601 18:37:38.052134  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.052140  6142 net.cpp:137] Memory required for data: 442753056
I0601 18:37:38.052146  6142 layer_factory.cpp:63] Creating layer conv4_2/dw
I0601 18:37:38.052156  6142 net.cpp:84] Creating Layer conv4_2/dw
I0601 18:37:38.052162  6142 net.cpp:406] conv4_2/dw <- conv4_2/sep1
I0601 18:37:38.052175  6142 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0601 18:37:38.052419  6142 net.cpp:122] Setting up conv4_2/dw
I0601 18:37:38.052438  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.052443  6142 net.cpp:137] Memory required for data: 445763616
I0601 18:37:38.052451  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/bn
I0601 18:37:38.052461  6142 net.cpp:84] Creating Layer conv4_2/dw/bn
I0601 18:37:38.052466  6142 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0601 18:37:38.052476  6142 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0601 18:37:38.052773  6142 net.cpp:122] Setting up conv4_2/dw/bn
I0601 18:37:38.052786  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.052791  6142 net.cpp:137] Memory required for data: 448774176
I0601 18:37:38.052803  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/scale
I0601 18:37:38.052814  6142 net.cpp:84] Creating Layer conv4_2/dw/scale
I0601 18:37:38.052819  6142 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0601 18:37:38.052826  6142 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0601 18:37:38.052881  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/scale
I0601 18:37:38.053054  6142 net.cpp:122] Setting up conv4_2/dw/scale
I0601 18:37:38.053067  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.053072  6142 net.cpp:137] Memory required for data: 451784736
I0601 18:37:38.053081  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/ReLU
I0601 18:37:38.053089  6142 net.cpp:84] Creating Layer conv4_2/dw/ReLU
I0601 18:37:38.053094  6142 net.cpp:406] conv4_2/dw/ReLU <- conv4_2/dw
I0601 18:37:38.053103  6142 net.cpp:367] conv4_2/dw/ReLU -> conv4_2/dw (in-place)
I0601 18:37:38.054523  6142 net.cpp:122] Setting up conv4_2/dw/ReLU
I0601 18:37:38.054549  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.054555  6142 net.cpp:137] Memory required for data: 454795296
I0601 18:37:38.054561  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2
I0601 18:37:38.054574  6142 net.cpp:84] Creating Layer conv4_2/sep2
I0601 18:37:38.054579  6142 net.cpp:406] conv4_2/sep2 <- conv4_2/dw
I0601 18:37:38.054591  6142 net.cpp:380] conv4_2/sep2 -> conv4_2/sep2
I0601 18:37:38.057549  6142 net.cpp:122] Setting up conv4_2/sep2
I0601 18:37:38.057574  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.057580  6142 net.cpp:137] Memory required for data: 455798816
I0601 18:37:38.057590  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/bn
I0601 18:37:38.057601  6142 net.cpp:84] Creating Layer conv4_2/sep2/bn
I0601 18:37:38.057607  6142 net.cpp:406] conv4_2/sep2/bn <- conv4_2/sep2
I0601 18:37:38.057615  6142 net.cpp:367] conv4_2/sep2/bn -> conv4_2/sep2 (in-place)
I0601 18:37:38.057929  6142 net.cpp:122] Setting up conv4_2/sep2/bn
I0601 18:37:38.057942  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.057948  6142 net.cpp:137] Memory required for data: 456802336
I0601 18:37:38.057960  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/scale
I0601 18:37:38.057971  6142 net.cpp:84] Creating Layer conv4_2/sep2/scale
I0601 18:37:38.057976  6142 net.cpp:406] conv4_2/sep2/scale <- conv4_2/sep2
I0601 18:37:38.057983  6142 net.cpp:367] conv4_2/sep2/scale -> conv4_2/sep2 (in-place)
I0601 18:37:38.058043  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/scale
I0601 18:37:38.058215  6142 net.cpp:122] Setting up conv4_2/sep2/scale
I0601 18:37:38.058228  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.058233  6142 net.cpp:137] Memory required for data: 457805856
I0601 18:37:38.058261  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise1
I0601 18:37:38.058275  6142 net.cpp:84] Creating Layer conv4_2/Eltwise1
I0601 18:37:38.058281  6142 net.cpp:406] conv4_2/Eltwise1 <- conv4_1/sep2_conv4_1/sep2/ReLU_0_split_1
I0601 18:37:38.058288  6142 net.cpp:406] conv4_2/Eltwise1 <- conv4_2/sep2
I0601 18:37:38.058297  6142 net.cpp:380] conv4_2/Eltwise1 -> conv4_2/Eltwise1
I0601 18:37:38.058336  6142 net.cpp:122] Setting up conv4_2/Eltwise1
I0601 18:37:38.058346  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.058351  6142 net.cpp:137] Memory required for data: 458809376
I0601 18:37:38.058356  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise/ReLU
I0601 18:37:38.058363  6142 net.cpp:84] Creating Layer conv4_2/Eltwise/ReLU
I0601 18:37:38.058369  6142 net.cpp:406] conv4_2/Eltwise/ReLU <- conv4_2/Eltwise1
I0601 18:37:38.058379  6142 net.cpp:367] conv4_2/Eltwise/ReLU -> conv4_2/Eltwise1 (in-place)
I0601 18:37:38.059295  6142 net.cpp:122] Setting up conv4_2/Eltwise/ReLU
I0601 18:37:38.059319  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.059324  6142 net.cpp:137] Memory required for data: 459812896
I0601 18:37:38.059330  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.059342  6142 net.cpp:84] Creating Layer conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.059350  6142 net.cpp:406] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split <- conv4_2/Eltwise1
I0601 18:37:38.059358  6142 net.cpp:380] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split -> conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.059370  6142 net.cpp:380] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split -> conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.059439  6142 net.cpp:122] Setting up conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.059448  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.059455  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.059460  6142 net.cpp:137] Memory required for data: 461819936
I0601 18:37:38.059465  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1
I0601 18:37:38.059478  6142 net.cpp:84] Creating Layer conv4_3/sep1
I0601 18:37:38.059485  6142 net.cpp:406] conv4_3/sep1 <- conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.059495  6142 net.cpp:380] conv4_3/sep1 -> conv4_3/sep1
I0601 18:37:38.062409  6142 net.cpp:122] Setting up conv4_3/sep1
I0601 18:37:38.062433  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.062439  6142 net.cpp:137] Memory required for data: 464830496
I0601 18:37:38.062448  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/bn
I0601 18:37:38.062460  6142 net.cpp:84] Creating Layer conv4_3/sep1/bn
I0601 18:37:38.062467  6142 net.cpp:406] conv4_3/sep1/bn <- conv4_3/sep1
I0601 18:37:38.062477  6142 net.cpp:367] conv4_3/sep1/bn -> conv4_3/sep1 (in-place)
I0601 18:37:38.062783  6142 net.cpp:122] Setting up conv4_3/sep1/bn
I0601 18:37:38.062798  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.062803  6142 net.cpp:137] Memory required for data: 467841056
I0601 18:37:38.062814  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/scale
I0601 18:37:38.062825  6142 net.cpp:84] Creating Layer conv4_3/sep1/scale
I0601 18:37:38.062831  6142 net.cpp:406] conv4_3/sep1/scale <- conv4_3/sep1
I0601 18:37:38.062839  6142 net.cpp:367] conv4_3/sep1/scale -> conv4_3/sep1 (in-place)
I0601 18:37:38.062896  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/scale
I0601 18:37:38.063081  6142 net.cpp:122] Setting up conv4_3/sep1/scale
I0601 18:37:38.063096  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.063100  6142 net.cpp:137] Memory required for data: 470851616
I0601 18:37:38.063109  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/ReLU
I0601 18:37:38.063117  6142 net.cpp:84] Creating Layer conv4_3/sep1/ReLU
I0601 18:37:38.063123  6142 net.cpp:406] conv4_3/sep1/ReLU <- conv4_3/sep1
I0601 18:37:38.063133  6142 net.cpp:367] conv4_3/sep1/ReLU -> conv4_3/sep1 (in-place)
I0601 18:37:38.064056  6142 net.cpp:122] Setting up conv4_3/sep1/ReLU
I0601 18:37:38.064080  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.064085  6142 net.cpp:137] Memory required for data: 473862176
I0601 18:37:38.064091  6142 layer_factory.cpp:63] Creating layer conv4_3/dw
I0601 18:37:38.064102  6142 net.cpp:84] Creating Layer conv4_3/dw
I0601 18:37:38.064108  6142 net.cpp:406] conv4_3/dw <- conv4_3/sep1
I0601 18:37:38.064121  6142 net.cpp:380] conv4_3/dw -> conv4_3/dw
I0601 18:37:38.064368  6142 net.cpp:122] Setting up conv4_3/dw
I0601 18:37:38.064386  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.064391  6142 net.cpp:137] Memory required for data: 476872736
I0601 18:37:38.064400  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/bn
I0601 18:37:38.064411  6142 net.cpp:84] Creating Layer conv4_3/dw/bn
I0601 18:37:38.064419  6142 net.cpp:406] conv4_3/dw/bn <- conv4_3/dw
I0601 18:37:38.064429  6142 net.cpp:367] conv4_3/dw/bn -> conv4_3/dw (in-place)
I0601 18:37:38.064725  6142 net.cpp:122] Setting up conv4_3/dw/bn
I0601 18:37:38.064739  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.064744  6142 net.cpp:137] Memory required for data: 479883296
I0601 18:37:38.064755  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/scale
I0601 18:37:38.064769  6142 net.cpp:84] Creating Layer conv4_3/dw/scale
I0601 18:37:38.064774  6142 net.cpp:406] conv4_3/dw/scale <- conv4_3/dw
I0601 18:37:38.064781  6142 net.cpp:367] conv4_3/dw/scale -> conv4_3/dw (in-place)
I0601 18:37:38.064838  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/scale
I0601 18:37:38.065004  6142 net.cpp:122] Setting up conv4_3/dw/scale
I0601 18:37:38.065017  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.065022  6142 net.cpp:137] Memory required for data: 482893856
I0601 18:37:38.065030  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/ReLU
I0601 18:37:38.065042  6142 net.cpp:84] Creating Layer conv4_3/dw/ReLU
I0601 18:37:38.065047  6142 net.cpp:406] conv4_3/dw/ReLU <- conv4_3/dw
I0601 18:37:38.065055  6142 net.cpp:367] conv4_3/dw/ReLU -> conv4_3/dw (in-place)
I0601 18:37:38.065954  6142 net.cpp:122] Setting up conv4_3/dw/ReLU
I0601 18:37:38.065977  6142 net.cpp:129] Top shape: 8 120 28 28 (752640)
I0601 18:37:38.065982  6142 net.cpp:137] Memory required for data: 485904416
I0601 18:37:38.065989  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2
I0601 18:37:38.066002  6142 net.cpp:84] Creating Layer conv4_3/sep2
I0601 18:37:38.066009  6142 net.cpp:406] conv4_3/sep2 <- conv4_3/dw
I0601 18:37:38.066022  6142 net.cpp:380] conv4_3/sep2 -> conv4_3/sep2
I0601 18:37:38.070344  6142 net.cpp:122] Setting up conv4_3/sep2
I0601 18:37:38.070372  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.070379  6142 net.cpp:137] Memory required for data: 486907936
I0601 18:37:38.070387  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/bn
I0601 18:37:38.070397  6142 net.cpp:84] Creating Layer conv4_3/sep2/bn
I0601 18:37:38.070403  6142 net.cpp:406] conv4_3/sep2/bn <- conv4_3/sep2
I0601 18:37:38.070415  6142 net.cpp:367] conv4_3/sep2/bn -> conv4_3/sep2 (in-place)
I0601 18:37:38.070732  6142 net.cpp:122] Setting up conv4_3/sep2/bn
I0601 18:37:38.070746  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.070752  6142 net.cpp:137] Memory required for data: 487911456
I0601 18:37:38.070763  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/scale
I0601 18:37:38.070772  6142 net.cpp:84] Creating Layer conv4_3/sep2/scale
I0601 18:37:38.070777  6142 net.cpp:406] conv4_3/sep2/scale <- conv4_3/sep2
I0601 18:37:38.070785  6142 net.cpp:367] conv4_3/sep2/scale -> conv4_3/sep2 (in-place)
I0601 18:37:38.070845  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/scale
I0601 18:37:38.071022  6142 net.cpp:122] Setting up conv4_3/sep2/scale
I0601 18:37:38.071034  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.071039  6142 net.cpp:137] Memory required for data: 488914976
I0601 18:37:38.071048  6142 layer_factory.cpp:63] Creating layer conv4_3/Eltwise1
I0601 18:37:38.071086  6142 net.cpp:84] Creating Layer conv4_3/Eltwise1
I0601 18:37:38.071094  6142 net.cpp:406] conv4_3/Eltwise1 <- conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.071101  6142 net.cpp:406] conv4_3/Eltwise1 <- conv4_3/sep2
I0601 18:37:38.071112  6142 net.cpp:380] conv4_3/Eltwise1 -> conv4_3/Eltwise1
I0601 18:37:38.071153  6142 net.cpp:122] Setting up conv4_3/Eltwise1
I0601 18:37:38.071166  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.071171  6142 net.cpp:137] Memory required for data: 489918496
I0601 18:37:38.071175  6142 layer_factory.cpp:63] Creating layer conv4_3/Eltwise/ReLU
I0601 18:37:38.071184  6142 net.cpp:84] Creating Layer conv4_3/Eltwise/ReLU
I0601 18:37:38.071189  6142 net.cpp:406] conv4_3/Eltwise/ReLU <- conv4_3/Eltwise1
I0601 18:37:38.071197  6142 net.cpp:367] conv4_3/Eltwise/ReLU -> conv4_3/Eltwise1 (in-place)
I0601 18:37:38.072108  6142 net.cpp:122] Setting up conv4_3/Eltwise/ReLU
I0601 18:37:38.072131  6142 net.cpp:129] Top shape: 8 40 28 28 (250880)
I0601 18:37:38.072136  6142 net.cpp:137] Memory required for data: 490922016
I0601 18:37:38.072142  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1
I0601 18:37:38.072160  6142 net.cpp:84] Creating Layer conv5_1/sep1
I0601 18:37:38.072167  6142 net.cpp:406] conv5_1/sep1 <- conv4_3/Eltwise1
I0601 18:37:38.072177  6142 net.cpp:380] conv5_1/sep1 -> conv5_1/sep1
I0601 18:37:38.075210  6142 net.cpp:122] Setting up conv5_1/sep1
I0601 18:37:38.075234  6142 net.cpp:129] Top shape: 8 240 28 28 (1505280)
I0601 18:37:38.075240  6142 net.cpp:137] Memory required for data: 496943136
I0601 18:37:38.075249  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/bn
I0601 18:37:38.075259  6142 net.cpp:84] Creating Layer conv5_1/sep1/bn
I0601 18:37:38.075265  6142 net.cpp:406] conv5_1/sep1/bn <- conv5_1/sep1
I0601 18:37:38.075276  6142 net.cpp:367] conv5_1/sep1/bn -> conv5_1/sep1 (in-place)
I0601 18:37:38.075587  6142 net.cpp:122] Setting up conv5_1/sep1/bn
I0601 18:37:38.075601  6142 net.cpp:129] Top shape: 8 240 28 28 (1505280)
I0601 18:37:38.075606  6142 net.cpp:137] Memory required for data: 502964256
I0601 18:37:38.075634  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/scale
I0601 18:37:38.075642  6142 net.cpp:84] Creating Layer conv5_1/sep1/scale
I0601 18:37:38.075649  6142 net.cpp:406] conv5_1/sep1/scale <- conv5_1/sep1
I0601 18:37:38.075659  6142 net.cpp:367] conv5_1/sep1/scale -> conv5_1/sep1 (in-place)
I0601 18:37:38.075718  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/scale
I0601 18:37:38.075891  6142 net.cpp:122] Setting up conv5_1/sep1/scale
I0601 18:37:38.075904  6142 net.cpp:129] Top shape: 8 240 28 28 (1505280)
I0601 18:37:38.075909  6142 net.cpp:137] Memory required for data: 508985376
I0601 18:37:38.075918  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/ReLU
I0601 18:37:38.075927  6142 net.cpp:84] Creating Layer conv5_1/sep1/ReLU
I0601 18:37:38.075932  6142 net.cpp:406] conv5_1/sep1/ReLU <- conv5_1/sep1
I0601 18:37:38.075942  6142 net.cpp:367] conv5_1/sep1/ReLU -> conv5_1/sep1 (in-place)
I0601 18:37:38.076854  6142 net.cpp:122] Setting up conv5_1/sep1/ReLU
I0601 18:37:38.076877  6142 net.cpp:129] Top shape: 8 240 28 28 (1505280)
I0601 18:37:38.076884  6142 net.cpp:137] Memory required for data: 515006496
I0601 18:37:38.076889  6142 layer_factory.cpp:63] Creating layer conv5_1/dw
I0601 18:37:38.076901  6142 net.cpp:84] Creating Layer conv5_1/dw
I0601 18:37:38.076907  6142 net.cpp:406] conv5_1/dw <- conv5_1/sep1
I0601 18:37:38.076917  6142 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0601 18:37:38.077219  6142 net.cpp:122] Setting up conv5_1/dw
I0601 18:37:38.077239  6142 net.cpp:129] Top shape: 8 240 14 14 (376320)
I0601 18:37:38.077244  6142 net.cpp:137] Memory required for data: 516511776
I0601 18:37:38.077252  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/bn
I0601 18:37:38.077263  6142 net.cpp:84] Creating Layer conv5_1/dw/bn
I0601 18:37:38.077270  6142 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0601 18:37:38.077277  6142 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0601 18:37:38.077608  6142 net.cpp:122] Setting up conv5_1/dw/bn
I0601 18:37:38.077622  6142 net.cpp:129] Top shape: 8 240 14 14 (376320)
I0601 18:37:38.077627  6142 net.cpp:137] Memory required for data: 518017056
I0601 18:37:38.077639  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/scale
I0601 18:37:38.077648  6142 net.cpp:84] Creating Layer conv5_1/dw/scale
I0601 18:37:38.077654  6142 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0601 18:37:38.077661  6142 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0601 18:37:38.077723  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/scale
I0601 18:37:38.077893  6142 net.cpp:122] Setting up conv5_1/dw/scale
I0601 18:37:38.077905  6142 net.cpp:129] Top shape: 8 240 14 14 (376320)
I0601 18:37:38.077910  6142 net.cpp:137] Memory required for data: 519522336
I0601 18:37:38.077919  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/ReLU
I0601 18:37:38.077927  6142 net.cpp:84] Creating Layer conv5_1/dw/ReLU
I0601 18:37:38.077934  6142 net.cpp:406] conv5_1/dw/ReLU <- conv5_1/dw
I0601 18:37:38.077942  6142 net.cpp:367] conv5_1/dw/ReLU -> conv5_1/dw (in-place)
I0601 18:37:38.078850  6142 net.cpp:122] Setting up conv5_1/dw/ReLU
I0601 18:37:38.078872  6142 net.cpp:129] Top shape: 8 240 14 14 (376320)
I0601 18:37:38.078877  6142 net.cpp:137] Memory required for data: 521027616
I0601 18:37:38.078883  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2
I0601 18:37:38.078897  6142 net.cpp:84] Creating Layer conv5_1/sep2
I0601 18:37:38.078904  6142 net.cpp:406] conv5_1/sep2 <- conv5_1/dw
I0601 18:37:38.078915  6142 net.cpp:380] conv5_1/sep2 -> conv5_1/sep2
I0601 18:37:38.082666  6142 net.cpp:122] Setting up conv5_1/sep2
I0601 18:37:38.082690  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.082696  6142 net.cpp:137] Memory required for data: 521529376
I0601 18:37:38.082705  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/bn
I0601 18:37:38.082717  6142 net.cpp:84] Creating Layer conv5_1/sep2/bn
I0601 18:37:38.082724  6142 net.cpp:406] conv5_1/sep2/bn <- conv5_1/sep2
I0601 18:37:38.082732  6142 net.cpp:367] conv5_1/sep2/bn -> conv5_1/sep2 (in-place)
I0601 18:37:38.083047  6142 net.cpp:122] Setting up conv5_1/sep2/bn
I0601 18:37:38.083072  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.083078  6142 net.cpp:137] Memory required for data: 522031136
I0601 18:37:38.083089  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/scale
I0601 18:37:38.083101  6142 net.cpp:84] Creating Layer conv5_1/sep2/scale
I0601 18:37:38.083107  6142 net.cpp:406] conv5_1/sep2/scale <- conv5_1/sep2
I0601 18:37:38.083114  6142 net.cpp:367] conv5_1/sep2/scale -> conv5_1/sep2 (in-place)
I0601 18:37:38.083176  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/scale
I0601 18:37:38.083353  6142 net.cpp:122] Setting up conv5_1/sep2/scale
I0601 18:37:38.083366  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.083371  6142 net.cpp:137] Memory required for data: 522532896
I0601 18:37:38.083380  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/ReLU
I0601 18:37:38.083393  6142 net.cpp:84] Creating Layer conv5_1/sep2/ReLU
I0601 18:37:38.083398  6142 net.cpp:406] conv5_1/sep2/ReLU <- conv5_1/sep2
I0601 18:37:38.083405  6142 net.cpp:367] conv5_1/sep2/ReLU -> conv5_1/sep2 (in-place)
I0601 18:37:38.084311  6142 net.cpp:122] Setting up conv5_1/sep2/ReLU
I0601 18:37:38.084334  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.084339  6142 net.cpp:137] Memory required for data: 523034656
I0601 18:37:38.084345  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.084358  6142 net.cpp:84] Creating Layer conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.084365  6142 net.cpp:406] conv5_1/sep2_conv5_1/sep2/ReLU_0_split <- conv5_1/sep2
I0601 18:37:38.084374  6142 net.cpp:380] conv5_1/sep2_conv5_1/sep2/ReLU_0_split -> conv5_1/sep2_conv5_1/sep2/ReLU_0_split_0
I0601 18:37:38.084388  6142 net.cpp:380] conv5_1/sep2_conv5_1/sep2/ReLU_0_split -> conv5_1/sep2_conv5_1/sep2/ReLU_0_split_1
I0601 18:37:38.084455  6142 net.cpp:122] Setting up conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.084481  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.084488  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.084493  6142 net.cpp:137] Memory required for data: 524038176
I0601 18:37:38.084498  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1
I0601 18:37:38.084513  6142 net.cpp:84] Creating Layer conv5_2/sep1
I0601 18:37:38.084519  6142 net.cpp:406] conv5_2/sep1 <- conv5_1/sep2_conv5_1/sep2/ReLU_0_split_0
I0601 18:37:38.084530  6142 net.cpp:380] conv5_2/sep1 -> conv5_2/sep1
I0601 18:37:38.088089  6142 net.cpp:122] Setting up conv5_2/sep1
I0601 18:37:38.088114  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.088119  6142 net.cpp:137] Memory required for data: 527048736
I0601 18:37:38.088129  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/bn
I0601 18:37:38.088141  6142 net.cpp:84] Creating Layer conv5_2/sep1/bn
I0601 18:37:38.088147  6142 net.cpp:406] conv5_2/sep1/bn <- conv5_2/sep1
I0601 18:37:38.088157  6142 net.cpp:367] conv5_2/sep1/bn -> conv5_2/sep1 (in-place)
I0601 18:37:38.088467  6142 net.cpp:122] Setting up conv5_2/sep1/bn
I0601 18:37:38.088481  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.088486  6142 net.cpp:137] Memory required for data: 530059296
I0601 18:37:38.088497  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/scale
I0601 18:37:38.088508  6142 net.cpp:84] Creating Layer conv5_2/sep1/scale
I0601 18:37:38.088515  6142 net.cpp:406] conv5_2/sep1/scale <- conv5_2/sep1
I0601 18:37:38.088521  6142 net.cpp:367] conv5_2/sep1/scale -> conv5_2/sep1 (in-place)
I0601 18:37:38.088582  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/scale
I0601 18:37:38.088759  6142 net.cpp:122] Setting up conv5_2/sep1/scale
I0601 18:37:38.088773  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.088778  6142 net.cpp:137] Memory required for data: 533069856
I0601 18:37:38.088786  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/ReLU
I0601 18:37:38.088794  6142 net.cpp:84] Creating Layer conv5_2/sep1/ReLU
I0601 18:37:38.088799  6142 net.cpp:406] conv5_2/sep1/ReLU <- conv5_2/sep1
I0601 18:37:38.088809  6142 net.cpp:367] conv5_2/sep1/ReLU -> conv5_2/sep1 (in-place)
I0601 18:37:38.089741  6142 net.cpp:122] Setting up conv5_2/sep1/ReLU
I0601 18:37:38.089764  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.089771  6142 net.cpp:137] Memory required for data: 536080416
I0601 18:37:38.089776  6142 layer_factory.cpp:63] Creating layer conv5_2/dw
I0601 18:37:38.089787  6142 net.cpp:84] Creating Layer conv5_2/dw
I0601 18:37:38.089792  6142 net.cpp:406] conv5_2/dw <- conv5_2/sep1
I0601 18:37:38.089804  6142 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0601 18:37:38.090226  6142 net.cpp:122] Setting up conv5_2/dw
I0601 18:37:38.090245  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.090250  6142 net.cpp:137] Memory required for data: 539090976
I0601 18:37:38.090258  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/bn
I0601 18:37:38.090267  6142 net.cpp:84] Creating Layer conv5_2/dw/bn
I0601 18:37:38.090273  6142 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0601 18:37:38.090283  6142 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0601 18:37:38.090589  6142 net.cpp:122] Setting up conv5_2/dw/bn
I0601 18:37:38.090601  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.090606  6142 net.cpp:137] Memory required for data: 542101536
I0601 18:37:38.090617  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/scale
I0601 18:37:38.090626  6142 net.cpp:84] Creating Layer conv5_2/dw/scale
I0601 18:37:38.090632  6142 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0601 18:37:38.090641  6142 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0601 18:37:38.090700  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/scale
I0601 18:37:38.090880  6142 net.cpp:122] Setting up conv5_2/dw/scale
I0601 18:37:38.090891  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.090896  6142 net.cpp:137] Memory required for data: 545112096
I0601 18:37:38.090924  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/ReLU
I0601 18:37:38.090934  6142 net.cpp:84] Creating Layer conv5_2/dw/ReLU
I0601 18:37:38.090939  6142 net.cpp:406] conv5_2/dw/ReLU <- conv5_2/dw
I0601 18:37:38.090950  6142 net.cpp:367] conv5_2/dw/ReLU -> conv5_2/dw (in-place)
I0601 18:37:38.091881  6142 net.cpp:122] Setting up conv5_2/dw/ReLU
I0601 18:37:38.091907  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.091912  6142 net.cpp:137] Memory required for data: 548122656
I0601 18:37:38.091918  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2
I0601 18:37:38.091933  6142 net.cpp:84] Creating Layer conv5_2/sep2
I0601 18:37:38.091938  6142 net.cpp:406] conv5_2/sep2 <- conv5_2/dw
I0601 18:37:38.091948  6142 net.cpp:380] conv5_2/sep2 -> conv5_2/sep2
I0601 18:37:38.096334  6142 net.cpp:122] Setting up conv5_2/sep2
I0601 18:37:38.096359  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.096365  6142 net.cpp:137] Memory required for data: 548624416
I0601 18:37:38.096374  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/bn
I0601 18:37:38.096387  6142 net.cpp:84] Creating Layer conv5_2/sep2/bn
I0601 18:37:38.096395  6142 net.cpp:406] conv5_2/sep2/bn <- conv5_2/sep2
I0601 18:37:38.096402  6142 net.cpp:367] conv5_2/sep2/bn -> conv5_2/sep2 (in-place)
I0601 18:37:38.096717  6142 net.cpp:122] Setting up conv5_2/sep2/bn
I0601 18:37:38.096731  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.096736  6142 net.cpp:137] Memory required for data: 549126176
I0601 18:37:38.096747  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/scale
I0601 18:37:38.096756  6142 net.cpp:84] Creating Layer conv5_2/sep2/scale
I0601 18:37:38.096762  6142 net.cpp:406] conv5_2/sep2/scale <- conv5_2/sep2
I0601 18:37:38.096769  6142 net.cpp:367] conv5_2/sep2/scale -> conv5_2/sep2 (in-place)
I0601 18:37:38.096832  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/scale
I0601 18:37:38.097010  6142 net.cpp:122] Setting up conv5_2/sep2/scale
I0601 18:37:38.097023  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.097028  6142 net.cpp:137] Memory required for data: 549627936
I0601 18:37:38.097038  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise1
I0601 18:37:38.097049  6142 net.cpp:84] Creating Layer conv5_2/Eltwise1
I0601 18:37:38.097055  6142 net.cpp:406] conv5_2/Eltwise1 <- conv5_1/sep2_conv5_1/sep2/ReLU_0_split_1
I0601 18:37:38.097062  6142 net.cpp:406] conv5_2/Eltwise1 <- conv5_2/sep2
I0601 18:37:38.097070  6142 net.cpp:380] conv5_2/Eltwise1 -> conv5_2/Eltwise1
I0601 18:37:38.097110  6142 net.cpp:122] Setting up conv5_2/Eltwise1
I0601 18:37:38.097120  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.097124  6142 net.cpp:137] Memory required for data: 550129696
I0601 18:37:38.097129  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise/ReLU
I0601 18:37:38.097138  6142 net.cpp:84] Creating Layer conv5_2/Eltwise/ReLU
I0601 18:37:38.097143  6142 net.cpp:406] conv5_2/Eltwise/ReLU <- conv5_2/Eltwise1
I0601 18:37:38.097151  6142 net.cpp:367] conv5_2/Eltwise/ReLU -> conv5_2/Eltwise1 (in-place)
I0601 18:37:38.098657  6142 net.cpp:122] Setting up conv5_2/Eltwise/ReLU
I0601 18:37:38.098681  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.098686  6142 net.cpp:137] Memory required for data: 550631456
I0601 18:37:38.098692  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.098702  6142 net.cpp:84] Creating Layer conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.098709  6142 net.cpp:406] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split <- conv5_2/Eltwise1
I0601 18:37:38.098722  6142 net.cpp:380] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split -> conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.098734  6142 net.cpp:380] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split -> conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.098796  6142 net.cpp:122] Setting up conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.098806  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.098830  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.098836  6142 net.cpp:137] Memory required for data: 551634976
I0601 18:37:38.098841  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1
I0601 18:37:38.098860  6142 net.cpp:84] Creating Layer conv5_3/sep1
I0601 18:37:38.098866  6142 net.cpp:406] conv5_3/sep1 <- conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.098875  6142 net.cpp:380] conv5_3/sep1 -> conv5_3/sep1
I0601 18:37:38.102643  6142 net.cpp:122] Setting up conv5_3/sep1
I0601 18:37:38.102669  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.102674  6142 net.cpp:137] Memory required for data: 554645536
I0601 18:37:38.102684  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/bn
I0601 18:37:38.102695  6142 net.cpp:84] Creating Layer conv5_3/sep1/bn
I0601 18:37:38.102702  6142 net.cpp:406] conv5_3/sep1/bn <- conv5_3/sep1
I0601 18:37:38.102710  6142 net.cpp:367] conv5_3/sep1/bn -> conv5_3/sep1 (in-place)
I0601 18:37:38.103020  6142 net.cpp:122] Setting up conv5_3/sep1/bn
I0601 18:37:38.103034  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.103039  6142 net.cpp:137] Memory required for data: 557656096
I0601 18:37:38.103050  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/scale
I0601 18:37:38.103073  6142 net.cpp:84] Creating Layer conv5_3/sep1/scale
I0601 18:37:38.103080  6142 net.cpp:406] conv5_3/sep1/scale <- conv5_3/sep1
I0601 18:37:38.103087  6142 net.cpp:367] conv5_3/sep1/scale -> conv5_3/sep1 (in-place)
I0601 18:37:38.103148  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/scale
I0601 18:37:38.103325  6142 net.cpp:122] Setting up conv5_3/sep1/scale
I0601 18:37:38.103339  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.103344  6142 net.cpp:137] Memory required for data: 560666656
I0601 18:37:38.103353  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/ReLU
I0601 18:37:38.103366  6142 net.cpp:84] Creating Layer conv5_3/sep1/ReLU
I0601 18:37:38.103371  6142 net.cpp:406] conv5_3/sep1/ReLU <- conv5_3/sep1
I0601 18:37:38.103379  6142 net.cpp:367] conv5_3/sep1/ReLU -> conv5_3/sep1 (in-place)
I0601 18:37:38.104104  6142 net.cpp:122] Setting up conv5_3/sep1/ReLU
I0601 18:37:38.104123  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.104130  6142 net.cpp:137] Memory required for data: 563677216
I0601 18:37:38.104135  6142 layer_factory.cpp:63] Creating layer conv5_3/dw
I0601 18:37:38.104147  6142 net.cpp:84] Creating Layer conv5_3/dw
I0601 18:37:38.104153  6142 net.cpp:406] conv5_3/dw <- conv5_3/sep1
I0601 18:37:38.104162  6142 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0601 18:37:38.104576  6142 net.cpp:122] Setting up conv5_3/dw
I0601 18:37:38.104595  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.104600  6142 net.cpp:137] Memory required for data: 566687776
I0601 18:37:38.104609  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/bn
I0601 18:37:38.104617  6142 net.cpp:84] Creating Layer conv5_3/dw/bn
I0601 18:37:38.104624  6142 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0601 18:37:38.104634  6142 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0601 18:37:38.104941  6142 net.cpp:122] Setting up conv5_3/dw/bn
I0601 18:37:38.104954  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.104959  6142 net.cpp:137] Memory required for data: 569698336
I0601 18:37:38.104971  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/scale
I0601 18:37:38.104980  6142 net.cpp:84] Creating Layer conv5_3/dw/scale
I0601 18:37:38.104985  6142 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0601 18:37:38.104995  6142 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0601 18:37:38.105052  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/scale
I0601 18:37:38.105224  6142 net.cpp:122] Setting up conv5_3/dw/scale
I0601 18:37:38.105237  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.105242  6142 net.cpp:137] Memory required for data: 572708896
I0601 18:37:38.105250  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/ReLU
I0601 18:37:38.105276  6142 net.cpp:84] Creating Layer conv5_3/dw/ReLU
I0601 18:37:38.105283  6142 net.cpp:406] conv5_3/dw/ReLU <- conv5_3/dw
I0601 18:37:38.105293  6142 net.cpp:367] conv5_3/dw/ReLU -> conv5_3/dw (in-place)
I0601 18:37:38.106216  6142 net.cpp:122] Setting up conv5_3/dw/ReLU
I0601 18:37:38.106238  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.106245  6142 net.cpp:137] Memory required for data: 575719456
I0601 18:37:38.106251  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2
I0601 18:37:38.106276  6142 net.cpp:84] Creating Layer conv5_3/sep2
I0601 18:37:38.106282  6142 net.cpp:406] conv5_3/sep2 <- conv5_3/dw
I0601 18:37:38.106292  6142 net.cpp:380] conv5_3/sep2 -> conv5_3/sep2
I0601 18:37:38.109869  6142 net.cpp:122] Setting up conv5_3/sep2
I0601 18:37:38.109894  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.109899  6142 net.cpp:137] Memory required for data: 576221216
I0601 18:37:38.109910  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/bn
I0601 18:37:38.109921  6142 net.cpp:84] Creating Layer conv5_3/sep2/bn
I0601 18:37:38.109927  6142 net.cpp:406] conv5_3/sep2/bn <- conv5_3/sep2
I0601 18:37:38.109935  6142 net.cpp:367] conv5_3/sep2/bn -> conv5_3/sep2 (in-place)
I0601 18:37:38.110252  6142 net.cpp:122] Setting up conv5_3/sep2/bn
I0601 18:37:38.110266  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.110271  6142 net.cpp:137] Memory required for data: 576722976
I0601 18:37:38.110283  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/scale
I0601 18:37:38.110294  6142 net.cpp:84] Creating Layer conv5_3/sep2/scale
I0601 18:37:38.110301  6142 net.cpp:406] conv5_3/sep2/scale <- conv5_3/sep2
I0601 18:37:38.110307  6142 net.cpp:367] conv5_3/sep2/scale -> conv5_3/sep2 (in-place)
I0601 18:37:38.110370  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/scale
I0601 18:37:38.110553  6142 net.cpp:122] Setting up conv5_3/sep2/scale
I0601 18:37:38.110568  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.110572  6142 net.cpp:137] Memory required for data: 577224736
I0601 18:37:38.110581  6142 layer_factory.cpp:63] Creating layer conv5_3/Eltwise1
I0601 18:37:38.110592  6142 net.cpp:84] Creating Layer conv5_3/Eltwise1
I0601 18:37:38.110599  6142 net.cpp:406] conv5_3/Eltwise1 <- conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.110605  6142 net.cpp:406] conv5_3/Eltwise1 <- conv5_3/sep2
I0601 18:37:38.110615  6142 net.cpp:380] conv5_3/Eltwise1 -> conv5_3/Eltwise1
I0601 18:37:38.110651  6142 net.cpp:122] Setting up conv5_3/Eltwise1
I0601 18:37:38.110659  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.110663  6142 net.cpp:137] Memory required for data: 577726496
I0601 18:37:38.110668  6142 layer_factory.cpp:63] Creating layer conv5_3/Eltwise/ReLU
I0601 18:37:38.110679  6142 net.cpp:84] Creating Layer conv5_3/Eltwise/ReLU
I0601 18:37:38.110685  6142 net.cpp:406] conv5_3/Eltwise/ReLU <- conv5_3/Eltwise1
I0601 18:37:38.110692  6142 net.cpp:367] conv5_3/Eltwise/ReLU -> conv5_3/Eltwise1 (in-place)
I0601 18:37:38.111618  6142 net.cpp:122] Setting up conv5_3/Eltwise/ReLU
I0601 18:37:38.111640  6142 net.cpp:129] Top shape: 8 80 14 14 (125440)
I0601 18:37:38.111646  6142 net.cpp:137] Memory required for data: 578228256
I0601 18:37:38.111651  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1
I0601 18:37:38.111666  6142 net.cpp:84] Creating Layer conv6_1/sep1
I0601 18:37:38.111673  6142 net.cpp:406] conv6_1/sep1 <- conv5_3/Eltwise1
I0601 18:37:38.111685  6142 net.cpp:380] conv6_1/sep1 -> conv6_1/sep1
I0601 18:37:38.115990  6142 net.cpp:122] Setting up conv6_1/sep1
I0601 18:37:38.116015  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.116021  6142 net.cpp:137] Memory required for data: 581238816
I0601 18:37:38.116030  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/bn
I0601 18:37:38.116042  6142 net.cpp:84] Creating Layer conv6_1/sep1/bn
I0601 18:37:38.116048  6142 net.cpp:406] conv6_1/sep1/bn <- conv6_1/sep1
I0601 18:37:38.116057  6142 net.cpp:367] conv6_1/sep1/bn -> conv6_1/sep1 (in-place)
I0601 18:37:38.116400  6142 net.cpp:122] Setting up conv6_1/sep1/bn
I0601 18:37:38.116415  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.116420  6142 net.cpp:137] Memory required for data: 584249376
I0601 18:37:38.116432  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/scale
I0601 18:37:38.116441  6142 net.cpp:84] Creating Layer conv6_1/sep1/scale
I0601 18:37:38.116447  6142 net.cpp:406] conv6_1/sep1/scale <- conv6_1/sep1
I0601 18:37:38.116454  6142 net.cpp:367] conv6_1/sep1/scale -> conv6_1/sep1 (in-place)
I0601 18:37:38.116518  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/scale
I0601 18:37:38.116690  6142 net.cpp:122] Setting up conv6_1/sep1/scale
I0601 18:37:38.116704  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.116708  6142 net.cpp:137] Memory required for data: 587259936
I0601 18:37:38.116717  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/ReLU
I0601 18:37:38.116726  6142 net.cpp:84] Creating Layer conv6_1/sep1/ReLU
I0601 18:37:38.116731  6142 net.cpp:406] conv6_1/sep1/ReLU <- conv6_1/sep1
I0601 18:37:38.116740  6142 net.cpp:367] conv6_1/sep1/ReLU -> conv6_1/sep1 (in-place)
I0601 18:37:38.117466  6142 net.cpp:122] Setting up conv6_1/sep1/ReLU
I0601 18:37:38.117488  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.117493  6142 net.cpp:137] Memory required for data: 590270496
I0601 18:37:38.117499  6142 layer_factory.cpp:63] Creating layer conv6_1/dw
I0601 18:37:38.117509  6142 net.cpp:84] Creating Layer conv6_1/dw
I0601 18:37:38.117516  6142 net.cpp:406] conv6_1/dw <- conv6_1/sep1
I0601 18:37:38.117527  6142 net.cpp:380] conv6_1/dw -> conv6_1/dw
I0601 18:37:38.117794  6142 net.cpp:122] Setting up conv6_1/dw
I0601 18:37:38.117811  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.117817  6142 net.cpp:137] Memory required for data: 593281056
I0601 18:37:38.117825  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/bn
I0601 18:37:38.117835  6142 net.cpp:84] Creating Layer conv6_1/dw/bn
I0601 18:37:38.117841  6142 net.cpp:406] conv6_1/dw/bn <- conv6_1/dw
I0601 18:37:38.117851  6142 net.cpp:367] conv6_1/dw/bn -> conv6_1/dw (in-place)
I0601 18:37:38.118155  6142 net.cpp:122] Setting up conv6_1/dw/bn
I0601 18:37:38.118168  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.118173  6142 net.cpp:137] Memory required for data: 596291616
I0601 18:37:38.118185  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/scale
I0601 18:37:38.118196  6142 net.cpp:84] Creating Layer conv6_1/dw/scale
I0601 18:37:38.118202  6142 net.cpp:406] conv6_1/dw/scale <- conv6_1/dw
I0601 18:37:38.118209  6142 net.cpp:367] conv6_1/dw/scale -> conv6_1/dw (in-place)
I0601 18:37:38.118268  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/scale
I0601 18:37:38.118446  6142 net.cpp:122] Setting up conv6_1/dw/scale
I0601 18:37:38.118459  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.118464  6142 net.cpp:137] Memory required for data: 599302176
I0601 18:37:38.118474  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/ReLU
I0601 18:37:38.118481  6142 net.cpp:84] Creating Layer conv6_1/dw/ReLU
I0601 18:37:38.118487  6142 net.cpp:406] conv6_1/dw/ReLU <- conv6_1/dw
I0601 18:37:38.118496  6142 net.cpp:367] conv6_1/dw/ReLU -> conv6_1/dw (in-place)
I0601 18:37:38.119422  6142 net.cpp:122] Setting up conv6_1/dw/ReLU
I0601 18:37:38.119448  6142 net.cpp:129] Top shape: 8 480 14 14 (752640)
I0601 18:37:38.119454  6142 net.cpp:137] Memory required for data: 602312736
I0601 18:37:38.119459  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2
I0601 18:37:38.119474  6142 net.cpp:84] Creating Layer conv6_1/sep2
I0601 18:37:38.119480  6142 net.cpp:406] conv6_1/sep2 <- conv6_1/dw
I0601 18:37:38.119490  6142 net.cpp:380] conv6_1/sep2 -> conv6_1/sep2
I0601 18:37:38.123409  6142 net.cpp:122] Setting up conv6_1/sep2
I0601 18:37:38.123436  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.123442  6142 net.cpp:137] Memory required for data: 602914848
I0601 18:37:38.123451  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/bn
I0601 18:37:38.123478  6142 net.cpp:84] Creating Layer conv6_1/sep2/bn
I0601 18:37:38.123486  6142 net.cpp:406] conv6_1/sep2/bn <- conv6_1/sep2
I0601 18:37:38.123494  6142 net.cpp:367] conv6_1/sep2/bn -> conv6_1/sep2 (in-place)
I0601 18:37:38.123814  6142 net.cpp:122] Setting up conv6_1/sep2/bn
I0601 18:37:38.123829  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.123834  6142 net.cpp:137] Memory required for data: 603516960
I0601 18:37:38.123847  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/scale
I0601 18:37:38.123855  6142 net.cpp:84] Creating Layer conv6_1/sep2/scale
I0601 18:37:38.123860  6142 net.cpp:406] conv6_1/sep2/scale <- conv6_1/sep2
I0601 18:37:38.123868  6142 net.cpp:367] conv6_1/sep2/scale -> conv6_1/sep2 (in-place)
I0601 18:37:38.123934  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/scale
I0601 18:37:38.124109  6142 net.cpp:122] Setting up conv6_1/sep2/scale
I0601 18:37:38.124126  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.124131  6142 net.cpp:137] Memory required for data: 604119072
I0601 18:37:38.124140  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/ReLU
I0601 18:37:38.124150  6142 net.cpp:84] Creating Layer conv6_1/sep2/ReLU
I0601 18:37:38.124155  6142 net.cpp:406] conv6_1/sep2/ReLU <- conv6_1/sep2
I0601 18:37:38.124161  6142 net.cpp:367] conv6_1/sep2/ReLU -> conv6_1/sep2 (in-place)
I0601 18:37:38.125070  6142 net.cpp:122] Setting up conv6_1/sep2/ReLU
I0601 18:37:38.125093  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.125098  6142 net.cpp:137] Memory required for data: 604721184
I0601 18:37:38.125104  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.125114  6142 net.cpp:84] Creating Layer conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.125120  6142 net.cpp:406] conv6_1/sep2_conv6_1/sep2/ReLU_0_split <- conv6_1/sep2
I0601 18:37:38.125131  6142 net.cpp:380] conv6_1/sep2_conv6_1/sep2/ReLU_0_split -> conv6_1/sep2_conv6_1/sep2/ReLU_0_split_0
I0601 18:37:38.125144  6142 net.cpp:380] conv6_1/sep2_conv6_1/sep2/ReLU_0_split -> conv6_1/sep2_conv6_1/sep2/ReLU_0_split_1
I0601 18:37:38.125213  6142 net.cpp:122] Setting up conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.125223  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.125229  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.125234  6142 net.cpp:137] Memory required for data: 605925408
I0601 18:37:38.125239  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1
I0601 18:37:38.125252  6142 net.cpp:84] Creating Layer conv6_2/sep1
I0601 18:37:38.125259  6142 net.cpp:406] conv6_2/sep1 <- conv6_1/sep2_conv6_1/sep2/ReLU_0_split_0
I0601 18:37:38.125267  6142 net.cpp:380] conv6_2/sep1 -> conv6_2/sep1
I0601 18:37:38.130534  6142 net.cpp:122] Setting up conv6_2/sep1
I0601 18:37:38.130563  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.130568  6142 net.cpp:137] Memory required for data: 609538080
I0601 18:37:38.130578  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/bn
I0601 18:37:38.130587  6142 net.cpp:84] Creating Layer conv6_2/sep1/bn
I0601 18:37:38.130594  6142 net.cpp:406] conv6_2/sep1/bn <- conv6_2/sep1
I0601 18:37:38.130607  6142 net.cpp:367] conv6_2/sep1/bn -> conv6_2/sep1 (in-place)
I0601 18:37:38.130935  6142 net.cpp:122] Setting up conv6_2/sep1/bn
I0601 18:37:38.130949  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.130955  6142 net.cpp:137] Memory required for data: 613150752
I0601 18:37:38.130966  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/scale
I0601 18:37:38.130975  6142 net.cpp:84] Creating Layer conv6_2/sep1/scale
I0601 18:37:38.130981  6142 net.cpp:406] conv6_2/sep1/scale <- conv6_2/sep1
I0601 18:37:38.130991  6142 net.cpp:367] conv6_2/sep1/scale -> conv6_2/sep1 (in-place)
I0601 18:37:38.131050  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/scale
I0601 18:37:38.131247  6142 net.cpp:122] Setting up conv6_2/sep1/scale
I0601 18:37:38.131261  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.131266  6142 net.cpp:137] Memory required for data: 616763424
I0601 18:37:38.131294  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/ReLU
I0601 18:37:38.131302  6142 net.cpp:84] Creating Layer conv6_2/sep1/ReLU
I0601 18:37:38.131309  6142 net.cpp:406] conv6_2/sep1/ReLU <- conv6_2/sep1
I0601 18:37:38.131315  6142 net.cpp:367] conv6_2/sep1/ReLU -> conv6_2/sep1 (in-place)
I0601 18:37:38.132241  6142 net.cpp:122] Setting up conv6_2/sep1/ReLU
I0601 18:37:38.132267  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.132273  6142 net.cpp:137] Memory required for data: 620376096
I0601 18:37:38.132279  6142 layer_factory.cpp:63] Creating layer conv6_2/dw
I0601 18:37:38.132290  6142 net.cpp:84] Creating Layer conv6_2/dw
I0601 18:37:38.132297  6142 net.cpp:406] conv6_2/dw <- conv6_2/sep1
I0601 18:37:38.132308  6142 net.cpp:380] conv6_2/dw -> conv6_2/dw
I0601 18:37:38.132591  6142 net.cpp:122] Setting up conv6_2/dw
I0601 18:37:38.132608  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.132614  6142 net.cpp:137] Memory required for data: 623988768
I0601 18:37:38.132622  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/bn
I0601 18:37:38.132634  6142 net.cpp:84] Creating Layer conv6_2/dw/bn
I0601 18:37:38.132640  6142 net.cpp:406] conv6_2/dw/bn <- conv6_2/dw
I0601 18:37:38.132648  6142 net.cpp:367] conv6_2/dw/bn -> conv6_2/dw (in-place)
I0601 18:37:38.132959  6142 net.cpp:122] Setting up conv6_2/dw/bn
I0601 18:37:38.132972  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.132977  6142 net.cpp:137] Memory required for data: 627601440
I0601 18:37:38.132989  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/scale
I0601 18:37:38.133000  6142 net.cpp:84] Creating Layer conv6_2/dw/scale
I0601 18:37:38.133006  6142 net.cpp:406] conv6_2/dw/scale <- conv6_2/dw
I0601 18:37:38.133013  6142 net.cpp:367] conv6_2/dw/scale -> conv6_2/dw (in-place)
I0601 18:37:38.133076  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/scale
I0601 18:37:38.133252  6142 net.cpp:122] Setting up conv6_2/dw/scale
I0601 18:37:38.133265  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.133270  6142 net.cpp:137] Memory required for data: 631214112
I0601 18:37:38.133280  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/ReLU
I0601 18:37:38.133289  6142 net.cpp:84] Creating Layer conv6_2/dw/ReLU
I0601 18:37:38.133296  6142 net.cpp:406] conv6_2/dw/ReLU <- conv6_2/dw
I0601 18:37:38.133302  6142 net.cpp:367] conv6_2/dw/ReLU -> conv6_2/dw (in-place)
I0601 18:37:38.134028  6142 net.cpp:122] Setting up conv6_2/dw/ReLU
I0601 18:37:38.134048  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.134054  6142 net.cpp:137] Memory required for data: 634826784
I0601 18:37:38.134059  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2
I0601 18:37:38.134073  6142 net.cpp:84] Creating Layer conv6_2/sep2
I0601 18:37:38.134079  6142 net.cpp:406] conv6_2/sep2 <- conv6_2/dw
I0601 18:37:38.134090  6142 net.cpp:380] conv6_2/sep2 -> conv6_2/sep2
I0601 18:37:38.138170  6142 net.cpp:122] Setting up conv6_2/sep2
I0601 18:37:38.138195  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.138200  6142 net.cpp:137] Memory required for data: 635428896
I0601 18:37:38.138208  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/bn
I0601 18:37:38.138218  6142 net.cpp:84] Creating Layer conv6_2/sep2/bn
I0601 18:37:38.138226  6142 net.cpp:406] conv6_2/sep2/bn <- conv6_2/sep2
I0601 18:37:38.138236  6142 net.cpp:367] conv6_2/sep2/bn -> conv6_2/sep2 (in-place)
I0601 18:37:38.138563  6142 net.cpp:122] Setting up conv6_2/sep2/bn
I0601 18:37:38.138577  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.138582  6142 net.cpp:137] Memory required for data: 636031008
I0601 18:37:38.138594  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/scale
I0601 18:37:38.138603  6142 net.cpp:84] Creating Layer conv6_2/sep2/scale
I0601 18:37:38.138608  6142 net.cpp:406] conv6_2/sep2/scale <- conv6_2/sep2
I0601 18:37:38.138618  6142 net.cpp:367] conv6_2/sep2/scale -> conv6_2/sep2 (in-place)
I0601 18:37:38.138679  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/scale
I0601 18:37:38.138881  6142 net.cpp:122] Setting up conv6_2/sep2/scale
I0601 18:37:38.138896  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.138901  6142 net.cpp:137] Memory required for data: 636633120
I0601 18:37:38.138911  6142 layer_factory.cpp:63] Creating layer conv6_2/Eltwise1
I0601 18:37:38.138921  6142 net.cpp:84] Creating Layer conv6_2/Eltwise1
I0601 18:37:38.138926  6142 net.cpp:406] conv6_2/Eltwise1 <- conv6_1/sep2_conv6_1/sep2/ReLU_0_split_1
I0601 18:37:38.138933  6142 net.cpp:406] conv6_2/Eltwise1 <- conv6_2/sep2
I0601 18:37:38.138944  6142 net.cpp:380] conv6_2/Eltwise1 -> conv6_2/Eltwise1
I0601 18:37:38.138985  6142 net.cpp:122] Setting up conv6_2/Eltwise1
I0601 18:37:38.138994  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.138998  6142 net.cpp:137] Memory required for data: 637235232
I0601 18:37:38.139003  6142 layer_factory.cpp:63] Creating layer conv6_2/Eltwise/ReLU
I0601 18:37:38.139012  6142 net.cpp:84] Creating Layer conv6_2/Eltwise/ReLU
I0601 18:37:38.139017  6142 net.cpp:406] conv6_2/Eltwise/ReLU <- conv6_2/Eltwise1
I0601 18:37:38.139025  6142 net.cpp:367] conv6_2/Eltwise/ReLU -> conv6_2/Eltwise1 (in-place)
I0601 18:37:38.139775  6142 net.cpp:122] Setting up conv6_2/Eltwise/ReLU
I0601 18:37:38.139796  6142 net.cpp:129] Top shape: 8 96 14 14 (150528)
I0601 18:37:38.139801  6142 net.cpp:137] Memory required for data: 637837344
I0601 18:37:38.139807  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1
I0601 18:37:38.139822  6142 net.cpp:84] Creating Layer conv7_1/sep1
I0601 18:37:38.139828  6142 net.cpp:406] conv7_1/sep1 <- conv6_2/Eltwise1
I0601 18:37:38.139839  6142 net.cpp:380] conv7_1/sep1 -> conv7_1/sep1
I0601 18:37:38.144477  6142 net.cpp:122] Setting up conv7_1/sep1
I0601 18:37:38.144503  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.144508  6142 net.cpp:137] Memory required for data: 641450016
I0601 18:37:38.144517  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/bn
I0601 18:37:38.144531  6142 net.cpp:84] Creating Layer conv7_1/sep1/bn
I0601 18:37:38.144537  6142 net.cpp:406] conv7_1/sep1/bn <- conv7_1/sep1
I0601 18:37:38.144544  6142 net.cpp:367] conv7_1/sep1/bn -> conv7_1/sep1 (in-place)
I0601 18:37:38.144865  6142 net.cpp:122] Setting up conv7_1/sep1/bn
I0601 18:37:38.144878  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.144883  6142 net.cpp:137] Memory required for data: 645062688
I0601 18:37:38.144896  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/scale
I0601 18:37:38.144904  6142 net.cpp:84] Creating Layer conv7_1/sep1/scale
I0601 18:37:38.144910  6142 net.cpp:406] conv7_1/sep1/scale <- conv7_1/sep1
I0601 18:37:38.144917  6142 net.cpp:367] conv7_1/sep1/scale -> conv7_1/sep1 (in-place)
I0601 18:37:38.144981  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/scale
I0601 18:37:38.145162  6142 net.cpp:122] Setting up conv7_1/sep1/scale
I0601 18:37:38.145175  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.145181  6142 net.cpp:137] Memory required for data: 648675360
I0601 18:37:38.145190  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/ReLU
I0601 18:37:38.145198  6142 net.cpp:84] Creating Layer conv7_1/sep1/ReLU
I0601 18:37:38.145206  6142 net.cpp:406] conv7_1/sep1/ReLU <- conv7_1/sep1
I0601 18:37:38.145213  6142 net.cpp:367] conv7_1/sep1/ReLU -> conv7_1/sep1 (in-place)
I0601 18:37:38.146132  6142 net.cpp:122] Setting up conv7_1/sep1/ReLU
I0601 18:37:38.146155  6142 net.cpp:129] Top shape: 8 576 14 14 (903168)
I0601 18:37:38.146160  6142 net.cpp:137] Memory required for data: 652288032
I0601 18:37:38.146167  6142 layer_factory.cpp:63] Creating layer conv7_1/dw
I0601 18:37:38.146179  6142 net.cpp:84] Creating Layer conv7_1/dw
I0601 18:37:38.146185  6142 net.cpp:406] conv7_1/dw <- conv7_1/sep1
I0601 18:37:38.146194  6142 net.cpp:380] conv7_1/dw -> conv7_1/dw
I0601 18:37:38.146653  6142 net.cpp:122] Setting up conv7_1/dw
I0601 18:37:38.146672  6142 net.cpp:129] Top shape: 8 576 7 7 (225792)
I0601 18:37:38.146677  6142 net.cpp:137] Memory required for data: 653191200
I0601 18:37:38.146703  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/bn
I0601 18:37:38.146715  6142 net.cpp:84] Creating Layer conv7_1/dw/bn
I0601 18:37:38.146723  6142 net.cpp:406] conv7_1/dw/bn <- conv7_1/dw
I0601 18:37:38.146729  6142 net.cpp:367] conv7_1/dw/bn -> conv7_1/dw (in-place)
I0601 18:37:38.147045  6142 net.cpp:122] Setting up conv7_1/dw/bn
I0601 18:37:38.147070  6142 net.cpp:129] Top shape: 8 576 7 7 (225792)
I0601 18:37:38.147075  6142 net.cpp:137] Memory required for data: 654094368
I0601 18:37:38.147087  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/scale
I0601 18:37:38.147096  6142 net.cpp:84] Creating Layer conv7_1/dw/scale
I0601 18:37:38.147102  6142 net.cpp:406] conv7_1/dw/scale <- conv7_1/dw
I0601 18:37:38.147111  6142 net.cpp:367] conv7_1/dw/scale -> conv7_1/dw (in-place)
I0601 18:37:38.147174  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/scale
I0601 18:37:38.147354  6142 net.cpp:122] Setting up conv7_1/dw/scale
I0601 18:37:38.147367  6142 net.cpp:129] Top shape: 8 576 7 7 (225792)
I0601 18:37:38.147372  6142 net.cpp:137] Memory required for data: 654997536
I0601 18:37:38.147382  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/ReLU
I0601 18:37:38.147389  6142 net.cpp:84] Creating Layer conv7_1/dw/ReLU
I0601 18:37:38.147394  6142 net.cpp:406] conv7_1/dw/ReLU <- conv7_1/dw
I0601 18:37:38.147403  6142 net.cpp:367] conv7_1/dw/ReLU -> conv7_1/dw (in-place)
I0601 18:37:38.148130  6142 net.cpp:122] Setting up conv7_1/dw/ReLU
I0601 18:37:38.148149  6142 net.cpp:129] Top shape: 8 576 7 7 (225792)
I0601 18:37:38.148154  6142 net.cpp:137] Memory required for data: 655900704
I0601 18:37:38.148160  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2
I0601 18:37:38.148175  6142 net.cpp:84] Creating Layer conv7_1/sep2
I0601 18:37:38.148180  6142 net.cpp:406] conv7_1/sep2 <- conv7_1/dw
I0601 18:37:38.148190  6142 net.cpp:380] conv7_1/sep2 -> conv7_1/sep2
I0601 18:37:38.153937  6142 net.cpp:122] Setting up conv7_1/sep2
I0601 18:37:38.153962  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.153968  6142 net.cpp:137] Memory required for data: 656201760
I0601 18:37:38.153976  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/bn
I0601 18:37:38.153990  6142 net.cpp:84] Creating Layer conv7_1/sep2/bn
I0601 18:37:38.153996  6142 net.cpp:406] conv7_1/sep2/bn <- conv7_1/sep2
I0601 18:37:38.154006  6142 net.cpp:367] conv7_1/sep2/bn -> conv7_1/sep2 (in-place)
I0601 18:37:38.154327  6142 net.cpp:122] Setting up conv7_1/sep2/bn
I0601 18:37:38.154341  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.154347  6142 net.cpp:137] Memory required for data: 656502816
I0601 18:37:38.154358  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/scale
I0601 18:37:38.154369  6142 net.cpp:84] Creating Layer conv7_1/sep2/scale
I0601 18:37:38.154376  6142 net.cpp:406] conv7_1/sep2/scale <- conv7_1/sep2
I0601 18:37:38.154382  6142 net.cpp:367] conv7_1/sep2/scale -> conv7_1/sep2 (in-place)
I0601 18:37:38.154444  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/scale
I0601 18:37:38.154628  6142 net.cpp:122] Setting up conv7_1/sep2/scale
I0601 18:37:38.154640  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.154645  6142 net.cpp:137] Memory required for data: 656803872
I0601 18:37:38.154654  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/ReLU
I0601 18:37:38.154665  6142 net.cpp:84] Creating Layer conv7_1/sep2/ReLU
I0601 18:37:38.154671  6142 net.cpp:406] conv7_1/sep2/ReLU <- conv7_1/sep2
I0601 18:37:38.154678  6142 net.cpp:367] conv7_1/sep2/ReLU -> conv7_1/sep2 (in-place)
I0601 18:37:38.155618  6142 net.cpp:122] Setting up conv7_1/sep2/ReLU
I0601 18:37:38.155643  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.155648  6142 net.cpp:137] Memory required for data: 657104928
I0601 18:37:38.155654  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.155664  6142 net.cpp:84] Creating Layer conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.155670  6142 net.cpp:406] conv7_1/sep2_conv7_1/sep2/ReLU_0_split <- conv7_1/sep2
I0601 18:37:38.155700  6142 net.cpp:380] conv7_1/sep2_conv7_1/sep2/ReLU_0_split -> conv7_1/sep2_conv7_1/sep2/ReLU_0_split_0
I0601 18:37:38.155714  6142 net.cpp:380] conv7_1/sep2_conv7_1/sep2/ReLU_0_split -> conv7_1/sep2_conv7_1/sep2/ReLU_0_split_1
I0601 18:37:38.155788  6142 net.cpp:122] Setting up conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.155798  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.155805  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.155809  6142 net.cpp:137] Memory required for data: 657707040
I0601 18:37:38.155815  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1
I0601 18:37:38.155831  6142 net.cpp:84] Creating Layer conv7_2/sep1
I0601 18:37:38.155838  6142 net.cpp:406] conv7_2/sep1 <- conv7_1/sep2_conv7_1/sep2/ReLU_0_split_0
I0601 18:37:38.155845  6142 net.cpp:380] conv7_2/sep1 -> conv7_2/sep1
I0601 18:37:38.163671  6142 net.cpp:122] Setting up conv7_2/sep1
I0601 18:37:38.163697  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.163702  6142 net.cpp:137] Memory required for data: 659513376
I0601 18:37:38.163712  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/bn
I0601 18:37:38.163722  6142 net.cpp:84] Creating Layer conv7_2/sep1/bn
I0601 18:37:38.163727  6142 net.cpp:406] conv7_2/sep1/bn <- conv7_2/sep1
I0601 18:37:38.163738  6142 net.cpp:367] conv7_2/sep1/bn -> conv7_2/sep1 (in-place)
I0601 18:37:38.164047  6142 net.cpp:122] Setting up conv7_2/sep1/bn
I0601 18:37:38.164060  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.164065  6142 net.cpp:137] Memory required for data: 661319712
I0601 18:37:38.164077  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/scale
I0601 18:37:38.164086  6142 net.cpp:84] Creating Layer conv7_2/sep1/scale
I0601 18:37:38.164091  6142 net.cpp:406] conv7_2/sep1/scale <- conv7_2/sep1
I0601 18:37:38.164099  6142 net.cpp:367] conv7_2/sep1/scale -> conv7_2/sep1 (in-place)
I0601 18:37:38.164161  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/scale
I0601 18:37:38.164330  6142 net.cpp:122] Setting up conv7_2/sep1/scale
I0601 18:37:38.164341  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.164346  6142 net.cpp:137] Memory required for data: 663126048
I0601 18:37:38.164355  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/ReLU
I0601 18:37:38.164364  6142 net.cpp:84] Creating Layer conv7_2/sep1/ReLU
I0601 18:37:38.164369  6142 net.cpp:406] conv7_2/sep1/ReLU <- conv7_2/sep1
I0601 18:37:38.164381  6142 net.cpp:367] conv7_2/sep1/ReLU -> conv7_2/sep1 (in-place)
I0601 18:37:38.165868  6142 net.cpp:122] Setting up conv7_2/sep1/ReLU
I0601 18:37:38.165892  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.165897  6142 net.cpp:137] Memory required for data: 664932384
I0601 18:37:38.165904  6142 layer_factory.cpp:63] Creating layer conv7_2/dw
I0601 18:37:38.165915  6142 net.cpp:84] Creating Layer conv7_2/dw
I0601 18:37:38.165920  6142 net.cpp:406] conv7_2/dw <- conv7_2/sep1
I0601 18:37:38.165932  6142 net.cpp:380] conv7_2/dw -> conv7_2/dw
I0601 18:37:38.166666  6142 net.cpp:122] Setting up conv7_2/dw
I0601 18:37:38.166687  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.166692  6142 net.cpp:137] Memory required for data: 666738720
I0601 18:37:38.166700  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/bn
I0601 18:37:38.166710  6142 net.cpp:84] Creating Layer conv7_2/dw/bn
I0601 18:37:38.166716  6142 net.cpp:406] conv7_2/dw/bn <- conv7_2/dw
I0601 18:37:38.166726  6142 net.cpp:367] conv7_2/dw/bn -> conv7_2/dw (in-place)
I0601 18:37:38.167047  6142 net.cpp:122] Setting up conv7_2/dw/bn
I0601 18:37:38.167073  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.167078  6142 net.cpp:137] Memory required for data: 668545056
I0601 18:37:38.167089  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/scale
I0601 18:37:38.167098  6142 net.cpp:84] Creating Layer conv7_2/dw/scale
I0601 18:37:38.167104  6142 net.cpp:406] conv7_2/dw/scale <- conv7_2/dw
I0601 18:37:38.167111  6142 net.cpp:367] conv7_2/dw/scale -> conv7_2/dw (in-place)
I0601 18:37:38.167199  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/scale
I0601 18:37:38.167373  6142 net.cpp:122] Setting up conv7_2/dw/scale
I0601 18:37:38.167387  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.167392  6142 net.cpp:137] Memory required for data: 670351392
I0601 18:37:38.167402  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/ReLU
I0601 18:37:38.167412  6142 net.cpp:84] Creating Layer conv7_2/dw/ReLU
I0601 18:37:38.167418  6142 net.cpp:406] conv7_2/dw/ReLU <- conv7_2/dw
I0601 18:37:38.167425  6142 net.cpp:367] conv7_2/dw/ReLU -> conv7_2/dw (in-place)
I0601 18:37:38.168349  6142 net.cpp:122] Setting up conv7_2/dw/ReLU
I0601 18:37:38.168372  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.168380  6142 net.cpp:137] Memory required for data: 672157728
I0601 18:37:38.168386  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2
I0601 18:37:38.168398  6142 net.cpp:84] Creating Layer conv7_2/sep2
I0601 18:37:38.168404  6142 net.cpp:406] conv7_2/sep2 <- conv7_2/dw
I0601 18:37:38.168416  6142 net.cpp:380] conv7_2/sep2 -> conv7_2/sep2
I0601 18:37:38.176193  6142 net.cpp:122] Setting up conv7_2/sep2
I0601 18:37:38.176218  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.176224  6142 net.cpp:137] Memory required for data: 672458784
I0601 18:37:38.176234  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/bn
I0601 18:37:38.176244  6142 net.cpp:84] Creating Layer conv7_2/sep2/bn
I0601 18:37:38.176250  6142 net.cpp:406] conv7_2/sep2/bn <- conv7_2/sep2
I0601 18:37:38.176265  6142 net.cpp:367] conv7_2/sep2/bn -> conv7_2/sep2 (in-place)
I0601 18:37:38.176590  6142 net.cpp:122] Setting up conv7_2/sep2/bn
I0601 18:37:38.176604  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.176609  6142 net.cpp:137] Memory required for data: 672759840
I0601 18:37:38.176620  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/scale
I0601 18:37:38.176630  6142 net.cpp:84] Creating Layer conv7_2/sep2/scale
I0601 18:37:38.176636  6142 net.cpp:406] conv7_2/sep2/scale <- conv7_2/sep2
I0601 18:37:38.176643  6142 net.cpp:367] conv7_2/sep2/scale -> conv7_2/sep2 (in-place)
I0601 18:37:38.176705  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/scale
I0601 18:37:38.176889  6142 net.cpp:122] Setting up conv7_2/sep2/scale
I0601 18:37:38.176903  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.176908  6142 net.cpp:137] Memory required for data: 673060896
I0601 18:37:38.176916  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise1
I0601 18:37:38.176926  6142 net.cpp:84] Creating Layer conv7_2/Eltwise1
I0601 18:37:38.176932  6142 net.cpp:406] conv7_2/Eltwise1 <- conv7_1/sep2_conv7_1/sep2/ReLU_0_split_1
I0601 18:37:38.176939  6142 net.cpp:406] conv7_2/Eltwise1 <- conv7_2/sep2
I0601 18:37:38.176952  6142 net.cpp:380] conv7_2/Eltwise1 -> conv7_2/Eltwise1
I0601 18:37:38.176992  6142 net.cpp:122] Setting up conv7_2/Eltwise1
I0601 18:37:38.177002  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.177007  6142 net.cpp:137] Memory required for data: 673361952
I0601 18:37:38.177012  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise/ReLU
I0601 18:37:38.177021  6142 net.cpp:84] Creating Layer conv7_2/Eltwise/ReLU
I0601 18:37:38.177027  6142 net.cpp:406] conv7_2/Eltwise/ReLU <- conv7_2/Eltwise1
I0601 18:37:38.177034  6142 net.cpp:367] conv7_2/Eltwise/ReLU -> conv7_2/Eltwise1 (in-place)
I0601 18:37:38.177963  6142 net.cpp:122] Setting up conv7_2/Eltwise/ReLU
I0601 18:37:38.177986  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.177991  6142 net.cpp:137] Memory required for data: 673663008
I0601 18:37:38.177997  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.178009  6142 net.cpp:84] Creating Layer conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.178014  6142 net.cpp:406] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split <- conv7_2/Eltwise1
I0601 18:37:38.178026  6142 net.cpp:380] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split -> conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.178057  6142 net.cpp:380] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split -> conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.178133  6142 net.cpp:122] Setting up conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.178143  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.178150  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.178155  6142 net.cpp:137] Memory required for data: 674265120
I0601 18:37:38.178160  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1
I0601 18:37:38.178174  6142 net.cpp:84] Creating Layer conv7_3/sep1
I0601 18:37:38.178181  6142 net.cpp:406] conv7_3/sep1 <- conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.178190  6142 net.cpp:380] conv7_3/sep1 -> conv7_3/sep1
I0601 18:37:38.185855  6142 net.cpp:122] Setting up conv7_3/sep1
I0601 18:37:38.185881  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.185887  6142 net.cpp:137] Memory required for data: 676071456
I0601 18:37:38.185896  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/bn
I0601 18:37:38.185911  6142 net.cpp:84] Creating Layer conv7_3/sep1/bn
I0601 18:37:38.185919  6142 net.cpp:406] conv7_3/sep1/bn <- conv7_3/sep1
I0601 18:37:38.185926  6142 net.cpp:367] conv7_3/sep1/bn -> conv7_3/sep1 (in-place)
I0601 18:37:38.186245  6142 net.cpp:122] Setting up conv7_3/sep1/bn
I0601 18:37:38.186260  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.186266  6142 net.cpp:137] Memory required for data: 677877792
I0601 18:37:38.186277  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/scale
I0601 18:37:38.186287  6142 net.cpp:84] Creating Layer conv7_3/sep1/scale
I0601 18:37:38.186293  6142 net.cpp:406] conv7_3/sep1/scale <- conv7_3/sep1
I0601 18:37:38.186303  6142 net.cpp:367] conv7_3/sep1/scale -> conv7_3/sep1 (in-place)
I0601 18:37:38.186364  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/scale
I0601 18:37:38.186538  6142 net.cpp:122] Setting up conv7_3/sep1/scale
I0601 18:37:38.186553  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.186558  6142 net.cpp:137] Memory required for data: 679684128
I0601 18:37:38.186591  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/ReLU
I0601 18:37:38.186601  6142 net.cpp:84] Creating Layer conv7_3/sep1/ReLU
I0601 18:37:38.186607  6142 net.cpp:406] conv7_3/sep1/ReLU <- conv7_3/sep1
I0601 18:37:38.186615  6142 net.cpp:367] conv7_3/sep1/ReLU -> conv7_3/sep1 (in-place)
I0601 18:37:38.187561  6142 net.cpp:122] Setting up conv7_3/sep1/ReLU
I0601 18:37:38.187584  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.187590  6142 net.cpp:137] Memory required for data: 681490464
I0601 18:37:38.187597  6142 layer_factory.cpp:63] Creating layer conv7_3/dw
I0601 18:37:38.187610  6142 net.cpp:84] Creating Layer conv7_3/dw
I0601 18:37:38.187616  6142 net.cpp:406] conv7_3/dw <- conv7_3/sep1
I0601 18:37:38.187628  6142 net.cpp:380] conv7_3/dw -> conv7_3/dw
I0601 18:37:38.188349  6142 net.cpp:122] Setting up conv7_3/dw
I0601 18:37:38.188372  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.188378  6142 net.cpp:137] Memory required for data: 683296800
I0601 18:37:38.188386  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/bn
I0601 18:37:38.188395  6142 net.cpp:84] Creating Layer conv7_3/dw/bn
I0601 18:37:38.188402  6142 net.cpp:406] conv7_3/dw/bn <- conv7_3/dw
I0601 18:37:38.188413  6142 net.cpp:367] conv7_3/dw/bn -> conv7_3/dw (in-place)
I0601 18:37:38.188724  6142 net.cpp:122] Setting up conv7_3/dw/bn
I0601 18:37:38.188738  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.188743  6142 net.cpp:137] Memory required for data: 685103136
I0601 18:37:38.188755  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/scale
I0601 18:37:38.188766  6142 net.cpp:84] Creating Layer conv7_3/dw/scale
I0601 18:37:38.188771  6142 net.cpp:406] conv7_3/dw/scale <- conv7_3/dw
I0601 18:37:38.188778  6142 net.cpp:367] conv7_3/dw/scale -> conv7_3/dw (in-place)
I0601 18:37:38.188843  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/scale
I0601 18:37:38.189033  6142 net.cpp:122] Setting up conv7_3/dw/scale
I0601 18:37:38.189049  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.189054  6142 net.cpp:137] Memory required for data: 686909472
I0601 18:37:38.189064  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/ReLU
I0601 18:37:38.189075  6142 net.cpp:84] Creating Layer conv7_3/dw/ReLU
I0601 18:37:38.189081  6142 net.cpp:406] conv7_3/dw/ReLU <- conv7_3/dw
I0601 18:37:38.189090  6142 net.cpp:367] conv7_3/dw/ReLU -> conv7_3/dw (in-place)
I0601 18:37:38.190608  6142 net.cpp:122] Setting up conv7_3/dw/ReLU
I0601 18:37:38.190632  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.190639  6142 net.cpp:137] Memory required for data: 688715808
I0601 18:37:38.190644  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2
I0601 18:37:38.190659  6142 net.cpp:84] Creating Layer conv7_3/sep2
I0601 18:37:38.190665  6142 net.cpp:406] conv7_3/sep2 <- conv7_3/dw
I0601 18:37:38.190677  6142 net.cpp:380] conv7_3/sep2 -> conv7_3/sep2
I0601 18:37:38.198382  6142 net.cpp:122] Setting up conv7_3/sep2
I0601 18:37:38.198407  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.198415  6142 net.cpp:137] Memory required for data: 689016864
I0601 18:37:38.198423  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/bn
I0601 18:37:38.198436  6142 net.cpp:84] Creating Layer conv7_3/sep2/bn
I0601 18:37:38.198443  6142 net.cpp:406] conv7_3/sep2/bn <- conv7_3/sep2
I0601 18:37:38.198453  6142 net.cpp:367] conv7_3/sep2/bn -> conv7_3/sep2 (in-place)
I0601 18:37:38.198781  6142 net.cpp:122] Setting up conv7_3/sep2/bn
I0601 18:37:38.198796  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.198801  6142 net.cpp:137] Memory required for data: 689317920
I0601 18:37:38.198812  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/scale
I0601 18:37:38.198824  6142 net.cpp:84] Creating Layer conv7_3/sep2/scale
I0601 18:37:38.198830  6142 net.cpp:406] conv7_3/sep2/scale <- conv7_3/sep2
I0601 18:37:38.198838  6142 net.cpp:367] conv7_3/sep2/scale -> conv7_3/sep2 (in-place)
I0601 18:37:38.198912  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/scale
I0601 18:37:38.199126  6142 net.cpp:122] Setting up conv7_3/sep2/scale
I0601 18:37:38.199141  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.199146  6142 net.cpp:137] Memory required for data: 689618976
I0601 18:37:38.199156  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise1
I0601 18:37:38.199167  6142 net.cpp:84] Creating Layer conv7_3/Eltwise1
I0601 18:37:38.199172  6142 net.cpp:406] conv7_3/Eltwise1 <- conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.199180  6142 net.cpp:406] conv7_3/Eltwise1 <- conv7_3/sep2
I0601 18:37:38.199192  6142 net.cpp:380] conv7_3/Eltwise1 -> conv7_3/Eltwise1
I0601 18:37:38.199234  6142 net.cpp:122] Setting up conv7_3/Eltwise1
I0601 18:37:38.199244  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.199249  6142 net.cpp:137] Memory required for data: 689920032
I0601 18:37:38.199254  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise/ReLU
I0601 18:37:38.199263  6142 net.cpp:84] Creating Layer conv7_3/Eltwise/ReLU
I0601 18:37:38.199268  6142 net.cpp:406] conv7_3/Eltwise/ReLU <- conv7_3/Eltwise1
I0601 18:37:38.199276  6142 net.cpp:367] conv7_3/Eltwise/ReLU -> conv7_3/Eltwise1 (in-place)
I0601 18:37:38.200194  6142 net.cpp:122] Setting up conv7_3/Eltwise/ReLU
I0601 18:37:38.200220  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.200225  6142 net.cpp:137] Memory required for data: 690221088
I0601 18:37:38.200232  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.200242  6142 net.cpp:84] Creating Layer conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.200248  6142 net.cpp:406] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split <- conv7_3/Eltwise1
I0601 18:37:38.200260  6142 net.cpp:380] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split -> conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_0
I0601 18:37:38.200273  6142 net.cpp:380] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split -> conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_1
I0601 18:37:38.200368  6142 net.cpp:122] Setting up conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.200381  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.200387  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.200392  6142 net.cpp:137] Memory required for data: 690823200
I0601 18:37:38.200397  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1
I0601 18:37:38.200412  6142 net.cpp:84] Creating Layer conv7_4/sep1
I0601 18:37:38.200418  6142 net.cpp:406] conv7_4/sep1 <- conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_0
I0601 18:37:38.200428  6142 net.cpp:380] conv7_4/sep1 -> conv7_4/sep1
I0601 18:37:38.208246  6142 net.cpp:122] Setting up conv7_4/sep1
I0601 18:37:38.208272  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.208278  6142 net.cpp:137] Memory required for data: 692629536
I0601 18:37:38.208287  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/bn
I0601 18:37:38.208302  6142 net.cpp:84] Creating Layer conv7_4/sep1/bn
I0601 18:37:38.208308  6142 net.cpp:406] conv7_4/sep1/bn <- conv7_4/sep1
I0601 18:37:38.208319  6142 net.cpp:367] conv7_4/sep1/bn -> conv7_4/sep1 (in-place)
I0601 18:37:38.208628  6142 net.cpp:122] Setting up conv7_4/sep1/bn
I0601 18:37:38.208643  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.208648  6142 net.cpp:137] Memory required for data: 694435872
I0601 18:37:38.208659  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/scale
I0601 18:37:38.208672  6142 net.cpp:84] Creating Layer conv7_4/sep1/scale
I0601 18:37:38.208678  6142 net.cpp:406] conv7_4/sep1/scale <- conv7_4/sep1
I0601 18:37:38.208686  6142 net.cpp:367] conv7_4/sep1/scale -> conv7_4/sep1 (in-place)
I0601 18:37:38.208750  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/scale
I0601 18:37:38.208920  6142 net.cpp:122] Setting up conv7_4/sep1/scale
I0601 18:37:38.208932  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.208938  6142 net.cpp:137] Memory required for data: 696242208
I0601 18:37:38.208947  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/ReLU
I0601 18:37:38.208956  6142 net.cpp:84] Creating Layer conv7_4/sep1/ReLU
I0601 18:37:38.208962  6142 net.cpp:406] conv7_4/sep1/ReLU <- conv7_4/sep1
I0601 18:37:38.208969  6142 net.cpp:367] conv7_4/sep1/ReLU -> conv7_4/sep1 (in-place)
I0601 18:37:38.209898  6142 net.cpp:122] Setting up conv7_4/sep1/ReLU
I0601 18:37:38.209924  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.209930  6142 net.cpp:137] Memory required for data: 698048544
I0601 18:37:38.209936  6142 layer_factory.cpp:63] Creating layer conv7_4/dw
I0601 18:37:38.209947  6142 net.cpp:84] Creating Layer conv7_4/dw
I0601 18:37:38.209954  6142 net.cpp:406] conv7_4/dw <- conv7_4/sep1
I0601 18:37:38.209965  6142 net.cpp:380] conv7_4/dw -> conv7_4/dw
I0601 18:37:38.210706  6142 net.cpp:122] Setting up conv7_4/dw
I0601 18:37:38.210726  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.210732  6142 net.cpp:137] Memory required for data: 699854880
I0601 18:37:38.210741  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/bn
I0601 18:37:38.210753  6142 net.cpp:84] Creating Layer conv7_4/dw/bn
I0601 18:37:38.210760  6142 net.cpp:406] conv7_4/dw/bn <- conv7_4/dw
I0601 18:37:38.210768  6142 net.cpp:367] conv7_4/dw/bn -> conv7_4/dw (in-place)
I0601 18:37:38.211094  6142 net.cpp:122] Setting up conv7_4/dw/bn
I0601 18:37:38.211110  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.211115  6142 net.cpp:137] Memory required for data: 701661216
I0601 18:37:38.211128  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/scale
I0601 18:37:38.211138  6142 net.cpp:84] Creating Layer conv7_4/dw/scale
I0601 18:37:38.211144  6142 net.cpp:406] conv7_4/dw/scale <- conv7_4/dw
I0601 18:37:38.211154  6142 net.cpp:367] conv7_4/dw/scale -> conv7_4/dw (in-place)
I0601 18:37:38.211215  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/scale
I0601 18:37:38.211385  6142 net.cpp:122] Setting up conv7_4/dw/scale
I0601 18:37:38.211419  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.211426  6142 net.cpp:137] Memory required for data: 703467552
I0601 18:37:38.211436  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/ReLU
I0601 18:37:38.211446  6142 net.cpp:84] Creating Layer conv7_4/dw/ReLU
I0601 18:37:38.211452  6142 net.cpp:406] conv7_4/dw/ReLU <- conv7_4/dw
I0601 18:37:38.211458  6142 net.cpp:367] conv7_4/dw/ReLU -> conv7_4/dw (in-place)
I0601 18:37:38.212394  6142 net.cpp:122] Setting up conv7_4/dw/ReLU
I0601 18:37:38.212419  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.212424  6142 net.cpp:137] Memory required for data: 705273888
I0601 18:37:38.212430  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2
I0601 18:37:38.212445  6142 net.cpp:84] Creating Layer conv7_4/sep2
I0601 18:37:38.212452  6142 net.cpp:406] conv7_4/sep2 <- conv7_4/dw
I0601 18:37:38.212464  6142 net.cpp:380] conv7_4/sep2 -> conv7_4/sep2
I0601 18:37:38.221441  6142 net.cpp:122] Setting up conv7_4/sep2
I0601 18:37:38.221467  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.221473  6142 net.cpp:137] Memory required for data: 705574944
I0601 18:37:38.221482  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/bn
I0601 18:37:38.221495  6142 net.cpp:84] Creating Layer conv7_4/sep2/bn
I0601 18:37:38.221503  6142 net.cpp:406] conv7_4/sep2/bn <- conv7_4/sep2
I0601 18:37:38.221515  6142 net.cpp:367] conv7_4/sep2/bn -> conv7_4/sep2 (in-place)
I0601 18:37:38.221846  6142 net.cpp:122] Setting up conv7_4/sep2/bn
I0601 18:37:38.221861  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.221866  6142 net.cpp:137] Memory required for data: 705876000
I0601 18:37:38.221879  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/scale
I0601 18:37:38.221889  6142 net.cpp:84] Creating Layer conv7_4/sep2/scale
I0601 18:37:38.221894  6142 net.cpp:406] conv7_4/sep2/scale <- conv7_4/sep2
I0601 18:37:38.221904  6142 net.cpp:367] conv7_4/sep2/scale -> conv7_4/sep2 (in-place)
I0601 18:37:38.221974  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/scale
I0601 18:37:38.222168  6142 net.cpp:122] Setting up conv7_4/sep2/scale
I0601 18:37:38.222182  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.222187  6142 net.cpp:137] Memory required for data: 706177056
I0601 18:37:38.222196  6142 layer_factory.cpp:63] Creating layer conv7_4/Eltwise1
I0601 18:37:38.222208  6142 net.cpp:84] Creating Layer conv7_4/Eltwise1
I0601 18:37:38.222214  6142 net.cpp:406] conv7_4/Eltwise1 <- conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_1
I0601 18:37:38.222223  6142 net.cpp:406] conv7_4/Eltwise1 <- conv7_4/sep2
I0601 18:37:38.222230  6142 net.cpp:380] conv7_4/Eltwise1 -> conv7_4/Eltwise1
I0601 18:37:38.222271  6142 net.cpp:122] Setting up conv7_4/Eltwise1
I0601 18:37:38.222281  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.222286  6142 net.cpp:137] Memory required for data: 706478112
I0601 18:37:38.222291  6142 layer_factory.cpp:63] Creating layer conv7_4/Eltwise/ReLU
I0601 18:37:38.222299  6142 net.cpp:84] Creating Layer conv7_4/Eltwise/ReLU
I0601 18:37:38.222306  6142 net.cpp:406] conv7_4/Eltwise/ReLU <- conv7_4/Eltwise1
I0601 18:37:38.222316  6142 net.cpp:367] conv7_4/Eltwise/ReLU -> conv7_4/Eltwise1 (in-place)
I0601 18:37:38.223256  6142 net.cpp:122] Setting up conv7_4/Eltwise/ReLU
I0601 18:37:38.223280  6142 net.cpp:129] Top shape: 8 192 7 7 (75264)
I0601 18:37:38.223286  6142 net.cpp:137] Memory required for data: 706779168
I0601 18:37:38.223292  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1
I0601 18:37:38.223307  6142 net.cpp:84] Creating Layer conv8_1/sep1
I0601 18:37:38.223315  6142 net.cpp:406] conv8_1/sep1 <- conv7_4/Eltwise1
I0601 18:37:38.223327  6142 net.cpp:380] conv8_1/sep1 -> conv8_1/sep1
I0601 18:37:38.230996  6142 net.cpp:122] Setting up conv8_1/sep1
I0601 18:37:38.231021  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.231027  6142 net.cpp:137] Memory required for data: 708585504
I0601 18:37:38.231036  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/bn
I0601 18:37:38.231081  6142 net.cpp:84] Creating Layer conv8_1/sep1/bn
I0601 18:37:38.231091  6142 net.cpp:406] conv8_1/sep1/bn <- conv8_1/sep1
I0601 18:37:38.231101  6142 net.cpp:367] conv8_1/sep1/bn -> conv8_1/sep1 (in-place)
I0601 18:37:38.231415  6142 net.cpp:122] Setting up conv8_1/sep1/bn
I0601 18:37:38.231431  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.231436  6142 net.cpp:137] Memory required for data: 710391840
I0601 18:37:38.231448  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/scale
I0601 18:37:38.231457  6142 net.cpp:84] Creating Layer conv8_1/sep1/scale
I0601 18:37:38.231463  6142 net.cpp:406] conv8_1/sep1/scale <- conv8_1/sep1
I0601 18:37:38.231473  6142 net.cpp:367] conv8_1/sep1/scale -> conv8_1/sep1 (in-place)
I0601 18:37:38.231534  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/scale
I0601 18:37:38.231703  6142 net.cpp:122] Setting up conv8_1/sep1/scale
I0601 18:37:38.231719  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.231724  6142 net.cpp:137] Memory required for data: 712198176
I0601 18:37:38.231734  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/ReLU
I0601 18:37:38.231742  6142 net.cpp:84] Creating Layer conv8_1/sep1/ReLU
I0601 18:37:38.231748  6142 net.cpp:406] conv8_1/sep1/ReLU <- conv8_1/sep1
I0601 18:37:38.231756  6142 net.cpp:367] conv8_1/sep1/ReLU -> conv8_1/sep1 (in-place)
I0601 18:37:38.232684  6142 net.cpp:122] Setting up conv8_1/sep1/ReLU
I0601 18:37:38.232708  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.232714  6142 net.cpp:137] Memory required for data: 714004512
I0601 18:37:38.232720  6142 layer_factory.cpp:63] Creating layer conv8_1/dw
I0601 18:37:38.232733  6142 net.cpp:84] Creating Layer conv8_1/dw
I0601 18:37:38.232740  6142 net.cpp:406] conv8_1/dw <- conv8_1/sep1
I0601 18:37:38.232753  6142 net.cpp:380] conv8_1/dw -> conv8_1/dw
I0601 18:37:38.233139  6142 net.cpp:122] Setting up conv8_1/dw
I0601 18:37:38.233157  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.233162  6142 net.cpp:137] Memory required for data: 715810848
I0601 18:37:38.233171  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/bn
I0601 18:37:38.233183  6142 net.cpp:84] Creating Layer conv8_1/dw/bn
I0601 18:37:38.233191  6142 net.cpp:406] conv8_1/dw/bn <- conv8_1/dw
I0601 18:37:38.233198  6142 net.cpp:367] conv8_1/dw/bn -> conv8_1/dw (in-place)
I0601 18:37:38.233525  6142 net.cpp:122] Setting up conv8_1/dw/bn
I0601 18:37:38.233539  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.233544  6142 net.cpp:137] Memory required for data: 717617184
I0601 18:37:38.233556  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/scale
I0601 18:37:38.233566  6142 net.cpp:84] Creating Layer conv8_1/dw/scale
I0601 18:37:38.233572  6142 net.cpp:406] conv8_1/dw/scale <- conv8_1/dw
I0601 18:37:38.233579  6142 net.cpp:367] conv8_1/dw/scale -> conv8_1/dw (in-place)
I0601 18:37:38.233644  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/scale
I0601 18:37:38.233821  6142 net.cpp:122] Setting up conv8_1/dw/scale
I0601 18:37:38.233835  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.233840  6142 net.cpp:137] Memory required for data: 719423520
I0601 18:37:38.233850  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/ReLU
I0601 18:37:38.233860  6142 net.cpp:84] Creating Layer conv8_1/dw/ReLU
I0601 18:37:38.233866  6142 net.cpp:406] conv8_1/dw/ReLU <- conv8_1/dw
I0601 18:37:38.233875  6142 net.cpp:367] conv8_1/dw/ReLU -> conv8_1/dw (in-place)
I0601 18:37:38.234814  6142 net.cpp:122] Setting up conv8_1/dw/ReLU
I0601 18:37:38.234841  6142 net.cpp:129] Top shape: 8 1152 7 7 (451584)
I0601 18:37:38.234846  6142 net.cpp:137] Memory required for data: 721229856
I0601 18:37:38.234853  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2
I0601 18:37:38.234867  6142 net.cpp:84] Creating Layer conv8_1/sep2
I0601 18:37:38.234874  6142 net.cpp:406] conv8_1/sep2 <- conv8_1/dw
I0601 18:37:38.234884  6142 net.cpp:380] conv8_1/sep2 -> conv8_1/sep2
I0601 18:37:38.246199  6142 net.cpp:122] Setting up conv8_1/sep2
I0601 18:37:38.246224  6142 net.cpp:129] Top shape: 8 320 7 7 (125440)
I0601 18:37:38.246253  6142 net.cpp:137] Memory required for data: 721731616
I0601 18:37:38.246264  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/bn
I0601 18:37:38.246279  6142 net.cpp:84] Creating Layer conv8_1/sep2/bn
I0601 18:37:38.246286  6142 net.cpp:406] conv8_1/sep2/bn <- conv8_1/sep2
I0601 18:37:38.246295  6142 net.cpp:367] conv8_1/sep2/bn -> conv8_1/sep2 (in-place)
I0601 18:37:38.246621  6142 net.cpp:122] Setting up conv8_1/sep2/bn
I0601 18:37:38.246636  6142 net.cpp:129] Top shape: 8 320 7 7 (125440)
I0601 18:37:38.246641  6142 net.cpp:137] Memory required for data: 722233376
I0601 18:37:38.246654  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/scale
I0601 18:37:38.246663  6142 net.cpp:84] Creating Layer conv8_1/sep2/scale
I0601 18:37:38.246670  6142 net.cpp:406] conv8_1/sep2/scale <- conv8_1/sep2
I0601 18:37:38.246676  6142 net.cpp:367] conv8_1/sep2/scale -> conv8_1/sep2 (in-place)
I0601 18:37:38.246742  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/scale
I0601 18:37:38.246925  6142 net.cpp:122] Setting up conv8_1/sep2/scale
I0601 18:37:38.246939  6142 net.cpp:129] Top shape: 8 320 7 7 (125440)
I0601 18:37:38.246944  6142 net.cpp:137] Memory required for data: 722735136
I0601 18:37:38.246953  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/ReLU
I0601 18:37:38.246963  6142 net.cpp:84] Creating Layer conv8_1/sep2/ReLU
I0601 18:37:38.246968  6142 net.cpp:406] conv8_1/sep2/ReLU <- conv8_1/sep2
I0601 18:37:38.246980  6142 net.cpp:367] conv8_1/sep2/ReLU -> conv8_1/sep2 (in-place)
I0601 18:37:38.247926  6142 net.cpp:122] Setting up conv8_1/sep2/ReLU
I0601 18:37:38.247951  6142 net.cpp:129] Top shape: 8 320 7 7 (125440)
I0601 18:37:38.247956  6142 net.cpp:137] Memory required for data: 723236896
I0601 18:37:38.247962  6142 layer_factory.cpp:63] Creating layer Pooling1
I0601 18:37:38.247977  6142 net.cpp:84] Creating Layer Pooling1
I0601 18:37:38.247982  6142 net.cpp:406] Pooling1 <- conv8_1/sep2
I0601 18:37:38.247995  6142 net.cpp:380] Pooling1 -> Pooling1
I0601 18:37:38.248980  6142 net.cpp:122] Setting up Pooling1
I0601 18:37:38.249003  6142 net.cpp:129] Top shape: 8 320 1 1 (2560)
I0601 18:37:38.249008  6142 net.cpp:137] Memory required for data: 723247136
I0601 18:37:38.249014  6142 layer_factory.cpp:63] Creating layer fc1
I0601 18:37:38.249027  6142 net.cpp:84] Creating Layer fc1
I0601 18:37:38.249033  6142 net.cpp:406] fc1 <- Pooling1
I0601 18:37:38.249045  6142 net.cpp:380] fc1 -> fc1
I0601 18:37:38.249241  6142 net.cpp:122] Setting up fc1
I0601 18:37:38.249256  6142 net.cpp:129] Top shape: 8 2 (16)
I0601 18:37:38.249261  6142 net.cpp:137] Memory required for data: 723247200
I0601 18:37:38.249271  6142 layer_factory.cpp:63] Creating layer Softmax
I0601 18:37:38.249284  6142 net.cpp:84] Creating Layer Softmax
I0601 18:37:38.249289  6142 net.cpp:406] Softmax <- fc1
I0601 18:37:38.249296  6142 net.cpp:406] Softmax <- label
I0601 18:37:38.249308  6142 net.cpp:380] Softmax -> Softmax
I0601 18:37:38.249323  6142 layer_factory.cpp:63] Creating layer Softmax
I0601 18:37:38.250406  6142 net.cpp:122] Setting up Softmax
I0601 18:37:38.250429  6142 net.cpp:129] Top shape: (1)
I0601 18:37:38.250435  6142 net.cpp:132]     with loss weight 1
I0601 18:37:38.250458  6142 net.cpp:137] Memory required for data: 723247204
I0601 18:37:38.250465  6142 net.cpp:198] Softmax needs backward computation.
I0601 18:37:38.250478  6142 net.cpp:198] fc1 needs backward computation.
I0601 18:37:38.250483  6142 net.cpp:198] Pooling1 needs backward computation.
I0601 18:37:38.250489  6142 net.cpp:198] conv8_1/sep2/ReLU needs backward computation.
I0601 18:37:38.250494  6142 net.cpp:198] conv8_1/sep2/scale needs backward computation.
I0601 18:37:38.250499  6142 net.cpp:198] conv8_1/sep2/bn needs backward computation.
I0601 18:37:38.250504  6142 net.cpp:198] conv8_1/sep2 needs backward computation.
I0601 18:37:38.250509  6142 net.cpp:198] conv8_1/dw/ReLU needs backward computation.
I0601 18:37:38.250514  6142 net.cpp:198] conv8_1/dw/scale needs backward computation.
I0601 18:37:38.250537  6142 net.cpp:198] conv8_1/dw/bn needs backward computation.
I0601 18:37:38.250543  6142 net.cpp:198] conv8_1/dw needs backward computation.
I0601 18:37:38.250548  6142 net.cpp:198] conv8_1/sep1/ReLU needs backward computation.
I0601 18:37:38.250553  6142 net.cpp:198] conv8_1/sep1/scale needs backward computation.
I0601 18:37:38.250558  6142 net.cpp:198] conv8_1/sep1/bn needs backward computation.
I0601 18:37:38.250563  6142 net.cpp:198] conv8_1/sep1 needs backward computation.
I0601 18:37:38.250569  6142 net.cpp:198] conv7_4/Eltwise/ReLU needs backward computation.
I0601 18:37:38.250574  6142 net.cpp:198] conv7_4/Eltwise1 needs backward computation.
I0601 18:37:38.250581  6142 net.cpp:198] conv7_4/sep2/scale needs backward computation.
I0601 18:37:38.250589  6142 net.cpp:198] conv7_4/sep2/bn needs backward computation.
I0601 18:37:38.250594  6142 net.cpp:198] conv7_4/sep2 needs backward computation.
I0601 18:37:38.250599  6142 net.cpp:198] conv7_4/dw/ReLU needs backward computation.
I0601 18:37:38.250604  6142 net.cpp:198] conv7_4/dw/scale needs backward computation.
I0601 18:37:38.250610  6142 net.cpp:198] conv7_4/dw/bn needs backward computation.
I0601 18:37:38.250615  6142 net.cpp:198] conv7_4/dw needs backward computation.
I0601 18:37:38.250620  6142 net.cpp:198] conv7_4/sep1/ReLU needs backward computation.
I0601 18:37:38.250627  6142 net.cpp:198] conv7_4/sep1/scale needs backward computation.
I0601 18:37:38.250631  6142 net.cpp:198] conv7_4/sep1/bn needs backward computation.
I0601 18:37:38.250636  6142 net.cpp:198] conv7_4/sep1 needs backward computation.
I0601 18:37:38.250643  6142 net.cpp:198] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split needs backward computation.
I0601 18:37:38.250648  6142 net.cpp:198] conv7_3/Eltwise/ReLU needs backward computation.
I0601 18:37:38.250654  6142 net.cpp:198] conv7_3/Eltwise1 needs backward computation.
I0601 18:37:38.250660  6142 net.cpp:198] conv7_3/sep2/scale needs backward computation.
I0601 18:37:38.250666  6142 net.cpp:198] conv7_3/sep2/bn needs backward computation.
I0601 18:37:38.250671  6142 net.cpp:198] conv7_3/sep2 needs backward computation.
I0601 18:37:38.250677  6142 net.cpp:198] conv7_3/dw/ReLU needs backward computation.
I0601 18:37:38.250682  6142 net.cpp:198] conv7_3/dw/scale needs backward computation.
I0601 18:37:38.250687  6142 net.cpp:198] conv7_3/dw/bn needs backward computation.
I0601 18:37:38.250692  6142 net.cpp:198] conv7_3/dw needs backward computation.
I0601 18:37:38.250699  6142 net.cpp:198] conv7_3/sep1/ReLU needs backward computation.
I0601 18:37:38.250705  6142 net.cpp:198] conv7_3/sep1/scale needs backward computation.
I0601 18:37:38.250710  6142 net.cpp:198] conv7_3/sep1/bn needs backward computation.
I0601 18:37:38.250715  6142 net.cpp:198] conv7_3/sep1 needs backward computation.
I0601 18:37:38.250720  6142 net.cpp:198] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split needs backward computation.
I0601 18:37:38.250726  6142 net.cpp:198] conv7_2/Eltwise/ReLU needs backward computation.
I0601 18:37:38.250732  6142 net.cpp:198] conv7_2/Eltwise1 needs backward computation.
I0601 18:37:38.250738  6142 net.cpp:198] conv7_2/sep2/scale needs backward computation.
I0601 18:37:38.250744  6142 net.cpp:198] conv7_2/sep2/bn needs backward computation.
I0601 18:37:38.250749  6142 net.cpp:198] conv7_2/sep2 needs backward computation.
I0601 18:37:38.250754  6142 net.cpp:198] conv7_2/dw/ReLU needs backward computation.
I0601 18:37:38.250761  6142 net.cpp:198] conv7_2/dw/scale needs backward computation.
I0601 18:37:38.250766  6142 net.cpp:198] conv7_2/dw/bn needs backward computation.
I0601 18:37:38.250771  6142 net.cpp:198] conv7_2/dw needs backward computation.
I0601 18:37:38.250777  6142 net.cpp:198] conv7_2/sep1/ReLU needs backward computation.
I0601 18:37:38.250782  6142 net.cpp:198] conv7_2/sep1/scale needs backward computation.
I0601 18:37:38.250787  6142 net.cpp:198] conv7_2/sep1/bn needs backward computation.
I0601 18:37:38.250792  6142 net.cpp:198] conv7_2/sep1 needs backward computation.
I0601 18:37:38.250797  6142 net.cpp:198] conv7_1/sep2_conv7_1/sep2/ReLU_0_split needs backward computation.
I0601 18:37:38.250814  6142 net.cpp:198] conv7_1/sep2/ReLU needs backward computation.
I0601 18:37:38.250820  6142 net.cpp:198] conv7_1/sep2/scale needs backward computation.
I0601 18:37:38.250825  6142 net.cpp:198] conv7_1/sep2/bn needs backward computation.
I0601 18:37:38.250830  6142 net.cpp:198] conv7_1/sep2 needs backward computation.
I0601 18:37:38.250836  6142 net.cpp:198] conv7_1/dw/ReLU needs backward computation.
I0601 18:37:38.250842  6142 net.cpp:198] conv7_1/dw/scale needs backward computation.
I0601 18:37:38.250847  6142 net.cpp:198] conv7_1/dw/bn needs backward computation.
I0601 18:37:38.250852  6142 net.cpp:198] conv7_1/dw needs backward computation.
I0601 18:37:38.250859  6142 net.cpp:198] conv7_1/sep1/ReLU needs backward computation.
I0601 18:37:38.250865  6142 net.cpp:198] conv7_1/sep1/scale needs backward computation.
I0601 18:37:38.250870  6142 net.cpp:198] conv7_1/sep1/bn needs backward computation.
I0601 18:37:38.250875  6142 net.cpp:198] conv7_1/sep1 needs backward computation.
I0601 18:37:38.250881  6142 net.cpp:198] conv6_2/Eltwise/ReLU needs backward computation.
I0601 18:37:38.250887  6142 net.cpp:198] conv6_2/Eltwise1 needs backward computation.
I0601 18:37:38.250893  6142 net.cpp:198] conv6_2/sep2/scale needs backward computation.
I0601 18:37:38.250900  6142 net.cpp:198] conv6_2/sep2/bn needs backward computation.
I0601 18:37:38.250905  6142 net.cpp:198] conv6_2/sep2 needs backward computation.
I0601 18:37:38.250910  6142 net.cpp:198] conv6_2/dw/ReLU needs backward computation.
I0601 18:37:38.250916  6142 net.cpp:198] conv6_2/dw/scale needs backward computation.
I0601 18:37:38.250921  6142 net.cpp:198] conv6_2/dw/bn needs backward computation.
I0601 18:37:38.250926  6142 net.cpp:198] conv6_2/dw needs backward computation.
I0601 18:37:38.250931  6142 net.cpp:198] conv6_2/sep1/ReLU needs backward computation.
I0601 18:37:38.250936  6142 net.cpp:198] conv6_2/sep1/scale needs backward computation.
I0601 18:37:38.250941  6142 net.cpp:198] conv6_2/sep1/bn needs backward computation.
I0601 18:37:38.250947  6142 net.cpp:198] conv6_2/sep1 needs backward computation.
I0601 18:37:38.250955  6142 net.cpp:198] conv6_1/sep2_conv6_1/sep2/ReLU_0_split needs backward computation.
I0601 18:37:38.250962  6142 net.cpp:198] conv6_1/sep2/ReLU needs backward computation.
I0601 18:37:38.250967  6142 net.cpp:198] conv6_1/sep2/scale needs backward computation.
I0601 18:37:38.250972  6142 net.cpp:198] conv6_1/sep2/bn needs backward computation.
I0601 18:37:38.250977  6142 net.cpp:198] conv6_1/sep2 needs backward computation.
I0601 18:37:38.250982  6142 net.cpp:198] conv6_1/dw/ReLU needs backward computation.
I0601 18:37:38.250988  6142 net.cpp:198] conv6_1/dw/scale needs backward computation.
I0601 18:37:38.250993  6142 net.cpp:198] conv6_1/dw/bn needs backward computation.
I0601 18:37:38.250998  6142 net.cpp:198] conv6_1/dw needs backward computation.
I0601 18:37:38.251004  6142 net.cpp:198] conv6_1/sep1/ReLU needs backward computation.
I0601 18:37:38.251009  6142 net.cpp:198] conv6_1/sep1/scale needs backward computation.
I0601 18:37:38.251014  6142 net.cpp:198] conv6_1/sep1/bn needs backward computation.
I0601 18:37:38.251019  6142 net.cpp:198] conv6_1/sep1 needs backward computation.
I0601 18:37:38.251025  6142 net.cpp:198] conv5_3/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251030  6142 net.cpp:198] conv5_3/Eltwise1 needs backward computation.
I0601 18:37:38.251037  6142 net.cpp:198] conv5_3/sep2/scale needs backward computation.
I0601 18:37:38.251042  6142 net.cpp:198] conv5_3/sep2/bn needs backward computation.
I0601 18:37:38.251049  6142 net.cpp:198] conv5_3/sep2 needs backward computation.
I0601 18:37:38.251063  6142 net.cpp:198] conv5_3/dw/ReLU needs backward computation.
I0601 18:37:38.251070  6142 net.cpp:198] conv5_3/dw/scale needs backward computation.
I0601 18:37:38.251075  6142 net.cpp:198] conv5_3/dw/bn needs backward computation.
I0601 18:37:38.251080  6142 net.cpp:198] conv5_3/dw needs backward computation.
I0601 18:37:38.251096  6142 net.cpp:198] conv5_3/sep1/ReLU needs backward computation.
I0601 18:37:38.251102  6142 net.cpp:198] conv5_3/sep1/scale needs backward computation.
I0601 18:37:38.251107  6142 net.cpp:198] conv5_3/sep1/bn needs backward computation.
I0601 18:37:38.251112  6142 net.cpp:198] conv5_3/sep1 needs backward computation.
I0601 18:37:38.251119  6142 net.cpp:198] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split needs backward computation.
I0601 18:37:38.251124  6142 net.cpp:198] conv5_2/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251130  6142 net.cpp:198] conv5_2/Eltwise1 needs backward computation.
I0601 18:37:38.251137  6142 net.cpp:198] conv5_2/sep2/scale needs backward computation.
I0601 18:37:38.251142  6142 net.cpp:198] conv5_2/sep2/bn needs backward computation.
I0601 18:37:38.251148  6142 net.cpp:198] conv5_2/sep2 needs backward computation.
I0601 18:37:38.251153  6142 net.cpp:198] conv5_2/dw/ReLU needs backward computation.
I0601 18:37:38.251159  6142 net.cpp:198] conv5_2/dw/scale needs backward computation.
I0601 18:37:38.251164  6142 net.cpp:198] conv5_2/dw/bn needs backward computation.
I0601 18:37:38.251169  6142 net.cpp:198] conv5_2/dw needs backward computation.
I0601 18:37:38.251175  6142 net.cpp:198] conv5_2/sep1/ReLU needs backward computation.
I0601 18:37:38.251180  6142 net.cpp:198] conv5_2/sep1/scale needs backward computation.
I0601 18:37:38.251186  6142 net.cpp:198] conv5_2/sep1/bn needs backward computation.
I0601 18:37:38.251191  6142 net.cpp:198] conv5_2/sep1 needs backward computation.
I0601 18:37:38.251197  6142 net.cpp:198] conv5_1/sep2_conv5_1/sep2/ReLU_0_split needs backward computation.
I0601 18:37:38.251202  6142 net.cpp:198] conv5_1/sep2/ReLU needs backward computation.
I0601 18:37:38.251209  6142 net.cpp:198] conv5_1/sep2/scale needs backward computation.
I0601 18:37:38.251214  6142 net.cpp:198] conv5_1/sep2/bn needs backward computation.
I0601 18:37:38.251219  6142 net.cpp:198] conv5_1/sep2 needs backward computation.
I0601 18:37:38.251224  6142 net.cpp:198] conv5_1/dw/ReLU needs backward computation.
I0601 18:37:38.251232  6142 net.cpp:198] conv5_1/dw/scale needs backward computation.
I0601 18:37:38.251237  6142 net.cpp:198] conv5_1/dw/bn needs backward computation.
I0601 18:37:38.251243  6142 net.cpp:198] conv5_1/dw needs backward computation.
I0601 18:37:38.251248  6142 net.cpp:198] conv5_1/sep1/ReLU needs backward computation.
I0601 18:37:38.251255  6142 net.cpp:198] conv5_1/sep1/scale needs backward computation.
I0601 18:37:38.251260  6142 net.cpp:198] conv5_1/sep1/bn needs backward computation.
I0601 18:37:38.251266  6142 net.cpp:198] conv5_1/sep1 needs backward computation.
I0601 18:37:38.251271  6142 net.cpp:198] conv4_3/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251276  6142 net.cpp:198] conv4_3/Eltwise1 needs backward computation.
I0601 18:37:38.251283  6142 net.cpp:198] conv4_3/sep2/scale needs backward computation.
I0601 18:37:38.251288  6142 net.cpp:198] conv4_3/sep2/bn needs backward computation.
I0601 18:37:38.251293  6142 net.cpp:198] conv4_3/sep2 needs backward computation.
I0601 18:37:38.251299  6142 net.cpp:198] conv4_3/dw/ReLU needs backward computation.
I0601 18:37:38.251304  6142 net.cpp:198] conv4_3/dw/scale needs backward computation.
I0601 18:37:38.251310  6142 net.cpp:198] conv4_3/dw/bn needs backward computation.
I0601 18:37:38.251315  6142 net.cpp:198] conv4_3/dw needs backward computation.
I0601 18:37:38.251320  6142 net.cpp:198] conv4_3/sep1/ReLU needs backward computation.
I0601 18:37:38.251327  6142 net.cpp:198] conv4_3/sep1/scale needs backward computation.
I0601 18:37:38.251332  6142 net.cpp:198] conv4_3/sep1/bn needs backward computation.
I0601 18:37:38.251338  6142 net.cpp:198] conv4_3/sep1 needs backward computation.
I0601 18:37:38.251343  6142 net.cpp:198] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split needs backward computation.
I0601 18:37:38.251348  6142 net.cpp:198] conv4_2/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251354  6142 net.cpp:198] conv4_2/Eltwise1 needs backward computation.
I0601 18:37:38.251360  6142 net.cpp:198] conv4_2/sep2/scale needs backward computation.
I0601 18:37:38.251374  6142 net.cpp:198] conv4_2/sep2/bn needs backward computation.
I0601 18:37:38.251379  6142 net.cpp:198] conv4_2/sep2 needs backward computation.
I0601 18:37:38.251385  6142 net.cpp:198] conv4_2/dw/ReLU needs backward computation.
I0601 18:37:38.251390  6142 net.cpp:198] conv4_2/dw/scale needs backward computation.
I0601 18:37:38.251395  6142 net.cpp:198] conv4_2/dw/bn needs backward computation.
I0601 18:37:38.251400  6142 net.cpp:198] conv4_2/dw needs backward computation.
I0601 18:37:38.251406  6142 net.cpp:198] conv4_2/sep1/ReLU needs backward computation.
I0601 18:37:38.251411  6142 net.cpp:198] conv4_2/sep1/scale needs backward computation.
I0601 18:37:38.251417  6142 net.cpp:198] conv4_2/sep1/bn needs backward computation.
I0601 18:37:38.251423  6142 net.cpp:198] conv4_2/sep1 needs backward computation.
I0601 18:37:38.251430  6142 net.cpp:198] conv4_1/sep2_conv4_1/sep2/ReLU_0_split needs backward computation.
I0601 18:37:38.251435  6142 net.cpp:198] conv4_1/sep2/ReLU needs backward computation.
I0601 18:37:38.251441  6142 net.cpp:198] conv4_1/sep2/scale needs backward computation.
I0601 18:37:38.251447  6142 net.cpp:198] conv4_1/sep2/bn needs backward computation.
I0601 18:37:38.251452  6142 net.cpp:198] conv4_1/sep2 needs backward computation.
I0601 18:37:38.251458  6142 net.cpp:198] conv4_1/dw/ReLU needs backward computation.
I0601 18:37:38.251463  6142 net.cpp:198] conv4_1/dw/scale needs backward computation.
I0601 18:37:38.251468  6142 net.cpp:198] conv4_1/dw/bn needs backward computation.
I0601 18:37:38.251473  6142 net.cpp:198] conv4_1/dw needs backward computation.
I0601 18:37:38.251479  6142 net.cpp:198] conv4_1/sep1/ReLU needs backward computation.
I0601 18:37:38.251484  6142 net.cpp:198] conv4_1/sep1/scale needs backward computation.
I0601 18:37:38.251490  6142 net.cpp:198] conv4_1/sep1/bn needs backward computation.
I0601 18:37:38.251495  6142 net.cpp:198] conv4_1/sep1 needs backward computation.
I0601 18:37:38.251502  6142 net.cpp:198] conv3_3/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251507  6142 net.cpp:198] conv3_3/Eltwise1 needs backward computation.
I0601 18:37:38.251513  6142 net.cpp:198] conv3_3/sep2/scale needs backward computation.
I0601 18:37:38.251519  6142 net.cpp:198] conv3_3/sep2/bn needs backward computation.
I0601 18:37:38.251524  6142 net.cpp:198] conv3_3/sep2 needs backward computation.
I0601 18:37:38.251530  6142 net.cpp:198] conv3_3/dw/ReLU needs backward computation.
I0601 18:37:38.251535  6142 net.cpp:198] conv3_3/dw/scale needs backward computation.
I0601 18:37:38.251541  6142 net.cpp:198] conv3_3/dw/bn needs backward computation.
I0601 18:37:38.251546  6142 net.cpp:198] conv3_3/dw needs backward computation.
I0601 18:37:38.251551  6142 net.cpp:198] conv3_3/sep1/ReLU needs backward computation.
I0601 18:37:38.251557  6142 net.cpp:198] conv3_3/sep1/scale needs backward computation.
I0601 18:37:38.251562  6142 net.cpp:198] conv3_3/sep1/bn needs backward computation.
I0601 18:37:38.251567  6142 net.cpp:198] conv3_3/sep1 needs backward computation.
I0601 18:37:38.251574  6142 net.cpp:198] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split needs backward computation.
I0601 18:37:38.251581  6142 net.cpp:198] conv3_2/Eltwise/ReLU needs backward computation.
I0601 18:37:38.251587  6142 net.cpp:198] conv3_2/Eltwise1 needs backward computation.
I0601 18:37:38.251593  6142 net.cpp:198] conv3_2/sep2/scale needs backward computation.
I0601 18:37:38.251600  6142 net.cpp:198] conv3_2/sep2/bn needs backward computation.
I0601 18:37:38.251605  6142 net.cpp:198] conv3_2/sep2 needs backward computation.
I0601 18:37:38.251610  6142 net.cpp:198] conv3_2/dw/ReLU needs backward computation.
I0601 18:37:38.251616  6142 net.cpp:198] conv3_2/dw/scale needs backward computation.
I0601 18:37:38.251621  6142 net.cpp:198] conv3_2/dw/bn needs backward computation.
I0601 18:37:38.251626  6142 net.cpp:198] conv3_2/dw needs backward computation.
I0601 18:37:38.251631  6142 net.cpp:198] conv3_2/sep1/ReLU needs backward computation.
I0601 18:37:38.251644  6142 net.cpp:198] conv3_2/sep1/scale needs backward computation.
I0601 18:37:38.251650  6142 net.cpp:198] conv3_2/sep1/bn needs backward computation.
I0601 18:37:38.251655  6142 net.cpp:198] conv3_2/sep1 needs backward computation.
I0601 18:37:38.251662  6142 net.cpp:198] conv3_1/sep2_conv3_1/sep2/ReLU_0_split needs backward computation.
I0601 18:37:38.251667  6142 net.cpp:198] conv3_1/sep2/ReLU needs backward computation.
I0601 18:37:38.251673  6142 net.cpp:198] conv3_1/sep2/scale needs backward computation.
I0601 18:37:38.251678  6142 net.cpp:198] conv3_1/sep2/bn needs backward computation.
I0601 18:37:38.251684  6142 net.cpp:198] conv3_1/sep2 needs backward computation.
I0601 18:37:38.251689  6142 net.cpp:198] conv3_1/dw/ReLU needs backward computation.
I0601 18:37:38.251695  6142 net.cpp:198] conv3_1/dw/scale needs backward computation.
I0601 18:37:38.251700  6142 net.cpp:198] conv3_1/dw/bn needs backward computation.
I0601 18:37:38.251705  6142 net.cpp:198] conv3_1/dw needs backward computation.
I0601 18:37:38.251711  6142 net.cpp:198] conv3_1/sep1/ReLU needs backward computation.
I0601 18:37:38.251716  6142 net.cpp:198] conv3_1/sep1/scale needs backward computation.
I0601 18:37:38.251722  6142 net.cpp:198] conv3_1/sep1/bn needs backward computation.
I0601 18:37:38.251727  6142 net.cpp:198] conv3_1/sep1 needs backward computation.
I0601 18:37:38.251734  6142 net.cpp:198] conv2_1/sep/ReLU needs backward computation.
I0601 18:37:38.251739  6142 net.cpp:198] conv2_1/sep/scale needs backward computation.
I0601 18:37:38.251744  6142 net.cpp:198] conv2_1/sep/bn needs backward computation.
I0601 18:37:38.251750  6142 net.cpp:198] conv2_1/sep needs backward computation.
I0601 18:37:38.251755  6142 net.cpp:198] conv2_1/dw/ReLU needs backward computation.
I0601 18:37:38.251761  6142 net.cpp:198] conv2_1/dw/scale needs backward computation.
I0601 18:37:38.251766  6142 net.cpp:198] conv2_1/dw/bn needs backward computation.
I0601 18:37:38.251771  6142 net.cpp:198] conv2_1/dw needs backward computation.
I0601 18:37:38.251777  6142 net.cpp:198] conv1/ReLU needs backward computation.
I0601 18:37:38.251783  6142 net.cpp:198] conv1/scale needs backward computation.
I0601 18:37:38.251788  6142 net.cpp:198] conv1/bn needs backward computation.
I0601 18:37:38.251793  6142 net.cpp:198] conv1 needs backward computation.
I0601 18:37:38.251801  6142 net.cpp:200] data does not need backward computation.
I0601 18:37:38.251806  6142 net.cpp:242] This network produces output Softmax
I0601 18:37:38.251967  6142 net.cpp:255] Network initialization done.
I0601 18:37:38.254453  6142 solver.cpp:172] Creating test net (#0) specified by test_net file: modeldef/MnasNet/test.prototxt
I0601 18:37:38.255537  6142 net.cpp:51] Initializing net from parameters: 
name: "MnasNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    scale: 0.00390625
    mirror: false
    crop_size: 224
  }
  data_param {
    source: "lmdb/val_lmdb"
    batch_size: 10
    backend: LMDB
  }
  image_data_param {
    shuffle: false
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1/scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1/ReLU"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv1"
  top: "conv2_1/dw"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/dw/scale"
  type: "Scale"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv2_1/dw"
  top: "conv2_1/dw"
}
layer {
  name: "conv2_1/sep"
  type: "Convolution"
  bottom: "conv2_1/dw"
  top: "conv2_1/sep"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv2_1/sep/bn"
  type: "BatchNorm"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/sep/scale"
  type: "Scale"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/sep/ReLU"
  type: "ReLU"
  bottom: "conv2_1/sep"
  top: "conv2_1/sep"
}
layer {
  name: "conv3_1/sep1"
  type: "Convolution"
  bottom: "conv2_1/sep"
  top: "conv3_1/sep1"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/sep1/scale"
  type: "Scale"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_1/sep1"
  top: "conv3_1/sep1"
}
layer {
  name: "conv3_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_1/sep1"
  top: "conv3_1/dw"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/dw/scale"
  type: "Scale"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_1/dw"
  top: "conv3_1/dw"
}
layer {
  name: "conv3_1/sep2"
  type: "Convolution"
  bottom: "conv3_1/dw"
  top: "conv3_1/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/sep2/scale"
  type: "Scale"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv3_1/sep2"
  top: "conv3_1/sep2"
}
layer {
  name: "conv3_2/sep1"
  type: "Convolution"
  bottom: "conv3_1/sep2"
  top: "conv3_2/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/sep1/scale"
  type: "Scale"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_2/sep1"
  top: "conv3_2/sep1"
}
layer {
  name: "conv3_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_2/sep1"
  top: "conv3_2/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/dw/scale"
  type: "Scale"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_2/dw"
  top: "conv3_2/dw"
}
layer {
  name: "conv3_2/sep2"
  type: "Convolution"
  bottom: "conv3_2/dw"
  top: "conv3_2/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_2/sep2"
  top: "conv3_2/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/sep2/scale"
  type: "Scale"
  bottom: "conv3_2/sep2"
  top: "conv3_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv3_1/sep2"
  bottom: "conv3_2/sep2"
  top: "conv3_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv3_2/Eltwise1"
  top: "conv3_2/Eltwise1"
}
layer {
  name: "conv3_3/sep1"
  type: "Convolution"
  bottom: "conv3_2/Eltwise1"
  top: "conv3_3/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/sep1/scale"
  type: "Scale"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv3_3/sep1"
  top: "conv3_3/sep1"
}
layer {
  name: "conv3_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv3_3/sep1"
  top: "conv3_3/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/dw/scale"
  type: "Scale"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv3_3/dw"
  top: "conv3_3/dw"
}
layer {
  name: "conv3_3/sep2"
  type: "Convolution"
  bottom: "conv3_3/dw"
  top: "conv3_3/sep2"
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv3_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv3_3/sep2"
  top: "conv3_3/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_3/sep2/scale"
  type: "Scale"
  bottom: "conv3_3/sep2"
  top: "conv3_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv3_2/Eltwise1"
  bottom: "conv3_3/sep2"
  top: "conv3_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv3_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv3_3/Eltwise1"
  top: "conv3_3/Eltwise1"
}
layer {
  name: "conv4_1/sep1"
  type: "Convolution"
  bottom: "conv3_3/Eltwise1"
  top: "conv4_1/sep1"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/sep1/scale"
  type: "Scale"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_1/sep1"
  top: "conv4_1/sep1"
}
layer {
  name: "conv4_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_1/sep1"
  top: "conv4_1/dw"
  convolution_param {
    num_output: 72
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/dw/scale"
  type: "Scale"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_1/dw"
  top: "conv4_1/dw"
}
layer {
  name: "conv4_1/sep2"
  type: "Convolution"
  bottom: "conv4_1/dw"
  top: "conv4_1/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/sep2/scale"
  type: "Scale"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv4_1/sep2"
  top: "conv4_1/sep2"
}
layer {
  name: "conv4_2/sep1"
  type: "Convolution"
  bottom: "conv4_1/sep2"
  top: "conv4_2/sep1"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/sep1/scale"
  type: "Scale"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_2/sep1"
  top: "conv4_2/sep1"
}
layer {
  name: "conv4_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_2/sep1"
  top: "conv4_2/dw"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/dw/scale"
  type: "Scale"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_2/dw"
  top: "conv4_2/dw"
}
layer {
  name: "conv4_2/sep2"
  type: "Convolution"
  bottom: "conv4_2/dw"
  top: "conv4_2/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_2/sep2"
  top: "conv4_2/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_2/sep2/scale"
  type: "Scale"
  bottom: "conv4_2/sep2"
  top: "conv4_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv4_1/sep2"
  bottom: "conv4_2/sep2"
  top: "conv4_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv4_2/Eltwise1"
  top: "conv4_2/Eltwise1"
}
layer {
  name: "conv4_3/sep1"
  type: "Convolution"
  bottom: "conv4_2/Eltwise1"
  top: "conv4_3/sep1"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/sep1/scale"
  type: "Scale"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv4_3/sep1"
  top: "conv4_3/sep1"
}
layer {
  name: "conv4_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv4_3/sep1"
  top: "conv4_3/dw"
  convolution_param {
    num_output: 120
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/dw/scale"
  type: "Scale"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv4_3/dw"
  top: "conv4_3/dw"
}
layer {
  name: "conv4_3/sep2"
  type: "Convolution"
  bottom: "conv4_3/dw"
  top: "conv4_3/sep2"
  convolution_param {
    num_output: 40
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv4_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv4_3/sep2"
  top: "conv4_3/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_3/sep2/scale"
  type: "Scale"
  bottom: "conv4_3/sep2"
  top: "conv4_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv4_2/Eltwise1"
  bottom: "conv4_3/sep2"
  top: "conv4_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv4_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv4_3/Eltwise1"
  top: "conv4_3/Eltwise1"
}
layer {
  name: "conv5_1/sep1"
  type: "Convolution"
  bottom: "conv4_3/Eltwise1"
  top: "conv5_1/sep1"
  convolution_param {
    num_output: 240
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/sep1/scale"
  type: "Scale"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_1/sep1"
  top: "conv5_1/sep1"
}
layer {
  name: "conv5_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_1/sep1"
  top: "conv5_1/dw"
  convolution_param {
    num_output: 240
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/dw/scale"
  type: "Scale"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_1/dw"
  top: "conv5_1/dw"
}
layer {
  name: "conv5_1/sep2"
  type: "Convolution"
  bottom: "conv5_1/dw"
  top: "conv5_1/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_1/sep2/scale"
  type: "Scale"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv5_1/sep2"
  top: "conv5_1/sep2"
}
layer {
  name: "conv5_2/sep1"
  type: "Convolution"
  bottom: "conv5_1/sep2"
  top: "conv5_2/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/sep1/scale"
  type: "Scale"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_2/sep1"
  top: "conv5_2/sep1"
}
layer {
  name: "conv5_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_2/sep1"
  top: "conv5_2/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/dw/scale"
  type: "Scale"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_2/dw"
  top: "conv5_2/dw"
}
layer {
  name: "conv5_2/sep2"
  type: "Convolution"
  bottom: "conv5_2/dw"
  top: "conv5_2/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_2/sep2"
  top: "conv5_2/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_2/sep2/scale"
  type: "Scale"
  bottom: "conv5_2/sep2"
  top: "conv5_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv5_1/sep2"
  bottom: "conv5_2/sep2"
  top: "conv5_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv5_2/Eltwise1"
  top: "conv5_2/Eltwise1"
}
layer {
  name: "conv5_3/sep1"
  type: "Convolution"
  bottom: "conv5_2/Eltwise1"
  top: "conv5_3/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/sep1/scale"
  type: "Scale"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv5_3/sep1"
  top: "conv5_3/sep1"
}
layer {
  name: "conv5_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv5_3/sep1"
  top: "conv5_3/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/dw/bn"
  type: "BatchNorm"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/dw/scale"
  type: "Scale"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/dw/ReLU"
  type: "ReLU"
  bottom: "conv5_3/dw"
  top: "conv5_3/dw"
}
layer {
  name: "conv5_3/sep2"
  type: "Convolution"
  bottom: "conv5_3/dw"
  top: "conv5_3/sep2"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv5_3/sep2/bn"
  type: "BatchNorm"
  bottom: "conv5_3/sep2"
  top: "conv5_3/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv5_3/sep2/scale"
  type: "Scale"
  bottom: "conv5_3/sep2"
  top: "conv5_3/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv5_3/Eltwise1"
  type: "Eltwise"
  bottom: "conv5_2/Eltwise1"
  bottom: "conv5_3/sep2"
  top: "conv5_3/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv5_3/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv5_3/Eltwise1"
  top: "conv5_3/Eltwise1"
}
layer {
  name: "conv6_1/sep1"
  type: "Convolution"
  bottom: "conv5_3/Eltwise1"
  top: "conv6_1/sep1"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_1/sep1/scale"
  type: "Scale"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv6_1/sep1"
  top: "conv6_1/sep1"
}
layer {
  name: "conv6_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv6_1/sep1"
  top: "conv6_1/dw"
  convolution_param {
    num_output: 480
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_1/dw/scale"
  type: "Scale"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv6_1/dw"
  top: "conv6_1/dw"
}
layer {
  name: "conv6_1/sep2"
  type: "Convolution"
  bottom: "conv6_1/dw"
  top: "conv6_1/sep2"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_1/sep2/scale"
  type: "Scale"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv6_1/sep2"
  top: "conv6_1/sep2"
}
layer {
  name: "conv6_2/sep1"
  type: "Convolution"
  bottom: "conv6_1/sep2"
  top: "conv6_2/sep1"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_2/sep1/scale"
  type: "Scale"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv6_2/sep1"
  top: "conv6_2/sep1"
}
layer {
  name: "conv6_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv6_2/sep1"
  top: "conv6_2/dw"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_2/dw/scale"
  type: "Scale"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv6_2/dw"
  top: "conv6_2/dw"
}
layer {
  name: "conv6_2/sep2"
  type: "Convolution"
  bottom: "conv6_2/dw"
  top: "conv6_2/sep2"
  convolution_param {
    num_output: 96
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv6_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv6_2/sep2"
  top: "conv6_2/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv6_2/sep2/scale"
  type: "Scale"
  bottom: "conv6_2/sep2"
  top: "conv6_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv6_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv6_1/sep2"
  bottom: "conv6_2/sep2"
  top: "conv6_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv6_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv6_2/Eltwise1"
  top: "conv6_2/Eltwise1"
}
layer {
  name: "conv7_1/sep1"
  type: "Convolution"
  bottom: "conv6_2/Eltwise1"
  top: "conv7_1/sep1"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_1/sep1/scale"
  type: "Scale"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_1/sep1"
  top: "conv7_1/sep1"
}
layer {
  name: "conv7_1/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_1/sep1"
  top: "conv7_1/dw"
  convolution_param {
    num_output: 576
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/dw/bn"
  type: "BatchNorm"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_1/dw/scale"
  type: "Scale"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/dw/ReLU"
  type: "ReLU"
  bottom: "conv7_1/dw"
  top: "conv7_1/dw"
}
layer {
  name: "conv7_1/sep2"
  type: "Convolution"
  bottom: "conv7_1/dw"
  top: "conv7_1/sep2"
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_1/sep2/bn"
  type: "BatchNorm"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_1/sep2/scale"
  type: "Scale"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_1/sep2/ReLU"
  type: "ReLU"
  bottom: "conv7_1/sep2"
  top: "conv7_1/sep2"
}
layer {
  name: "conv7_2/sep1"
  type: "Convolution"
  bottom: "conv7_1/sep2"
  top: "conv7_2/sep1"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_2/sep1/scale"
  type: "Scale"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_2/sep1"
  top: "conv7_2/sep1"
}
layer {
  name: "conv7_2/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_2/sep1"
  top: "conv7_2/dw"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/dw/bn"
  type: "BatchNorm"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_2/dw/scale"
  type: "Scale"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/dw/ReLU"
  type: "ReLU"
  bottom: "conv7_2/dw"
  top: "conv7_2/dw"
}
layer {
  name: "conv7_2/sep2"
  type: "Convolution"
  bottom: "conv7_2/dw"
  top: "conv7_2/sep2"
  convolution_param {
    num_output: 192
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_2/sep2/bn"
  type: "BatchNorm"
  bottom: "conv7_2/sep2"
  top: "conv7_2/sep2"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_2/sep2/scale"
  type: "Scale"
  bottom: "conv7_2/sep2"
  top: "conv7_2/sep2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_2/Eltwise1"
  type: "Eltwise"
  bottom: "conv7_1/sep2"
  bottom: "conv7_2/sep2"
  top: "conv7_2/Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "conv7_2/Eltwise/ReLU"
  type: "ReLU"
  bottom: "conv7_2/Eltwise1"
  top: "conv7_2/Eltwise1"
}
layer {
  name: "conv7_3/sep1"
  type: "Convolution"
  bottom: "conv7_2/Eltwise1"
  top: "conv7_3/sep1"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "conv7_3/sep1/bn"
  type: "BatchNorm"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv7_3/sep1/scale"
  type: "Scale"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv7_3/sep1/ReLU"
  type: "ReLU"
  bottom: "conv7_3/sep1"
  top: "conv7_3/sep1"
}
layer {
  name: "conv7_3/dw"
  type: "ConvolutionDepthwise"
  bottom: "conv7_3/sep1"
  top: "conv7_3/dw"
  convolution_param {
    num_output: 1152
    bias_term: false
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
I0601 18:37:38.256417  6142 layer_factory.cpp:63] Creating layer data
I0601 18:37:38.256834  6142 db_lmdb.cpp:40] Opened lmdb lmdb/val_lmdb
I0601 18:37:38.256860  6142 net.cpp:84] Creating Layer data
I0601 18:37:38.256870  6142 net.cpp:380] data -> data
I0601 18:37:38.256882  6142 net.cpp:380] data -> label
I0601 18:37:38.257351  6142 data_layer.cpp:45] output data size: 10,3,224,224
I0601 18:37:38.273814  6142 net.cpp:122] Setting up data
I0601 18:37:38.273856  6142 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0601 18:37:38.273865  6142 net.cpp:129] Top shape: 10 (10)
I0601 18:37:38.273870  6142 net.cpp:137] Memory required for data: 6021160
I0601 18:37:38.273880  6142 layer_factory.cpp:63] Creating layer conv1
I0601 18:37:38.273898  6142 net.cpp:84] Creating Layer conv1
I0601 18:37:38.273906  6142 net.cpp:406] conv1 <- data
I0601 18:37:38.273917  6142 net.cpp:380] conv1 -> conv1
I0601 18:37:38.277657  6142 net.cpp:122] Setting up conv1
I0601 18:37:38.277686  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.277693  6142 net.cpp:137] Memory required for data: 22077480
I0601 18:37:38.277705  6142 layer_factory.cpp:63] Creating layer conv1/bn
I0601 18:37:38.277721  6142 net.cpp:84] Creating Layer conv1/bn
I0601 18:37:38.277729  6142 net.cpp:406] conv1/bn <- conv1
I0601 18:37:38.277736  6142 net.cpp:367] conv1/bn -> conv1 (in-place)
I0601 18:37:38.278085  6142 net.cpp:122] Setting up conv1/bn
I0601 18:37:38.278108  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.278113  6142 net.cpp:137] Memory required for data: 38133800
I0601 18:37:38.278129  6142 layer_factory.cpp:63] Creating layer conv1/scale
I0601 18:37:38.278142  6142 net.cpp:84] Creating Layer conv1/scale
I0601 18:37:38.278148  6142 net.cpp:406] conv1/scale <- conv1
I0601 18:37:38.278156  6142 net.cpp:367] conv1/scale -> conv1 (in-place)
I0601 18:37:38.278226  6142 layer_factory.cpp:63] Creating layer conv1/scale
I0601 18:37:38.278430  6142 net.cpp:122] Setting up conv1/scale
I0601 18:37:38.278445  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.278450  6142 net.cpp:137] Memory required for data: 54190120
I0601 18:37:38.278461  6142 layer_factory.cpp:63] Creating layer conv1/ReLU
I0601 18:37:38.278471  6142 net.cpp:84] Creating Layer conv1/ReLU
I0601 18:37:38.278478  6142 net.cpp:406] conv1/ReLU <- conv1
I0601 18:37:38.278488  6142 net.cpp:367] conv1/ReLU -> conv1 (in-place)
I0601 18:37:38.279454  6142 net.cpp:122] Setting up conv1/ReLU
I0601 18:37:38.279479  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.279485  6142 net.cpp:137] Memory required for data: 70246440
I0601 18:37:38.279491  6142 layer_factory.cpp:63] Creating layer conv2_1/dw
I0601 18:37:38.279502  6142 net.cpp:84] Creating Layer conv2_1/dw
I0601 18:37:38.279508  6142 net.cpp:406] conv2_1/dw <- conv1
I0601 18:37:38.279520  6142 net.cpp:380] conv2_1/dw -> conv2_1/dw
I0601 18:37:38.279745  6142 net.cpp:122] Setting up conv2_1/dw
I0601 18:37:38.279763  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.279769  6142 net.cpp:137] Memory required for data: 86302760
I0601 18:37:38.279778  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/bn
I0601 18:37:38.279791  6142 net.cpp:84] Creating Layer conv2_1/dw/bn
I0601 18:37:38.279798  6142 net.cpp:406] conv2_1/dw/bn <- conv2_1/dw
I0601 18:37:38.279808  6142 net.cpp:367] conv2_1/dw/bn -> conv2_1/dw (in-place)
I0601 18:37:38.280139  6142 net.cpp:122] Setting up conv2_1/dw/bn
I0601 18:37:38.280153  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.280158  6142 net.cpp:137] Memory required for data: 102359080
I0601 18:37:38.280174  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/scale
I0601 18:37:38.280185  6142 net.cpp:84] Creating Layer conv2_1/dw/scale
I0601 18:37:38.280190  6142 net.cpp:406] conv2_1/dw/scale <- conv2_1/dw
I0601 18:37:38.280198  6142 net.cpp:367] conv2_1/dw/scale -> conv2_1/dw (in-place)
I0601 18:37:38.280264  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/scale
I0601 18:37:38.280511  6142 net.cpp:122] Setting up conv2_1/dw/scale
I0601 18:37:38.280527  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.280558  6142 net.cpp:137] Memory required for data: 118415400
I0601 18:37:38.280570  6142 layer_factory.cpp:63] Creating layer conv2_1/dw/ReLU
I0601 18:37:38.280586  6142 net.cpp:84] Creating Layer conv2_1/dw/ReLU
I0601 18:37:38.280591  6142 net.cpp:406] conv2_1/dw/ReLU <- conv2_1/dw
I0601 18:37:38.280599  6142 net.cpp:367] conv2_1/dw/ReLU -> conv2_1/dw (in-place)
I0601 18:37:38.282124  6142 net.cpp:122] Setting up conv2_1/dw/ReLU
I0601 18:37:38.282150  6142 net.cpp:129] Top shape: 10 32 112 112 (4014080)
I0601 18:37:38.282155  6142 net.cpp:137] Memory required for data: 134471720
I0601 18:37:38.282161  6142 layer_factory.cpp:63] Creating layer conv2_1/sep
I0601 18:37:38.282176  6142 net.cpp:84] Creating Layer conv2_1/sep
I0601 18:37:38.282182  6142 net.cpp:406] conv2_1/sep <- conv2_1/dw
I0601 18:37:38.282192  6142 net.cpp:380] conv2_1/sep -> conv2_1/sep
I0601 18:37:38.286772  6142 net.cpp:122] Setting up conv2_1/sep
I0601 18:37:38.286800  6142 net.cpp:129] Top shape: 10 16 112 112 (2007040)
I0601 18:37:38.286808  6142 net.cpp:137] Memory required for data: 142499880
I0601 18:37:38.286818  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/bn
I0601 18:37:38.286828  6142 net.cpp:84] Creating Layer conv2_1/sep/bn
I0601 18:37:38.286834  6142 net.cpp:406] conv2_1/sep/bn <- conv2_1/sep
I0601 18:37:38.286845  6142 net.cpp:367] conv2_1/sep/bn -> conv2_1/sep (in-place)
I0601 18:37:38.287277  6142 net.cpp:122] Setting up conv2_1/sep/bn
I0601 18:37:38.287294  6142 net.cpp:129] Top shape: 10 16 112 112 (2007040)
I0601 18:37:38.287300  6142 net.cpp:137] Memory required for data: 150528040
I0601 18:37:38.287312  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/scale
I0601 18:37:38.287325  6142 net.cpp:84] Creating Layer conv2_1/sep/scale
I0601 18:37:38.287331  6142 net.cpp:406] conv2_1/sep/scale <- conv2_1/sep
I0601 18:37:38.287339  6142 net.cpp:367] conv2_1/sep/scale -> conv2_1/sep (in-place)
I0601 18:37:38.287410  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/scale
I0601 18:37:38.287609  6142 net.cpp:122] Setting up conv2_1/sep/scale
I0601 18:37:38.287624  6142 net.cpp:129] Top shape: 10 16 112 112 (2007040)
I0601 18:37:38.287629  6142 net.cpp:137] Memory required for data: 158556200
I0601 18:37:38.287645  6142 layer_factory.cpp:63] Creating layer conv2_1/sep/ReLU
I0601 18:37:38.287655  6142 net.cpp:84] Creating Layer conv2_1/sep/ReLU
I0601 18:37:38.287662  6142 net.cpp:406] conv2_1/sep/ReLU <- conv2_1/sep
I0601 18:37:38.287672  6142 net.cpp:367] conv2_1/sep/ReLU -> conv2_1/sep (in-place)
I0601 18:37:38.288597  6142 net.cpp:122] Setting up conv2_1/sep/ReLU
I0601 18:37:38.288620  6142 net.cpp:129] Top shape: 10 16 112 112 (2007040)
I0601 18:37:38.288626  6142 net.cpp:137] Memory required for data: 166584360
I0601 18:37:38.288632  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1
I0601 18:37:38.288648  6142 net.cpp:84] Creating Layer conv3_1/sep1
I0601 18:37:38.288655  6142 net.cpp:406] conv3_1/sep1 <- conv2_1/sep
I0601 18:37:38.288666  6142 net.cpp:380] conv3_1/sep1 -> conv3_1/sep1
I0601 18:37:38.292222  6142 net.cpp:122] Setting up conv3_1/sep1
I0601 18:37:38.292251  6142 net.cpp:129] Top shape: 10 48 112 112 (6021120)
I0601 18:37:38.292258  6142 net.cpp:137] Memory required for data: 190668840
I0601 18:37:38.292266  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/bn
I0601 18:37:38.292279  6142 net.cpp:84] Creating Layer conv3_1/sep1/bn
I0601 18:37:38.292284  6142 net.cpp:406] conv3_1/sep1/bn <- conv3_1/sep1
I0601 18:37:38.292295  6142 net.cpp:367] conv3_1/sep1/bn -> conv3_1/sep1 (in-place)
I0601 18:37:38.292670  6142 net.cpp:122] Setting up conv3_1/sep1/bn
I0601 18:37:38.292685  6142 net.cpp:129] Top shape: 10 48 112 112 (6021120)
I0601 18:37:38.292690  6142 net.cpp:137] Memory required for data: 214753320
I0601 18:37:38.292702  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/scale
I0601 18:37:38.292711  6142 net.cpp:84] Creating Layer conv3_1/sep1/scale
I0601 18:37:38.292717  6142 net.cpp:406] conv3_1/sep1/scale <- conv3_1/sep1
I0601 18:37:38.292753  6142 net.cpp:367] conv3_1/sep1/scale -> conv3_1/sep1 (in-place)
I0601 18:37:38.292824  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/scale
I0601 18:37:38.293030  6142 net.cpp:122] Setting up conv3_1/sep1/scale
I0601 18:37:38.293045  6142 net.cpp:129] Top shape: 10 48 112 112 (6021120)
I0601 18:37:38.293051  6142 net.cpp:137] Memory required for data: 238837800
I0601 18:37:38.293061  6142 layer_factory.cpp:63] Creating layer conv3_1/sep1/ReLU
I0601 18:37:38.293073  6142 net.cpp:84] Creating Layer conv3_1/sep1/ReLU
I0601 18:37:38.293079  6142 net.cpp:406] conv3_1/sep1/ReLU <- conv3_1/sep1
I0601 18:37:38.293087  6142 net.cpp:367] conv3_1/sep1/ReLU -> conv3_1/sep1 (in-place)
I0601 18:37:38.294052  6142 net.cpp:122] Setting up conv3_1/sep1/ReLU
I0601 18:37:38.294075  6142 net.cpp:129] Top shape: 10 48 112 112 (6021120)
I0601 18:37:38.294080  6142 net.cpp:137] Memory required for data: 262922280
I0601 18:37:38.294085  6142 layer_factory.cpp:63] Creating layer conv3_1/dw
I0601 18:37:38.294100  6142 net.cpp:84] Creating Layer conv3_1/dw
I0601 18:37:38.294106  6142 net.cpp:406] conv3_1/dw <- conv3_1/sep1
I0601 18:37:38.294114  6142 net.cpp:380] conv3_1/dw -> conv3_1/dw
I0601 18:37:38.294340  6142 net.cpp:122] Setting up conv3_1/dw
I0601 18:37:38.294359  6142 net.cpp:129] Top shape: 10 48 56 56 (1505280)
I0601 18:37:38.294364  6142 net.cpp:137] Memory required for data: 268943400
I0601 18:37:38.294373  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/bn
I0601 18:37:38.294384  6142 net.cpp:84] Creating Layer conv3_1/dw/bn
I0601 18:37:38.294390  6142 net.cpp:406] conv3_1/dw/bn <- conv3_1/dw
I0601 18:37:38.294399  6142 net.cpp:367] conv3_1/dw/bn -> conv3_1/dw (in-place)
I0601 18:37:38.294762  6142 net.cpp:122] Setting up conv3_1/dw/bn
I0601 18:37:38.294776  6142 net.cpp:129] Top shape: 10 48 56 56 (1505280)
I0601 18:37:38.294781  6142 net.cpp:137] Memory required for data: 274964520
I0601 18:37:38.294793  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/scale
I0601 18:37:38.294806  6142 net.cpp:84] Creating Layer conv3_1/dw/scale
I0601 18:37:38.294811  6142 net.cpp:406] conv3_1/dw/scale <- conv3_1/dw
I0601 18:37:38.294821  6142 net.cpp:367] conv3_1/dw/scale -> conv3_1/dw (in-place)
I0601 18:37:38.294883  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/scale
I0601 18:37:38.295116  6142 net.cpp:122] Setting up conv3_1/dw/scale
I0601 18:37:38.295132  6142 net.cpp:129] Top shape: 10 48 56 56 (1505280)
I0601 18:37:38.295138  6142 net.cpp:137] Memory required for data: 280985640
I0601 18:37:38.295147  6142 layer_factory.cpp:63] Creating layer conv3_1/dw/ReLU
I0601 18:37:38.295156  6142 net.cpp:84] Creating Layer conv3_1/dw/ReLU
I0601 18:37:38.295161  6142 net.cpp:406] conv3_1/dw/ReLU <- conv3_1/dw
I0601 18:37:38.295171  6142 net.cpp:367] conv3_1/dw/ReLU -> conv3_1/dw (in-place)
I0601 18:37:38.296363  6142 net.cpp:122] Setting up conv3_1/dw/ReLU
I0601 18:37:38.296389  6142 net.cpp:129] Top shape: 10 48 56 56 (1505280)
I0601 18:37:38.296396  6142 net.cpp:137] Memory required for data: 287006760
I0601 18:37:38.296401  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2
I0601 18:37:38.296416  6142 net.cpp:84] Creating Layer conv3_1/sep2
I0601 18:37:38.296422  6142 net.cpp:406] conv3_1/sep2 <- conv3_1/dw
I0601 18:37:38.296432  6142 net.cpp:380] conv3_1/sep2 -> conv3_1/sep2
I0601 18:37:38.300278  6142 net.cpp:122] Setting up conv3_1/sep2
I0601 18:37:38.300307  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.300312  6142 net.cpp:137] Memory required for data: 290017320
I0601 18:37:38.300321  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/bn
I0601 18:37:38.300331  6142 net.cpp:84] Creating Layer conv3_1/sep2/bn
I0601 18:37:38.300338  6142 net.cpp:406] conv3_1/sep2/bn <- conv3_1/sep2
I0601 18:37:38.300348  6142 net.cpp:367] conv3_1/sep2/bn -> conv3_1/sep2 (in-place)
I0601 18:37:38.300680  6142 net.cpp:122] Setting up conv3_1/sep2/bn
I0601 18:37:38.300695  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.300700  6142 net.cpp:137] Memory required for data: 293027880
I0601 18:37:38.300745  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/scale
I0601 18:37:38.300756  6142 net.cpp:84] Creating Layer conv3_1/sep2/scale
I0601 18:37:38.300761  6142 net.cpp:406] conv3_1/sep2/scale <- conv3_1/sep2
I0601 18:37:38.300770  6142 net.cpp:367] conv3_1/sep2/scale -> conv3_1/sep2 (in-place)
I0601 18:37:38.300837  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/scale
I0601 18:37:38.301023  6142 net.cpp:122] Setting up conv3_1/sep2/scale
I0601 18:37:38.301038  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.301043  6142 net.cpp:137] Memory required for data: 296038440
I0601 18:37:38.301051  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2/ReLU
I0601 18:37:38.301060  6142 net.cpp:84] Creating Layer conv3_1/sep2/ReLU
I0601 18:37:38.301065  6142 net.cpp:406] conv3_1/sep2/ReLU <- conv3_1/sep2
I0601 18:37:38.301075  6142 net.cpp:367] conv3_1/sep2/ReLU -> conv3_1/sep2 (in-place)
I0601 18:37:38.302013  6142 net.cpp:122] Setting up conv3_1/sep2/ReLU
I0601 18:37:38.302037  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.302042  6142 net.cpp:137] Memory required for data: 299049000
I0601 18:37:38.302048  6142 layer_factory.cpp:63] Creating layer conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.302058  6142 net.cpp:84] Creating Layer conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.302064  6142 net.cpp:406] conv3_1/sep2_conv3_1/sep2/ReLU_0_split <- conv3_1/sep2
I0601 18:37:38.302075  6142 net.cpp:380] conv3_1/sep2_conv3_1/sep2/ReLU_0_split -> conv3_1/sep2_conv3_1/sep2/ReLU_0_split_0
I0601 18:37:38.302088  6142 net.cpp:380] conv3_1/sep2_conv3_1/sep2/ReLU_0_split -> conv3_1/sep2_conv3_1/sep2/ReLU_0_split_1
I0601 18:37:38.302165  6142 net.cpp:122] Setting up conv3_1/sep2_conv3_1/sep2/ReLU_0_split
I0601 18:37:38.302175  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.302181  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.302186  6142 net.cpp:137] Memory required for data: 305070120
I0601 18:37:38.302191  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1
I0601 18:37:38.302206  6142 net.cpp:84] Creating Layer conv3_2/sep1
I0601 18:37:38.302211  6142 net.cpp:406] conv3_2/sep1 <- conv3_1/sep2_conv3_1/sep2/ReLU_0_split_0
I0601 18:37:38.302222  6142 net.cpp:380] conv3_2/sep1 -> conv3_2/sep1
I0601 18:37:38.305148  6142 net.cpp:122] Setting up conv3_2/sep1
I0601 18:37:38.305173  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.305179  6142 net.cpp:137] Memory required for data: 314101800
I0601 18:37:38.305188  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/bn
I0601 18:37:38.305198  6142 net.cpp:84] Creating Layer conv3_2/sep1/bn
I0601 18:37:38.305205  6142 net.cpp:406] conv3_2/sep1/bn <- conv3_2/sep1
I0601 18:37:38.305215  6142 net.cpp:367] conv3_2/sep1/bn -> conv3_2/sep1 (in-place)
I0601 18:37:38.305559  6142 net.cpp:122] Setting up conv3_2/sep1/bn
I0601 18:37:38.305572  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.305577  6142 net.cpp:137] Memory required for data: 323133480
I0601 18:37:38.305589  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/scale
I0601 18:37:38.305598  6142 net.cpp:84] Creating Layer conv3_2/sep1/scale
I0601 18:37:38.305603  6142 net.cpp:406] conv3_2/sep1/scale <- conv3_2/sep1
I0601 18:37:38.305613  6142 net.cpp:367] conv3_2/sep1/scale -> conv3_2/sep1 (in-place)
I0601 18:37:38.305675  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/scale
I0601 18:37:38.305862  6142 net.cpp:122] Setting up conv3_2/sep1/scale
I0601 18:37:38.305876  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.305881  6142 net.cpp:137] Memory required for data: 332165160
I0601 18:37:38.305891  6142 layer_factory.cpp:63] Creating layer conv3_2/sep1/ReLU
I0601 18:37:38.305898  6142 net.cpp:84] Creating Layer conv3_2/sep1/ReLU
I0601 18:37:38.305903  6142 net.cpp:406] conv3_2/sep1/ReLU <- conv3_2/sep1
I0601 18:37:38.305913  6142 net.cpp:367] conv3_2/sep1/ReLU -> conv3_2/sep1 (in-place)
I0601 18:37:38.306855  6142 net.cpp:122] Setting up conv3_2/sep1/ReLU
I0601 18:37:38.306896  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.306903  6142 net.cpp:137] Memory required for data: 341196840
I0601 18:37:38.306910  6142 layer_factory.cpp:63] Creating layer conv3_2/dw
I0601 18:37:38.306922  6142 net.cpp:84] Creating Layer conv3_2/dw
I0601 18:37:38.306928  6142 net.cpp:406] conv3_2/dw <- conv3_2/sep1
I0601 18:37:38.306937  6142 net.cpp:380] conv3_2/dw -> conv3_2/dw
I0601 18:37:38.307180  6142 net.cpp:122] Setting up conv3_2/dw
I0601 18:37:38.307201  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.307206  6142 net.cpp:137] Memory required for data: 350228520
I0601 18:37:38.307214  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/bn
I0601 18:37:38.307224  6142 net.cpp:84] Creating Layer conv3_2/dw/bn
I0601 18:37:38.307230  6142 net.cpp:406] conv3_2/dw/bn <- conv3_2/dw
I0601 18:37:38.307240  6142 net.cpp:367] conv3_2/dw/bn -> conv3_2/dw (in-place)
I0601 18:37:38.307564  6142 net.cpp:122] Setting up conv3_2/dw/bn
I0601 18:37:38.307579  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.307583  6142 net.cpp:137] Memory required for data: 359260200
I0601 18:37:38.307595  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/scale
I0601 18:37:38.307608  6142 net.cpp:84] Creating Layer conv3_2/dw/scale
I0601 18:37:38.307615  6142 net.cpp:406] conv3_2/dw/scale <- conv3_2/dw
I0601 18:37:38.307621  6142 net.cpp:367] conv3_2/dw/scale -> conv3_2/dw (in-place)
I0601 18:37:38.307687  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/scale
I0601 18:37:38.307883  6142 net.cpp:122] Setting up conv3_2/dw/scale
I0601 18:37:38.307893  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.307898  6142 net.cpp:137] Memory required for data: 368291880
I0601 18:37:38.307907  6142 layer_factory.cpp:63] Creating layer conv3_2/dw/ReLU
I0601 18:37:38.307915  6142 net.cpp:84] Creating Layer conv3_2/dw/ReLU
I0601 18:37:38.307920  6142 net.cpp:406] conv3_2/dw/ReLU <- conv3_2/dw
I0601 18:37:38.307927  6142 net.cpp:367] conv3_2/dw/ReLU -> conv3_2/dw (in-place)
I0601 18:37:38.308853  6142 net.cpp:122] Setting up conv3_2/dw/ReLU
I0601 18:37:38.308876  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.308882  6142 net.cpp:137] Memory required for data: 377323560
I0601 18:37:38.308888  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2
I0601 18:37:38.308903  6142 net.cpp:84] Creating Layer conv3_2/sep2
I0601 18:37:38.308909  6142 net.cpp:406] conv3_2/sep2 <- conv3_2/dw
I0601 18:37:38.308920  6142 net.cpp:380] conv3_2/sep2 -> conv3_2/sep2
I0601 18:37:38.311877  6142 net.cpp:122] Setting up conv3_2/sep2
I0601 18:37:38.311902  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.311908  6142 net.cpp:137] Memory required for data: 380334120
I0601 18:37:38.311915  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/bn
I0601 18:37:38.311928  6142 net.cpp:84] Creating Layer conv3_2/sep2/bn
I0601 18:37:38.311934  6142 net.cpp:406] conv3_2/sep2/bn <- conv3_2/sep2
I0601 18:37:38.311942  6142 net.cpp:367] conv3_2/sep2/bn -> conv3_2/sep2 (in-place)
I0601 18:37:38.312283  6142 net.cpp:122] Setting up conv3_2/sep2/bn
I0601 18:37:38.312297  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.312302  6142 net.cpp:137] Memory required for data: 383344680
I0601 18:37:38.312314  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/scale
I0601 18:37:38.312322  6142 net.cpp:84] Creating Layer conv3_2/sep2/scale
I0601 18:37:38.312328  6142 net.cpp:406] conv3_2/sep2/scale <- conv3_2/sep2
I0601 18:37:38.312335  6142 net.cpp:367] conv3_2/sep2/scale -> conv3_2/sep2 (in-place)
I0601 18:37:38.312404  6142 layer_factory.cpp:63] Creating layer conv3_2/sep2/scale
I0601 18:37:38.312593  6142 net.cpp:122] Setting up conv3_2/sep2/scale
I0601 18:37:38.312608  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.312613  6142 net.cpp:137] Memory required for data: 386355240
I0601 18:37:38.312621  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise1
I0601 18:37:38.312633  6142 net.cpp:84] Creating Layer conv3_2/Eltwise1
I0601 18:37:38.312656  6142 net.cpp:406] conv3_2/Eltwise1 <- conv3_1/sep2_conv3_1/sep2/ReLU_0_split_1
I0601 18:37:38.312664  6142 net.cpp:406] conv3_2/Eltwise1 <- conv3_2/sep2
I0601 18:37:38.312672  6142 net.cpp:380] conv3_2/Eltwise1 -> conv3_2/Eltwise1
I0601 18:37:38.312716  6142 net.cpp:122] Setting up conv3_2/Eltwise1
I0601 18:37:38.312726  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.312731  6142 net.cpp:137] Memory required for data: 389365800
I0601 18:37:38.312736  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise/ReLU
I0601 18:37:38.312744  6142 net.cpp:84] Creating Layer conv3_2/Eltwise/ReLU
I0601 18:37:38.312750  6142 net.cpp:406] conv3_2/Eltwise/ReLU <- conv3_2/Eltwise1
I0601 18:37:38.312759  6142 net.cpp:367] conv3_2/Eltwise/ReLU -> conv3_2/Eltwise1 (in-place)
I0601 18:37:38.314363  6142 net.cpp:122] Setting up conv3_2/Eltwise/ReLU
I0601 18:37:38.314386  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.314391  6142 net.cpp:137] Memory required for data: 392376360
I0601 18:37:38.314397  6142 layer_factory.cpp:63] Creating layer conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.314407  6142 net.cpp:84] Creating Layer conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.314414  6142 net.cpp:406] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split <- conv3_2/Eltwise1
I0601 18:37:38.314425  6142 net.cpp:380] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split -> conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.314437  6142 net.cpp:380] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split -> conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.314517  6142 net.cpp:122] Setting up conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split
I0601 18:37:38.314529  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.314535  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.314540  6142 net.cpp:137] Memory required for data: 398397480
I0601 18:37:38.314545  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1
I0601 18:37:38.314559  6142 net.cpp:84] Creating Layer conv3_3/sep1
I0601 18:37:38.314565  6142 net.cpp:406] conv3_3/sep1 <- conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.314576  6142 net.cpp:380] conv3_3/sep1 -> conv3_3/sep1
I0601 18:37:38.317704  6142 net.cpp:122] Setting up conv3_3/sep1
I0601 18:37:38.317730  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.317736  6142 net.cpp:137] Memory required for data: 407429160
I0601 18:37:38.317745  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/bn
I0601 18:37:38.317756  6142 net.cpp:84] Creating Layer conv3_3/sep1/bn
I0601 18:37:38.317762  6142 net.cpp:406] conv3_3/sep1/bn <- conv3_3/sep1
I0601 18:37:38.317772  6142 net.cpp:367] conv3_3/sep1/bn -> conv3_3/sep1 (in-place)
I0601 18:37:38.318114  6142 net.cpp:122] Setting up conv3_3/sep1/bn
I0601 18:37:38.318128  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.318133  6142 net.cpp:137] Memory required for data: 416460840
I0601 18:37:38.318145  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/scale
I0601 18:37:38.318153  6142 net.cpp:84] Creating Layer conv3_3/sep1/scale
I0601 18:37:38.318159  6142 net.cpp:406] conv3_3/sep1/scale <- conv3_3/sep1
I0601 18:37:38.318166  6142 net.cpp:367] conv3_3/sep1/scale -> conv3_3/sep1 (in-place)
I0601 18:37:38.318233  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/scale
I0601 18:37:38.318426  6142 net.cpp:122] Setting up conv3_3/sep1/scale
I0601 18:37:38.318441  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.318446  6142 net.cpp:137] Memory required for data: 425492520
I0601 18:37:38.318456  6142 layer_factory.cpp:63] Creating layer conv3_3/sep1/ReLU
I0601 18:37:38.318464  6142 net.cpp:84] Creating Layer conv3_3/sep1/ReLU
I0601 18:37:38.318470  6142 net.cpp:406] conv3_3/sep1/ReLU <- conv3_3/sep1
I0601 18:37:38.318478  6142 net.cpp:367] conv3_3/sep1/ReLU -> conv3_3/sep1 (in-place)
I0601 18:37:38.319440  6142 net.cpp:122] Setting up conv3_3/sep1/ReLU
I0601 18:37:38.319463  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.319486  6142 net.cpp:137] Memory required for data: 434524200
I0601 18:37:38.319494  6142 layer_factory.cpp:63] Creating layer conv3_3/dw
I0601 18:37:38.319506  6142 net.cpp:84] Creating Layer conv3_3/dw
I0601 18:37:38.319512  6142 net.cpp:406] conv3_3/dw <- conv3_3/sep1
I0601 18:37:38.319521  6142 net.cpp:380] conv3_3/dw -> conv3_3/dw
I0601 18:37:38.319742  6142 net.cpp:122] Setting up conv3_3/dw
I0601 18:37:38.319761  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.319766  6142 net.cpp:137] Memory required for data: 443555880
I0601 18:37:38.319774  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/bn
I0601 18:37:38.319787  6142 net.cpp:84] Creating Layer conv3_3/dw/bn
I0601 18:37:38.319793  6142 net.cpp:406] conv3_3/dw/bn <- conv3_3/dw
I0601 18:37:38.319802  6142 net.cpp:367] conv3_3/dw/bn -> conv3_3/dw (in-place)
I0601 18:37:38.320139  6142 net.cpp:122] Setting up conv3_3/dw/bn
I0601 18:37:38.320152  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.320158  6142 net.cpp:137] Memory required for data: 452587560
I0601 18:37:38.320169  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/scale
I0601 18:37:38.320178  6142 net.cpp:84] Creating Layer conv3_3/dw/scale
I0601 18:37:38.320183  6142 net.cpp:406] conv3_3/dw/scale <- conv3_3/dw
I0601 18:37:38.320192  6142 net.cpp:367] conv3_3/dw/scale -> conv3_3/dw (in-place)
I0601 18:37:38.320261  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/scale
I0601 18:37:38.320451  6142 net.cpp:122] Setting up conv3_3/dw/scale
I0601 18:37:38.320466  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.320470  6142 net.cpp:137] Memory required for data: 461619240
I0601 18:37:38.320490  6142 layer_factory.cpp:63] Creating layer conv3_3/dw/ReLU
I0601 18:37:38.320498  6142 net.cpp:84] Creating Layer conv3_3/dw/ReLU
I0601 18:37:38.320504  6142 net.cpp:406] conv3_3/dw/ReLU <- conv3_3/dw
I0601 18:37:38.320511  6142 net.cpp:367] conv3_3/dw/ReLU -> conv3_3/dw (in-place)
I0601 18:37:38.321440  6142 net.cpp:122] Setting up conv3_3/dw/ReLU
I0601 18:37:38.321463  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.321470  6142 net.cpp:137] Memory required for data: 470650920
I0601 18:37:38.321475  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2
I0601 18:37:38.321489  6142 net.cpp:84] Creating Layer conv3_3/sep2
I0601 18:37:38.321496  6142 net.cpp:406] conv3_3/sep2 <- conv3_3/dw
I0601 18:37:38.321507  6142 net.cpp:380] conv3_3/sep2 -> conv3_3/sep2
I0601 18:37:38.324482  6142 net.cpp:122] Setting up conv3_3/sep2
I0601 18:37:38.324507  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.324513  6142 net.cpp:137] Memory required for data: 473661480
I0601 18:37:38.324522  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/bn
I0601 18:37:38.324532  6142 net.cpp:84] Creating Layer conv3_3/sep2/bn
I0601 18:37:38.324538  6142 net.cpp:406] conv3_3/sep2/bn <- conv3_3/sep2
I0601 18:37:38.324548  6142 net.cpp:367] conv3_3/sep2/bn -> conv3_3/sep2 (in-place)
I0601 18:37:38.325538  6142 net.cpp:122] Setting up conv3_3/sep2/bn
I0601 18:37:38.325559  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.325565  6142 net.cpp:137] Memory required for data: 476672040
I0601 18:37:38.325578  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/scale
I0601 18:37:38.325590  6142 net.cpp:84] Creating Layer conv3_3/sep2/scale
I0601 18:37:38.325596  6142 net.cpp:406] conv3_3/sep2/scale <- conv3_3/sep2
I0601 18:37:38.325604  6142 net.cpp:367] conv3_3/sep2/scale -> conv3_3/sep2 (in-place)
I0601 18:37:38.325680  6142 layer_factory.cpp:63] Creating layer conv3_3/sep2/scale
I0601 18:37:38.325881  6142 net.cpp:122] Setting up conv3_3/sep2/scale
I0601 18:37:38.325894  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.325899  6142 net.cpp:137] Memory required for data: 479682600
I0601 18:37:38.325908  6142 layer_factory.cpp:63] Creating layer conv3_3/Eltwise1
I0601 18:37:38.325917  6142 net.cpp:84] Creating Layer conv3_3/Eltwise1
I0601 18:37:38.325923  6142 net.cpp:406] conv3_3/Eltwise1 <- conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.325950  6142 net.cpp:406] conv3_3/Eltwise1 <- conv3_3/sep2
I0601 18:37:38.325963  6142 net.cpp:380] conv3_3/Eltwise1 -> conv3_3/Eltwise1
I0601 18:37:38.326004  6142 net.cpp:122] Setting up conv3_3/Eltwise1
I0601 18:37:38.326014  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.326018  6142 net.cpp:137] Memory required for data: 482693160
I0601 18:37:38.326023  6142 layer_factory.cpp:63] Creating layer conv3_3/Eltwise/ReLU
I0601 18:37:38.326035  6142 net.cpp:84] Creating Layer conv3_3/Eltwise/ReLU
I0601 18:37:38.326040  6142 net.cpp:406] conv3_3/Eltwise/ReLU <- conv3_3/Eltwise1
I0601 18:37:38.326047  6142 net.cpp:367] conv3_3/Eltwise/ReLU -> conv3_3/Eltwise1 (in-place)
I0601 18:37:38.326985  6142 net.cpp:122] Setting up conv3_3/Eltwise/ReLU
I0601 18:37:38.327011  6142 net.cpp:129] Top shape: 10 24 56 56 (752640)
I0601 18:37:38.327018  6142 net.cpp:137] Memory required for data: 485703720
I0601 18:37:38.327023  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1
I0601 18:37:38.327037  6142 net.cpp:84] Creating Layer conv4_1/sep1
I0601 18:37:38.327044  6142 net.cpp:406] conv4_1/sep1 <- conv3_3/Eltwise1
I0601 18:37:38.327064  6142 net.cpp:380] conv4_1/sep1 -> conv4_1/sep1
I0601 18:37:38.330850  6142 net.cpp:122] Setting up conv4_1/sep1
I0601 18:37:38.330878  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.330884  6142 net.cpp:137] Memory required for data: 494735400
I0601 18:37:38.330893  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/bn
I0601 18:37:38.330904  6142 net.cpp:84] Creating Layer conv4_1/sep1/bn
I0601 18:37:38.330910  6142 net.cpp:406] conv4_1/sep1/bn <- conv4_1/sep1
I0601 18:37:38.330920  6142 net.cpp:367] conv4_1/sep1/bn -> conv4_1/sep1 (in-place)
I0601 18:37:38.331266  6142 net.cpp:122] Setting up conv4_1/sep1/bn
I0601 18:37:38.331282  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.331287  6142 net.cpp:137] Memory required for data: 503767080
I0601 18:37:38.331300  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/scale
I0601 18:37:38.331308  6142 net.cpp:84] Creating Layer conv4_1/sep1/scale
I0601 18:37:38.331315  6142 net.cpp:406] conv4_1/sep1/scale <- conv4_1/sep1
I0601 18:37:38.331324  6142 net.cpp:367] conv4_1/sep1/scale -> conv4_1/sep1 (in-place)
I0601 18:37:38.331387  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/scale
I0601 18:37:38.331575  6142 net.cpp:122] Setting up conv4_1/sep1/scale
I0601 18:37:38.331588  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.331593  6142 net.cpp:137] Memory required for data: 512798760
I0601 18:37:38.331602  6142 layer_factory.cpp:63] Creating layer conv4_1/sep1/ReLU
I0601 18:37:38.331610  6142 net.cpp:84] Creating Layer conv4_1/sep1/ReLU
I0601 18:37:38.331616  6142 net.cpp:406] conv4_1/sep1/ReLU <- conv4_1/sep1
I0601 18:37:38.331624  6142 net.cpp:367] conv4_1/sep1/ReLU -> conv4_1/sep1 (in-place)
I0601 18:37:38.332363  6142 net.cpp:122] Setting up conv4_1/sep1/ReLU
I0601 18:37:38.332383  6142 net.cpp:129] Top shape: 10 72 56 56 (2257920)
I0601 18:37:38.332388  6142 net.cpp:137] Memory required for data: 521830440
I0601 18:37:38.332394  6142 layer_factory.cpp:63] Creating layer conv4_1/dw
I0601 18:37:38.332406  6142 net.cpp:84] Creating Layer conv4_1/dw
I0601 18:37:38.332412  6142 net.cpp:406] conv4_1/dw <- conv4_1/sep1
I0601 18:37:38.332423  6142 net.cpp:380] conv4_1/dw -> conv4_1/dw
I0601 18:37:38.332649  6142 net.cpp:122] Setting up conv4_1/dw
I0601 18:37:38.332667  6142 net.cpp:129] Top shape: 10 72 28 28 (564480)
I0601 18:37:38.332672  6142 net.cpp:137] Memory required for data: 524088360
I0601 18:37:38.332680  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/bn
I0601 18:37:38.332692  6142 net.cpp:84] Creating Layer conv4_1/dw/bn
I0601 18:37:38.332698  6142 net.cpp:406] conv4_1/dw/bn <- conv4_1/dw
I0601 18:37:38.332706  6142 net.cpp:367] conv4_1/dw/bn -> conv4_1/dw (in-place)
I0601 18:37:38.333027  6142 net.cpp:122] Setting up conv4_1/dw/bn
I0601 18:37:38.333041  6142 net.cpp:129] Top shape: 10 72 28 28 (564480)
I0601 18:37:38.333065  6142 net.cpp:137] Memory required for data: 526346280
I0601 18:37:38.333076  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/scale
I0601 18:37:38.333086  6142 net.cpp:84] Creating Layer conv4_1/dw/scale
I0601 18:37:38.333091  6142 net.cpp:406] conv4_1/dw/scale <- conv4_1/dw
I0601 18:37:38.333098  6142 net.cpp:367] conv4_1/dw/scale -> conv4_1/dw (in-place)
I0601 18:37:38.333168  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/scale
I0601 18:37:38.333349  6142 net.cpp:122] Setting up conv4_1/dw/scale
I0601 18:37:38.333364  6142 net.cpp:129] Top shape: 10 72 28 28 (564480)
I0601 18:37:38.333369  6142 net.cpp:137] Memory required for data: 528604200
I0601 18:37:38.333379  6142 layer_factory.cpp:63] Creating layer conv4_1/dw/ReLU
I0601 18:37:38.333387  6142 net.cpp:84] Creating Layer conv4_1/dw/ReLU
I0601 18:37:38.333392  6142 net.cpp:406] conv4_1/dw/ReLU <- conv4_1/dw
I0601 18:37:38.333400  6142 net.cpp:367] conv4_1/dw/ReLU -> conv4_1/dw (in-place)
I0601 18:37:38.334342  6142 net.cpp:122] Setting up conv4_1/dw/ReLU
I0601 18:37:38.334364  6142 net.cpp:129] Top shape: 10 72 28 28 (564480)
I0601 18:37:38.334370  6142 net.cpp:137] Memory required for data: 530862120
I0601 18:37:38.334376  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2
I0601 18:37:38.334393  6142 net.cpp:84] Creating Layer conv4_1/sep2
I0601 18:37:38.334398  6142 net.cpp:406] conv4_1/sep2 <- conv4_1/dw
I0601 18:37:38.334409  6142 net.cpp:380] conv4_1/sep2 -> conv4_1/sep2
I0601 18:37:38.337756  6142 net.cpp:122] Setting up conv4_1/sep2
I0601 18:37:38.337781  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.337787  6142 net.cpp:137] Memory required for data: 532116520
I0601 18:37:38.337795  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/bn
I0601 18:37:38.337808  6142 net.cpp:84] Creating Layer conv4_1/sep2/bn
I0601 18:37:38.337815  6142 net.cpp:406] conv4_1/sep2/bn <- conv4_1/sep2
I0601 18:37:38.337822  6142 net.cpp:367] conv4_1/sep2/bn -> conv4_1/sep2 (in-place)
I0601 18:37:38.338160  6142 net.cpp:122] Setting up conv4_1/sep2/bn
I0601 18:37:38.338173  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.338178  6142 net.cpp:137] Memory required for data: 533370920
I0601 18:37:38.338191  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/scale
I0601 18:37:38.338199  6142 net.cpp:84] Creating Layer conv4_1/sep2/scale
I0601 18:37:38.338205  6142 net.cpp:406] conv4_1/sep2/scale <- conv4_1/sep2
I0601 18:37:38.338212  6142 net.cpp:367] conv4_1/sep2/scale -> conv4_1/sep2 (in-place)
I0601 18:37:38.338279  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/scale
I0601 18:37:38.338466  6142 net.cpp:122] Setting up conv4_1/sep2/scale
I0601 18:37:38.338479  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.338485  6142 net.cpp:137] Memory required for data: 534625320
I0601 18:37:38.338493  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2/ReLU
I0601 18:37:38.338510  6142 net.cpp:84] Creating Layer conv4_1/sep2/ReLU
I0601 18:37:38.338515  6142 net.cpp:406] conv4_1/sep2/ReLU <- conv4_1/sep2
I0601 18:37:38.338522  6142 net.cpp:367] conv4_1/sep2/ReLU -> conv4_1/sep2 (in-place)
I0601 18:37:38.339277  6142 net.cpp:122] Setting up conv4_1/sep2/ReLU
I0601 18:37:38.339298  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.339303  6142 net.cpp:137] Memory required for data: 535879720
I0601 18:37:38.339310  6142 layer_factory.cpp:63] Creating layer conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.339323  6142 net.cpp:84] Creating Layer conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.339329  6142 net.cpp:406] conv4_1/sep2_conv4_1/sep2/ReLU_0_split <- conv4_1/sep2
I0601 18:37:38.339336  6142 net.cpp:380] conv4_1/sep2_conv4_1/sep2/ReLU_0_split -> conv4_1/sep2_conv4_1/sep2/ReLU_0_split_0
I0601 18:37:38.339349  6142 net.cpp:380] conv4_1/sep2_conv4_1/sep2/ReLU_0_split -> conv4_1/sep2_conv4_1/sep2/ReLU_0_split_1
I0601 18:37:38.339421  6142 net.cpp:122] Setting up conv4_1/sep2_conv4_1/sep2/ReLU_0_split
I0601 18:37:38.339429  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.339457  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.339462  6142 net.cpp:137] Memory required for data: 538388520
I0601 18:37:38.339466  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1
I0601 18:37:38.339480  6142 net.cpp:84] Creating Layer conv4_2/sep1
I0601 18:37:38.339488  6142 net.cpp:406] conv4_2/sep1 <- conv4_1/sep2_conv4_1/sep2/ReLU_0_split_0
I0601 18:37:38.339499  6142 net.cpp:380] conv4_2/sep1 -> conv4_2/sep1
I0601 18:37:38.343329  6142 net.cpp:122] Setting up conv4_2/sep1
I0601 18:37:38.343353  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.343359  6142 net.cpp:137] Memory required for data: 542151720
I0601 18:37:38.343369  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/bn
I0601 18:37:38.343380  6142 net.cpp:84] Creating Layer conv4_2/sep1/bn
I0601 18:37:38.343387  6142 net.cpp:406] conv4_2/sep1/bn <- conv4_2/sep1
I0601 18:37:38.343395  6142 net.cpp:367] conv4_2/sep1/bn -> conv4_2/sep1 (in-place)
I0601 18:37:38.343734  6142 net.cpp:122] Setting up conv4_2/sep1/bn
I0601 18:37:38.343750  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.343755  6142 net.cpp:137] Memory required for data: 545914920
I0601 18:37:38.343766  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/scale
I0601 18:37:38.343775  6142 net.cpp:84] Creating Layer conv4_2/sep1/scale
I0601 18:37:38.343780  6142 net.cpp:406] conv4_2/sep1/scale <- conv4_2/sep1
I0601 18:37:38.343788  6142 net.cpp:367] conv4_2/sep1/scale -> conv4_2/sep1 (in-place)
I0601 18:37:38.343854  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/scale
I0601 18:37:38.344038  6142 net.cpp:122] Setting up conv4_2/sep1/scale
I0601 18:37:38.344050  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.344055  6142 net.cpp:137] Memory required for data: 549678120
I0601 18:37:38.344064  6142 layer_factory.cpp:63] Creating layer conv4_2/sep1/ReLU
I0601 18:37:38.344075  6142 net.cpp:84] Creating Layer conv4_2/sep1/ReLU
I0601 18:37:38.344080  6142 net.cpp:406] conv4_2/sep1/ReLU <- conv4_2/sep1
I0601 18:37:38.344087  6142 net.cpp:367] conv4_2/sep1/ReLU -> conv4_2/sep1 (in-place)
I0601 18:37:38.344833  6142 net.cpp:122] Setting up conv4_2/sep1/ReLU
I0601 18:37:38.344853  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.344858  6142 net.cpp:137] Memory required for data: 553441320
I0601 18:37:38.344864  6142 layer_factory.cpp:63] Creating layer conv4_2/dw
I0601 18:37:38.344877  6142 net.cpp:84] Creating Layer conv4_2/dw
I0601 18:37:38.344882  6142 net.cpp:406] conv4_2/dw <- conv4_2/sep1
I0601 18:37:38.344892  6142 net.cpp:380] conv4_2/dw -> conv4_2/dw
I0601 18:37:38.345146  6142 net.cpp:122] Setting up conv4_2/dw
I0601 18:37:38.345165  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.345170  6142 net.cpp:137] Memory required for data: 557204520
I0601 18:37:38.345178  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/bn
I0601 18:37:38.345189  6142 net.cpp:84] Creating Layer conv4_2/dw/bn
I0601 18:37:38.345196  6142 net.cpp:406] conv4_2/dw/bn <- conv4_2/dw
I0601 18:37:38.345203  6142 net.cpp:367] conv4_2/dw/bn -> conv4_2/dw (in-place)
I0601 18:37:38.345533  6142 net.cpp:122] Setting up conv4_2/dw/bn
I0601 18:37:38.345546  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.345551  6142 net.cpp:137] Memory required for data: 560967720
I0601 18:37:38.345563  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/scale
I0601 18:37:38.345572  6142 net.cpp:84] Creating Layer conv4_2/dw/scale
I0601 18:37:38.345577  6142 net.cpp:406] conv4_2/dw/scale <- conv4_2/dw
I0601 18:37:38.345584  6142 net.cpp:367] conv4_2/dw/scale -> conv4_2/dw (in-place)
I0601 18:37:38.345649  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/scale
I0601 18:37:38.345830  6142 net.cpp:122] Setting up conv4_2/dw/scale
I0601 18:37:38.345844  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.345849  6142 net.cpp:137] Memory required for data: 564730920
I0601 18:37:38.345857  6142 layer_factory.cpp:63] Creating layer conv4_2/dw/ReLU
I0601 18:37:38.345883  6142 net.cpp:84] Creating Layer conv4_2/dw/ReLU
I0601 18:37:38.345890  6142 net.cpp:406] conv4_2/dw/ReLU <- conv4_2/dw
I0601 18:37:38.345899  6142 net.cpp:367] conv4_2/dw/ReLU -> conv4_2/dw (in-place)
I0601 18:37:38.346837  6142 net.cpp:122] Setting up conv4_2/dw/ReLU
I0601 18:37:38.346859  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.346865  6142 net.cpp:137] Memory required for data: 568494120
I0601 18:37:38.346871  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2
I0601 18:37:38.346885  6142 net.cpp:84] Creating Layer conv4_2/sep2
I0601 18:37:38.346892  6142 net.cpp:406] conv4_2/sep2 <- conv4_2/dw
I0601 18:37:38.346904  6142 net.cpp:380] conv4_2/sep2 -> conv4_2/sep2
I0601 18:37:38.350121  6142 net.cpp:122] Setting up conv4_2/sep2
I0601 18:37:38.350145  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.350152  6142 net.cpp:137] Memory required for data: 569748520
I0601 18:37:38.350160  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/bn
I0601 18:37:38.350170  6142 net.cpp:84] Creating Layer conv4_2/sep2/bn
I0601 18:37:38.350176  6142 net.cpp:406] conv4_2/sep2/bn <- conv4_2/sep2
I0601 18:37:38.350186  6142 net.cpp:367] conv4_2/sep2/bn -> conv4_2/sep2 (in-place)
I0601 18:37:38.350523  6142 net.cpp:122] Setting up conv4_2/sep2/bn
I0601 18:37:38.350538  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.350543  6142 net.cpp:137] Memory required for data: 571002920
I0601 18:37:38.350554  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/scale
I0601 18:37:38.350562  6142 net.cpp:84] Creating Layer conv4_2/sep2/scale
I0601 18:37:38.350569  6142 net.cpp:406] conv4_2/sep2/scale <- conv4_2/sep2
I0601 18:37:38.350579  6142 net.cpp:367] conv4_2/sep2/scale -> conv4_2/sep2 (in-place)
I0601 18:37:38.350639  6142 layer_factory.cpp:63] Creating layer conv4_2/sep2/scale
I0601 18:37:38.350827  6142 net.cpp:122] Setting up conv4_2/sep2/scale
I0601 18:37:38.350841  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.350847  6142 net.cpp:137] Memory required for data: 572257320
I0601 18:37:38.350855  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise1
I0601 18:37:38.350864  6142 net.cpp:84] Creating Layer conv4_2/Eltwise1
I0601 18:37:38.350870  6142 net.cpp:406] conv4_2/Eltwise1 <- conv4_1/sep2_conv4_1/sep2/ReLU_0_split_1
I0601 18:37:38.350878  6142 net.cpp:406] conv4_2/Eltwise1 <- conv4_2/sep2
I0601 18:37:38.350888  6142 net.cpp:380] conv4_2/Eltwise1 -> conv4_2/Eltwise1
I0601 18:37:38.350929  6142 net.cpp:122] Setting up conv4_2/Eltwise1
I0601 18:37:38.350939  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.350944  6142 net.cpp:137] Memory required for data: 573511720
I0601 18:37:38.350948  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise/ReLU
I0601 18:37:38.350957  6142 net.cpp:84] Creating Layer conv4_2/Eltwise/ReLU
I0601 18:37:38.350962  6142 net.cpp:406] conv4_2/Eltwise/ReLU <- conv4_2/Eltwise1
I0601 18:37:38.350972  6142 net.cpp:367] conv4_2/Eltwise/ReLU -> conv4_2/Eltwise1 (in-place)
I0601 18:37:38.351724  6142 net.cpp:122] Setting up conv4_2/Eltwise/ReLU
I0601 18:37:38.351747  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.351753  6142 net.cpp:137] Memory required for data: 574766120
I0601 18:37:38.351758  6142 layer_factory.cpp:63] Creating layer conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.351768  6142 net.cpp:84] Creating Layer conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.351774  6142 net.cpp:406] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split <- conv4_2/Eltwise1
I0601 18:37:38.351785  6142 net.cpp:380] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split -> conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.351796  6142 net.cpp:380] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split -> conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.351866  6142 net.cpp:122] Setting up conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split
I0601 18:37:38.351876  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.351882  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.351904  6142 net.cpp:137] Memory required for data: 577274920
I0601 18:37:38.351910  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1
I0601 18:37:38.351927  6142 net.cpp:84] Creating Layer conv4_3/sep1
I0601 18:37:38.351933  6142 net.cpp:406] conv4_3/sep1 <- conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.351941  6142 net.cpp:380] conv4_3/sep1 -> conv4_3/sep1
I0601 18:37:38.355767  6142 net.cpp:122] Setting up conv4_3/sep1
I0601 18:37:38.355792  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.355798  6142 net.cpp:137] Memory required for data: 581038120
I0601 18:37:38.355806  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/bn
I0601 18:37:38.355824  6142 net.cpp:84] Creating Layer conv4_3/sep1/bn
I0601 18:37:38.355831  6142 net.cpp:406] conv4_3/sep1/bn <- conv4_3/sep1
I0601 18:37:38.355842  6142 net.cpp:367] conv4_3/sep1/bn -> conv4_3/sep1 (in-place)
I0601 18:37:38.356175  6142 net.cpp:122] Setting up conv4_3/sep1/bn
I0601 18:37:38.356189  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.356195  6142 net.cpp:137] Memory required for data: 584801320
I0601 18:37:38.356206  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/scale
I0601 18:37:38.356218  6142 net.cpp:84] Creating Layer conv4_3/sep1/scale
I0601 18:37:38.356223  6142 net.cpp:406] conv4_3/sep1/scale <- conv4_3/sep1
I0601 18:37:38.356230  6142 net.cpp:367] conv4_3/sep1/scale -> conv4_3/sep1 (in-place)
I0601 18:37:38.356297  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/scale
I0601 18:37:38.356490  6142 net.cpp:122] Setting up conv4_3/sep1/scale
I0601 18:37:38.356504  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.356509  6142 net.cpp:137] Memory required for data: 588564520
I0601 18:37:38.356518  6142 layer_factory.cpp:63] Creating layer conv4_3/sep1/ReLU
I0601 18:37:38.356529  6142 net.cpp:84] Creating Layer conv4_3/sep1/ReLU
I0601 18:37:38.356534  6142 net.cpp:406] conv4_3/sep1/ReLU <- conv4_3/sep1
I0601 18:37:38.356541  6142 net.cpp:367] conv4_3/sep1/ReLU -> conv4_3/sep1 (in-place)
I0601 18:37:38.357475  6142 net.cpp:122] Setting up conv4_3/sep1/ReLU
I0601 18:37:38.357501  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.357506  6142 net.cpp:137] Memory required for data: 592327720
I0601 18:37:38.357512  6142 layer_factory.cpp:63] Creating layer conv4_3/dw
I0601 18:37:38.357522  6142 net.cpp:84] Creating Layer conv4_3/dw
I0601 18:37:38.357528  6142 net.cpp:406] conv4_3/dw <- conv4_3/sep1
I0601 18:37:38.357539  6142 net.cpp:380] conv4_3/dw -> conv4_3/dw
I0601 18:37:38.357800  6142 net.cpp:122] Setting up conv4_3/dw
I0601 18:37:38.357818  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.357823  6142 net.cpp:137] Memory required for data: 596090920
I0601 18:37:38.357831  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/bn
I0601 18:37:38.357843  6142 net.cpp:84] Creating Layer conv4_3/dw/bn
I0601 18:37:38.357849  6142 net.cpp:406] conv4_3/dw/bn <- conv4_3/dw
I0601 18:37:38.357857  6142 net.cpp:367] conv4_3/dw/bn -> conv4_3/dw (in-place)
I0601 18:37:38.358186  6142 net.cpp:122] Setting up conv4_3/dw/bn
I0601 18:37:38.358199  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.358204  6142 net.cpp:137] Memory required for data: 599854120
I0601 18:37:38.358217  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/scale
I0601 18:37:38.358228  6142 net.cpp:84] Creating Layer conv4_3/dw/scale
I0601 18:37:38.358233  6142 net.cpp:406] conv4_3/dw/scale <- conv4_3/dw
I0601 18:37:38.358240  6142 net.cpp:367] conv4_3/dw/scale -> conv4_3/dw (in-place)
I0601 18:37:38.358305  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/scale
I0601 18:37:38.358491  6142 net.cpp:122] Setting up conv4_3/dw/scale
I0601 18:37:38.358505  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.358510  6142 net.cpp:137] Memory required for data: 603617320
I0601 18:37:38.358518  6142 layer_factory.cpp:63] Creating layer conv4_3/dw/ReLU
I0601 18:37:38.358528  6142 net.cpp:84] Creating Layer conv4_3/dw/ReLU
I0601 18:37:38.358551  6142 net.cpp:406] conv4_3/dw/ReLU <- conv4_3/dw
I0601 18:37:38.358561  6142 net.cpp:367] conv4_3/dw/ReLU -> conv4_3/dw (in-place)
I0601 18:37:38.359314  6142 net.cpp:122] Setting up conv4_3/dw/ReLU
I0601 18:37:38.359335  6142 net.cpp:129] Top shape: 10 120 28 28 (940800)
I0601 18:37:38.359341  6142 net.cpp:137] Memory required for data: 607380520
I0601 18:37:38.359346  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2
I0601 18:37:38.359360  6142 net.cpp:84] Creating Layer conv4_3/sep2
I0601 18:37:38.359366  6142 net.cpp:406] conv4_3/sep2 <- conv4_3/dw
I0601 18:37:38.359378  6142 net.cpp:380] conv4_3/sep2 -> conv4_3/sep2
I0601 18:37:38.362752  6142 net.cpp:122] Setting up conv4_3/sep2
I0601 18:37:38.362776  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.362782  6142 net.cpp:137] Memory required for data: 608634920
I0601 18:37:38.362792  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/bn
I0601 18:37:38.362803  6142 net.cpp:84] Creating Layer conv4_3/sep2/bn
I0601 18:37:38.362809  6142 net.cpp:406] conv4_3/sep2/bn <- conv4_3/sep2
I0601 18:37:38.362819  6142 net.cpp:367] conv4_3/sep2/bn -> conv4_3/sep2 (in-place)
I0601 18:37:38.363165  6142 net.cpp:122] Setting up conv4_3/sep2/bn
I0601 18:37:38.363180  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.363186  6142 net.cpp:137] Memory required for data: 609889320
I0601 18:37:38.363198  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/scale
I0601 18:37:38.363209  6142 net.cpp:84] Creating Layer conv4_3/sep2/scale
I0601 18:37:38.363215  6142 net.cpp:406] conv4_3/sep2/scale <- conv4_3/sep2
I0601 18:37:38.363222  6142 net.cpp:367] conv4_3/sep2/scale -> conv4_3/sep2 (in-place)
I0601 18:37:38.363291  6142 layer_factory.cpp:63] Creating layer conv4_3/sep2/scale
I0601 18:37:38.363481  6142 net.cpp:122] Setting up conv4_3/sep2/scale
I0601 18:37:38.363493  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.363498  6142 net.cpp:137] Memory required for data: 611143720
I0601 18:37:38.363507  6142 layer_factory.cpp:63] Creating layer conv4_3/Eltwise1
I0601 18:37:38.363517  6142 net.cpp:84] Creating Layer conv4_3/Eltwise1
I0601 18:37:38.363523  6142 net.cpp:406] conv4_3/Eltwise1 <- conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.363529  6142 net.cpp:406] conv4_3/Eltwise1 <- conv4_3/sep2
I0601 18:37:38.363540  6142 net.cpp:380] conv4_3/Eltwise1 -> conv4_3/Eltwise1
I0601 18:37:38.363581  6142 net.cpp:122] Setting up conv4_3/Eltwise1
I0601 18:37:38.363590  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.363595  6142 net.cpp:137] Memory required for data: 612398120
I0601 18:37:38.363600  6142 layer_factory.cpp:63] Creating layer conv4_3/Eltwise/ReLU
I0601 18:37:38.363608  6142 net.cpp:84] Creating Layer conv4_3/Eltwise/ReLU
I0601 18:37:38.363615  6142 net.cpp:406] conv4_3/Eltwise/ReLU <- conv4_3/Eltwise1
I0601 18:37:38.363621  6142 net.cpp:367] conv4_3/Eltwise/ReLU -> conv4_3/Eltwise1 (in-place)
I0601 18:37:38.364552  6142 net.cpp:122] Setting up conv4_3/Eltwise/ReLU
I0601 18:37:38.364578  6142 net.cpp:129] Top shape: 10 40 28 28 (313600)
I0601 18:37:38.364584  6142 net.cpp:137] Memory required for data: 613652520
I0601 18:37:38.364590  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1
I0601 18:37:38.364606  6142 net.cpp:84] Creating Layer conv5_1/sep1
I0601 18:37:38.364614  6142 net.cpp:406] conv5_1/sep1 <- conv4_3/Eltwise1
I0601 18:37:38.364624  6142 net.cpp:380] conv5_1/sep1 -> conv5_1/sep1
I0601 18:37:38.367717  6142 net.cpp:122] Setting up conv5_1/sep1
I0601 18:37:38.367741  6142 net.cpp:129] Top shape: 10 240 28 28 (1881600)
I0601 18:37:38.367748  6142 net.cpp:137] Memory required for data: 621178920
I0601 18:37:38.367756  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/bn
I0601 18:37:38.367769  6142 net.cpp:84] Creating Layer conv5_1/sep1/bn
I0601 18:37:38.367775  6142 net.cpp:406] conv5_1/sep1/bn <- conv5_1/sep1
I0601 18:37:38.367784  6142 net.cpp:367] conv5_1/sep1/bn -> conv5_1/sep1 (in-place)
I0601 18:37:38.368119  6142 net.cpp:122] Setting up conv5_1/sep1/bn
I0601 18:37:38.368151  6142 net.cpp:129] Top shape: 10 240 28 28 (1881600)
I0601 18:37:38.368157  6142 net.cpp:137] Memory required for data: 628705320
I0601 18:37:38.368185  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/scale
I0601 18:37:38.368198  6142 net.cpp:84] Creating Layer conv5_1/sep1/scale
I0601 18:37:38.368204  6142 net.cpp:406] conv5_1/sep1/scale <- conv5_1/sep1
I0601 18:37:38.368211  6142 net.cpp:367] conv5_1/sep1/scale -> conv5_1/sep1 (in-place)
I0601 18:37:38.368279  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/scale
I0601 18:37:38.368463  6142 net.cpp:122] Setting up conv5_1/sep1/scale
I0601 18:37:38.368476  6142 net.cpp:129] Top shape: 10 240 28 28 (1881600)
I0601 18:37:38.368481  6142 net.cpp:137] Memory required for data: 636231720
I0601 18:37:38.368490  6142 layer_factory.cpp:63] Creating layer conv5_1/sep1/ReLU
I0601 18:37:38.368500  6142 net.cpp:84] Creating Layer conv5_1/sep1/ReLU
I0601 18:37:38.368506  6142 net.cpp:406] conv5_1/sep1/ReLU <- conv5_1/sep1
I0601 18:37:38.368513  6142 net.cpp:367] conv5_1/sep1/ReLU -> conv5_1/sep1 (in-place)
I0601 18:37:38.370864  6142 net.cpp:122] Setting up conv5_1/sep1/ReLU
I0601 18:37:38.370889  6142 net.cpp:129] Top shape: 10 240 28 28 (1881600)
I0601 18:37:38.370895  6142 net.cpp:137] Memory required for data: 643758120
I0601 18:37:38.370901  6142 layer_factory.cpp:63] Creating layer conv5_1/dw
I0601 18:37:38.370914  6142 net.cpp:84] Creating Layer conv5_1/dw
I0601 18:37:38.370920  6142 net.cpp:406] conv5_1/dw <- conv5_1/sep1
I0601 18:37:38.370929  6142 net.cpp:380] conv5_1/dw -> conv5_1/dw
I0601 18:37:38.371268  6142 net.cpp:122] Setting up conv5_1/dw
I0601 18:37:38.371289  6142 net.cpp:129] Top shape: 10 240 14 14 (470400)
I0601 18:37:38.371295  6142 net.cpp:137] Memory required for data: 645639720
I0601 18:37:38.371304  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/bn
I0601 18:37:38.371312  6142 net.cpp:84] Creating Layer conv5_1/dw/bn
I0601 18:37:38.371321  6142 net.cpp:406] conv5_1/dw/bn <- conv5_1/dw
I0601 18:37:38.371330  6142 net.cpp:367] conv5_1/dw/bn -> conv5_1/dw (in-place)
I0601 18:37:38.371672  6142 net.cpp:122] Setting up conv5_1/dw/bn
I0601 18:37:38.371685  6142 net.cpp:129] Top shape: 10 240 14 14 (470400)
I0601 18:37:38.371690  6142 net.cpp:137] Memory required for data: 647521320
I0601 18:37:38.371702  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/scale
I0601 18:37:38.371711  6142 net.cpp:84] Creating Layer conv5_1/dw/scale
I0601 18:37:38.371716  6142 net.cpp:406] conv5_1/dw/scale <- conv5_1/dw
I0601 18:37:38.371724  6142 net.cpp:367] conv5_1/dw/scale -> conv5_1/dw (in-place)
I0601 18:37:38.371788  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/scale
I0601 18:37:38.371978  6142 net.cpp:122] Setting up conv5_1/dw/scale
I0601 18:37:38.371990  6142 net.cpp:129] Top shape: 10 240 14 14 (470400)
I0601 18:37:38.371995  6142 net.cpp:137] Memory required for data: 649402920
I0601 18:37:38.372004  6142 layer_factory.cpp:63] Creating layer conv5_1/dw/ReLU
I0601 18:37:38.372012  6142 net.cpp:84] Creating Layer conv5_1/dw/ReLU
I0601 18:37:38.372017  6142 net.cpp:406] conv5_1/dw/ReLU <- conv5_1/dw
I0601 18:37:38.372026  6142 net.cpp:367] conv5_1/dw/ReLU -> conv5_1/dw (in-place)
I0601 18:37:38.372766  6142 net.cpp:122] Setting up conv5_1/dw/ReLU
I0601 18:37:38.372786  6142 net.cpp:129] Top shape: 10 240 14 14 (470400)
I0601 18:37:38.372792  6142 net.cpp:137] Memory required for data: 651284520
I0601 18:37:38.372797  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2
I0601 18:37:38.372815  6142 net.cpp:84] Creating Layer conv5_1/sep2
I0601 18:37:38.372822  6142 net.cpp:406] conv5_1/sep2 <- conv5_1/dw
I0601 18:37:38.372831  6142 net.cpp:380] conv5_1/sep2 -> conv5_1/sep2
I0601 18:37:38.376387  6142 net.cpp:122] Setting up conv5_1/sep2
I0601 18:37:38.376412  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.376418  6142 net.cpp:137] Memory required for data: 651911720
I0601 18:37:38.376427  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/bn
I0601 18:37:38.376439  6142 net.cpp:84] Creating Layer conv5_1/sep2/bn
I0601 18:37:38.376464  6142 net.cpp:406] conv5_1/sep2/bn <- conv5_1/sep2
I0601 18:37:38.376473  6142 net.cpp:367] conv5_1/sep2/bn -> conv5_1/sep2 (in-place)
I0601 18:37:38.376825  6142 net.cpp:122] Setting up conv5_1/sep2/bn
I0601 18:37:38.376840  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.376845  6142 net.cpp:137] Memory required for data: 652538920
I0601 18:37:38.376857  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/scale
I0601 18:37:38.376868  6142 net.cpp:84] Creating Layer conv5_1/sep2/scale
I0601 18:37:38.376874  6142 net.cpp:406] conv5_1/sep2/scale <- conv5_1/sep2
I0601 18:37:38.376881  6142 net.cpp:367] conv5_1/sep2/scale -> conv5_1/sep2 (in-place)
I0601 18:37:38.376947  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/scale
I0601 18:37:38.377140  6142 net.cpp:122] Setting up conv5_1/sep2/scale
I0601 18:37:38.377154  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.377159  6142 net.cpp:137] Memory required for data: 653166120
I0601 18:37:38.377168  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2/ReLU
I0601 18:37:38.377178  6142 net.cpp:84] Creating Layer conv5_1/sep2/ReLU
I0601 18:37:38.377184  6142 net.cpp:406] conv5_1/sep2/ReLU <- conv5_1/sep2
I0601 18:37:38.377192  6142 net.cpp:367] conv5_1/sep2/ReLU -> conv5_1/sep2 (in-place)
I0601 18:37:38.378129  6142 net.cpp:122] Setting up conv5_1/sep2/ReLU
I0601 18:37:38.378151  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.378157  6142 net.cpp:137] Memory required for data: 653793320
I0601 18:37:38.378163  6142 layer_factory.cpp:63] Creating layer conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.378175  6142 net.cpp:84] Creating Layer conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.378181  6142 net.cpp:406] conv5_1/sep2_conv5_1/sep2/ReLU_0_split <- conv5_1/sep2
I0601 18:37:38.378190  6142 net.cpp:380] conv5_1/sep2_conv5_1/sep2/ReLU_0_split -> conv5_1/sep2_conv5_1/sep2/ReLU_0_split_0
I0601 18:37:38.378204  6142 net.cpp:380] conv5_1/sep2_conv5_1/sep2/ReLU_0_split -> conv5_1/sep2_conv5_1/sep2/ReLU_0_split_1
I0601 18:37:38.378280  6142 net.cpp:122] Setting up conv5_1/sep2_conv5_1/sep2/ReLU_0_split
I0601 18:37:38.378290  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.378296  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.378301  6142 net.cpp:137] Memory required for data: 655047720
I0601 18:37:38.378306  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1
I0601 18:37:38.378322  6142 net.cpp:84] Creating Layer conv5_2/sep1
I0601 18:37:38.378329  6142 net.cpp:406] conv5_2/sep1 <- conv5_1/sep2_conv5_1/sep2/ReLU_0_split_0
I0601 18:37:38.378340  6142 net.cpp:380] conv5_2/sep1 -> conv5_2/sep1
I0601 18:37:38.381978  6142 net.cpp:122] Setting up conv5_2/sep1
I0601 18:37:38.382002  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.382009  6142 net.cpp:137] Memory required for data: 658810920
I0601 18:37:38.382017  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/bn
I0601 18:37:38.382032  6142 net.cpp:84] Creating Layer conv5_2/sep1/bn
I0601 18:37:38.382038  6142 net.cpp:406] conv5_2/sep1/bn <- conv5_2/sep1
I0601 18:37:38.382048  6142 net.cpp:367] conv5_2/sep1/bn -> conv5_2/sep1 (in-place)
I0601 18:37:38.382387  6142 net.cpp:122] Setting up conv5_2/sep1/bn
I0601 18:37:38.382401  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.382406  6142 net.cpp:137] Memory required for data: 662574120
I0601 18:37:38.382418  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/scale
I0601 18:37:38.382429  6142 net.cpp:84] Creating Layer conv5_2/sep1/scale
I0601 18:37:38.382436  6142 net.cpp:406] conv5_2/sep1/scale <- conv5_2/sep1
I0601 18:37:38.382442  6142 net.cpp:367] conv5_2/sep1/scale -> conv5_2/sep1 (in-place)
I0601 18:37:38.382508  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/scale
I0601 18:37:38.382699  6142 net.cpp:122] Setting up conv5_2/sep1/scale
I0601 18:37:38.382711  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.382717  6142 net.cpp:137] Memory required for data: 666337320
I0601 18:37:38.382745  6142 layer_factory.cpp:63] Creating layer conv5_2/sep1/ReLU
I0601 18:37:38.382755  6142 net.cpp:84] Creating Layer conv5_2/sep1/ReLU
I0601 18:37:38.382759  6142 net.cpp:406] conv5_2/sep1/ReLU <- conv5_2/sep1
I0601 18:37:38.382769  6142 net.cpp:367] conv5_2/sep1/ReLU -> conv5_2/sep1 (in-place)
I0601 18:37:38.383713  6142 net.cpp:122] Setting up conv5_2/sep1/ReLU
I0601 18:37:38.383738  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.383742  6142 net.cpp:137] Memory required for data: 670100520
I0601 18:37:38.383749  6142 layer_factory.cpp:63] Creating layer conv5_2/dw
I0601 18:37:38.383759  6142 net.cpp:84] Creating Layer conv5_2/dw
I0601 18:37:38.383764  6142 net.cpp:406] conv5_2/dw <- conv5_2/sep1
I0601 18:37:38.383776  6142 net.cpp:380] conv5_2/dw -> conv5_2/dw
I0601 18:37:38.384205  6142 net.cpp:122] Setting up conv5_2/dw
I0601 18:37:38.384223  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.384228  6142 net.cpp:137] Memory required for data: 673863720
I0601 18:37:38.384238  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/bn
I0601 18:37:38.384246  6142 net.cpp:84] Creating Layer conv5_2/dw/bn
I0601 18:37:38.384253  6142 net.cpp:406] conv5_2/dw/bn <- conv5_2/dw
I0601 18:37:38.384264  6142 net.cpp:367] conv5_2/dw/bn -> conv5_2/dw (in-place)
I0601 18:37:38.384596  6142 net.cpp:122] Setting up conv5_2/dw/bn
I0601 18:37:38.384609  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.384614  6142 net.cpp:137] Memory required for data: 677626920
I0601 18:37:38.384626  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/scale
I0601 18:37:38.384634  6142 net.cpp:84] Creating Layer conv5_2/dw/scale
I0601 18:37:38.384640  6142 net.cpp:406] conv5_2/dw/scale <- conv5_2/dw
I0601 18:37:38.384649  6142 net.cpp:367] conv5_2/dw/scale -> conv5_2/dw (in-place)
I0601 18:37:38.384711  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/scale
I0601 18:37:38.384899  6142 net.cpp:122] Setting up conv5_2/dw/scale
I0601 18:37:38.384912  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.384917  6142 net.cpp:137] Memory required for data: 681390120
I0601 18:37:38.384927  6142 layer_factory.cpp:63] Creating layer conv5_2/dw/ReLU
I0601 18:37:38.384934  6142 net.cpp:84] Creating Layer conv5_2/dw/ReLU
I0601 18:37:38.384940  6142 net.cpp:406] conv5_2/dw/ReLU <- conv5_2/dw
I0601 18:37:38.384949  6142 net.cpp:367] conv5_2/dw/ReLU -> conv5_2/dw (in-place)
I0601 18:37:38.386538  6142 net.cpp:122] Setting up conv5_2/dw/ReLU
I0601 18:37:38.386564  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.386569  6142 net.cpp:137] Memory required for data: 685153320
I0601 18:37:38.386575  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2
I0601 18:37:38.386590  6142 net.cpp:84] Creating Layer conv5_2/sep2
I0601 18:37:38.386596  6142 net.cpp:406] conv5_2/sep2 <- conv5_2/dw
I0601 18:37:38.386605  6142 net.cpp:380] conv5_2/sep2 -> conv5_2/sep2
I0601 18:37:38.391108  6142 net.cpp:122] Setting up conv5_2/sep2
I0601 18:37:38.391134  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.391139  6142 net.cpp:137] Memory required for data: 685780520
I0601 18:37:38.391149  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/bn
I0601 18:37:38.391158  6142 net.cpp:84] Creating Layer conv5_2/sep2/bn
I0601 18:37:38.391167  6142 net.cpp:406] conv5_2/sep2/bn <- conv5_2/sep2
I0601 18:37:38.391175  6142 net.cpp:367] conv5_2/sep2/bn -> conv5_2/sep2 (in-place)
I0601 18:37:38.391517  6142 net.cpp:122] Setting up conv5_2/sep2/bn
I0601 18:37:38.391531  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.391536  6142 net.cpp:137] Memory required for data: 686407720
I0601 18:37:38.391547  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/scale
I0601 18:37:38.391556  6142 net.cpp:84] Creating Layer conv5_2/sep2/scale
I0601 18:37:38.391562  6142 net.cpp:406] conv5_2/sep2/scale <- conv5_2/sep2
I0601 18:37:38.391569  6142 net.cpp:367] conv5_2/sep2/scale -> conv5_2/sep2 (in-place)
I0601 18:37:38.391638  6142 layer_factory.cpp:63] Creating layer conv5_2/sep2/scale
I0601 18:37:38.391850  6142 net.cpp:122] Setting up conv5_2/sep2/scale
I0601 18:37:38.391865  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.391870  6142 net.cpp:137] Memory required for data: 687034920
I0601 18:37:38.391880  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise1
I0601 18:37:38.391889  6142 net.cpp:84] Creating Layer conv5_2/Eltwise1
I0601 18:37:38.391898  6142 net.cpp:406] conv5_2/Eltwise1 <- conv5_1/sep2_conv5_1/sep2/ReLU_0_split_1
I0601 18:37:38.391906  6142 net.cpp:406] conv5_2/Eltwise1 <- conv5_2/sep2
I0601 18:37:38.391914  6142 net.cpp:380] conv5_2/Eltwise1 -> conv5_2/Eltwise1
I0601 18:37:38.391955  6142 net.cpp:122] Setting up conv5_2/Eltwise1
I0601 18:37:38.391964  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.391969  6142 net.cpp:137] Memory required for data: 687662120
I0601 18:37:38.391974  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise/ReLU
I0601 18:37:38.391983  6142 net.cpp:84] Creating Layer conv5_2/Eltwise/ReLU
I0601 18:37:38.391988  6142 net.cpp:406] conv5_2/Eltwise/ReLU <- conv5_2/Eltwise1
I0601 18:37:38.391995  6142 net.cpp:367] conv5_2/Eltwise/ReLU -> conv5_2/Eltwise1 (in-place)
I0601 18:37:38.392930  6142 net.cpp:122] Setting up conv5_2/Eltwise/ReLU
I0601 18:37:38.392954  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.392961  6142 net.cpp:137] Memory required for data: 688289320
I0601 18:37:38.392966  6142 layer_factory.cpp:63] Creating layer conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.392976  6142 net.cpp:84] Creating Layer conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.392982  6142 net.cpp:406] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split <- conv5_2/Eltwise1
I0601 18:37:38.392994  6142 net.cpp:380] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split -> conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.393007  6142 net.cpp:380] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split -> conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.393080  6142 net.cpp:122] Setting up conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split
I0601 18:37:38.393090  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.393097  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.393102  6142 net.cpp:137] Memory required for data: 689543720
I0601 18:37:38.393107  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1
I0601 18:37:38.393121  6142 net.cpp:84] Creating Layer conv5_3/sep1
I0601 18:37:38.393127  6142 net.cpp:406] conv5_3/sep1 <- conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.393136  6142 net.cpp:380] conv5_3/sep1 -> conv5_3/sep1
I0601 18:37:38.396765  6142 net.cpp:122] Setting up conv5_3/sep1
I0601 18:37:38.396790  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.396796  6142 net.cpp:137] Memory required for data: 693306920
I0601 18:37:38.396806  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/bn
I0601 18:37:38.396817  6142 net.cpp:84] Creating Layer conv5_3/sep1/bn
I0601 18:37:38.396824  6142 net.cpp:406] conv5_3/sep1/bn <- conv5_3/sep1
I0601 18:37:38.396832  6142 net.cpp:367] conv5_3/sep1/bn -> conv5_3/sep1 (in-place)
I0601 18:37:38.397172  6142 net.cpp:122] Setting up conv5_3/sep1/bn
I0601 18:37:38.397187  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.397192  6142 net.cpp:137] Memory required for data: 697070120
I0601 18:37:38.397203  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/scale
I0601 18:37:38.397212  6142 net.cpp:84] Creating Layer conv5_3/sep1/scale
I0601 18:37:38.397218  6142 net.cpp:406] conv5_3/sep1/scale <- conv5_3/sep1
I0601 18:37:38.397225  6142 net.cpp:367] conv5_3/sep1/scale -> conv5_3/sep1 (in-place)
I0601 18:37:38.397291  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/scale
I0601 18:37:38.397475  6142 net.cpp:122] Setting up conv5_3/sep1/scale
I0601 18:37:38.397488  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.397493  6142 net.cpp:137] Memory required for data: 700833320
I0601 18:37:38.397502  6142 layer_factory.cpp:63] Creating layer conv5_3/sep1/ReLU
I0601 18:37:38.397531  6142 net.cpp:84] Creating Layer conv5_3/sep1/ReLU
I0601 18:37:38.397537  6142 net.cpp:406] conv5_3/sep1/ReLU <- conv5_3/sep1
I0601 18:37:38.397544  6142 net.cpp:367] conv5_3/sep1/ReLU -> conv5_3/sep1 (in-place)
I0601 18:37:38.398481  6142 net.cpp:122] Setting up conv5_3/sep1/ReLU
I0601 18:37:38.398505  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.398510  6142 net.cpp:137] Memory required for data: 704596520
I0601 18:37:38.398516  6142 layer_factory.cpp:63] Creating layer conv5_3/dw
I0601 18:37:38.398530  6142 net.cpp:84] Creating Layer conv5_3/dw
I0601 18:37:38.398535  6142 net.cpp:406] conv5_3/dw <- conv5_3/sep1
I0601 18:37:38.398547  6142 net.cpp:380] conv5_3/dw -> conv5_3/dw
I0601 18:37:38.398975  6142 net.cpp:122] Setting up conv5_3/dw
I0601 18:37:38.398994  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.398999  6142 net.cpp:137] Memory required for data: 708359720
I0601 18:37:38.399008  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/bn
I0601 18:37:38.399019  6142 net.cpp:84] Creating Layer conv5_3/dw/bn
I0601 18:37:38.399025  6142 net.cpp:406] conv5_3/dw/bn <- conv5_3/dw
I0601 18:37:38.399034  6142 net.cpp:367] conv5_3/dw/bn -> conv5_3/dw (in-place)
I0601 18:37:38.399371  6142 net.cpp:122] Setting up conv5_3/dw/bn
I0601 18:37:38.399386  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.399392  6142 net.cpp:137] Memory required for data: 712122920
I0601 18:37:38.399403  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/scale
I0601 18:37:38.399415  6142 net.cpp:84] Creating Layer conv5_3/dw/scale
I0601 18:37:38.399420  6142 net.cpp:406] conv5_3/dw/scale <- conv5_3/dw
I0601 18:37:38.399428  6142 net.cpp:367] conv5_3/dw/scale -> conv5_3/dw (in-place)
I0601 18:37:38.399492  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/scale
I0601 18:37:38.399682  6142 net.cpp:122] Setting up conv5_3/dw/scale
I0601 18:37:38.399695  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.399700  6142 net.cpp:137] Memory required for data: 715886120
I0601 18:37:38.399709  6142 layer_factory.cpp:63] Creating layer conv5_3/dw/ReLU
I0601 18:37:38.399721  6142 net.cpp:84] Creating Layer conv5_3/dw/ReLU
I0601 18:37:38.399727  6142 net.cpp:406] conv5_3/dw/ReLU <- conv5_3/dw
I0601 18:37:38.399734  6142 net.cpp:367] conv5_3/dw/ReLU -> conv5_3/dw (in-place)
I0601 18:37:38.400673  6142 net.cpp:122] Setting up conv5_3/dw/ReLU
I0601 18:37:38.400696  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.400702  6142 net.cpp:137] Memory required for data: 719649320
I0601 18:37:38.400707  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2
I0601 18:37:38.400738  6142 net.cpp:84] Creating Layer conv5_3/sep2
I0601 18:37:38.400744  6142 net.cpp:406] conv5_3/sep2 <- conv5_3/dw
I0601 18:37:38.400753  6142 net.cpp:380] conv5_3/sep2 -> conv5_3/sep2
I0601 18:37:38.405050  6142 net.cpp:122] Setting up conv5_3/sep2
I0601 18:37:38.405074  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.405081  6142 net.cpp:137] Memory required for data: 720276520
I0601 18:37:38.405090  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/bn
I0601 18:37:38.405102  6142 net.cpp:84] Creating Layer conv5_3/sep2/bn
I0601 18:37:38.405108  6142 net.cpp:406] conv5_3/sep2/bn <- conv5_3/sep2
I0601 18:37:38.405117  6142 net.cpp:367] conv5_3/sep2/bn -> conv5_3/sep2 (in-place)
I0601 18:37:38.405455  6142 net.cpp:122] Setting up conv5_3/sep2/bn
I0601 18:37:38.405469  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.405474  6142 net.cpp:137] Memory required for data: 720903720
I0601 18:37:38.405486  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/scale
I0601 18:37:38.405498  6142 net.cpp:84] Creating Layer conv5_3/sep2/scale
I0601 18:37:38.405503  6142 net.cpp:406] conv5_3/sep2/scale <- conv5_3/sep2
I0601 18:37:38.405510  6142 net.cpp:367] conv5_3/sep2/scale -> conv5_3/sep2 (in-place)
I0601 18:37:38.405575  6142 layer_factory.cpp:63] Creating layer conv5_3/sep2/scale
I0601 18:37:38.405761  6142 net.cpp:122] Setting up conv5_3/sep2/scale
I0601 18:37:38.405792  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.405798  6142 net.cpp:137] Memory required for data: 721530920
I0601 18:37:38.405808  6142 layer_factory.cpp:63] Creating layer conv5_3/Eltwise1
I0601 18:37:38.405820  6142 net.cpp:84] Creating Layer conv5_3/Eltwise1
I0601 18:37:38.405827  6142 net.cpp:406] conv5_3/Eltwise1 <- conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.405834  6142 net.cpp:406] conv5_3/Eltwise1 <- conv5_3/sep2
I0601 18:37:38.405844  6142 net.cpp:380] conv5_3/Eltwise1 -> conv5_3/Eltwise1
I0601 18:37:38.405884  6142 net.cpp:122] Setting up conv5_3/Eltwise1
I0601 18:37:38.405894  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.405898  6142 net.cpp:137] Memory required for data: 722158120
I0601 18:37:38.405903  6142 layer_factory.cpp:63] Creating layer conv5_3/Eltwise/ReLU
I0601 18:37:38.405915  6142 net.cpp:84] Creating Layer conv5_3/Eltwise/ReLU
I0601 18:37:38.405920  6142 net.cpp:406] conv5_3/Eltwise/ReLU <- conv5_3/Eltwise1
I0601 18:37:38.405927  6142 net.cpp:367] conv5_3/Eltwise/ReLU -> conv5_3/Eltwise1 (in-place)
I0601 18:37:38.406855  6142 net.cpp:122] Setting up conv5_3/Eltwise/ReLU
I0601 18:37:38.406878  6142 net.cpp:129] Top shape: 10 80 14 14 (156800)
I0601 18:37:38.406884  6142 net.cpp:137] Memory required for data: 722785320
I0601 18:37:38.406890  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1
I0601 18:37:38.406904  6142 net.cpp:84] Creating Layer conv6_1/sep1
I0601 18:37:38.406911  6142 net.cpp:406] conv6_1/sep1 <- conv5_3/Eltwise1
I0601 18:37:38.406924  6142 net.cpp:380] conv6_1/sep1 -> conv6_1/sep1
I0601 18:37:38.410553  6142 net.cpp:122] Setting up conv6_1/sep1
I0601 18:37:38.410580  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.410586  6142 net.cpp:137] Memory required for data: 726548520
I0601 18:37:38.410595  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/bn
I0601 18:37:38.410605  6142 net.cpp:84] Creating Layer conv6_1/sep1/bn
I0601 18:37:38.410611  6142 net.cpp:406] conv6_1/sep1/bn <- conv6_1/sep1
I0601 18:37:38.410621  6142 net.cpp:367] conv6_1/sep1/bn -> conv6_1/sep1 (in-place)
I0601 18:37:38.410951  6142 net.cpp:122] Setting up conv6_1/sep1/bn
I0601 18:37:38.410964  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.410970  6142 net.cpp:137] Memory required for data: 730311720
I0601 18:37:38.410981  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/scale
I0601 18:37:38.410990  6142 net.cpp:84] Creating Layer conv6_1/sep1/scale
I0601 18:37:38.410996  6142 net.cpp:406] conv6_1/sep1/scale <- conv6_1/sep1
I0601 18:37:38.411005  6142 net.cpp:367] conv6_1/sep1/scale -> conv6_1/sep1 (in-place)
I0601 18:37:38.411077  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/scale
I0601 18:37:38.411273  6142 net.cpp:122] Setting up conv6_1/sep1/scale
I0601 18:37:38.411288  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.411293  6142 net.cpp:137] Memory required for data: 734074920
I0601 18:37:38.411301  6142 layer_factory.cpp:63] Creating layer conv6_1/sep1/ReLU
I0601 18:37:38.411310  6142 net.cpp:84] Creating Layer conv6_1/sep1/ReLU
I0601 18:37:38.411315  6142 net.cpp:406] conv6_1/sep1/ReLU <- conv6_1/sep1
I0601 18:37:38.411325  6142 net.cpp:367] conv6_1/sep1/ReLU -> conv6_1/sep1 (in-place)
I0601 18:37:38.412256  6142 net.cpp:122] Setting up conv6_1/sep1/ReLU
I0601 18:37:38.412281  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.412286  6142 net.cpp:137] Memory required for data: 737838120
I0601 18:37:38.412292  6142 layer_factory.cpp:63] Creating layer conv6_1/dw
I0601 18:37:38.412302  6142 net.cpp:84] Creating Layer conv6_1/dw
I0601 18:37:38.412308  6142 net.cpp:406] conv6_1/dw <- conv6_1/sep1
I0601 18:37:38.412320  6142 net.cpp:380] conv6_1/dw -> conv6_1/dw
I0601 18:37:38.412602  6142 net.cpp:122] Setting up conv6_1/dw
I0601 18:37:38.412621  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.412626  6142 net.cpp:137] Memory required for data: 741601320
I0601 18:37:38.412633  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/bn
I0601 18:37:38.412660  6142 net.cpp:84] Creating Layer conv6_1/dw/bn
I0601 18:37:38.412667  6142 net.cpp:406] conv6_1/dw/bn <- conv6_1/dw
I0601 18:37:38.412678  6142 net.cpp:367] conv6_1/dw/bn -> conv6_1/dw (in-place)
I0601 18:37:38.412999  6142 net.cpp:122] Setting up conv6_1/dw/bn
I0601 18:37:38.413013  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.413019  6142 net.cpp:137] Memory required for data: 745364520
I0601 18:37:38.413031  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/scale
I0601 18:37:38.413043  6142 net.cpp:84] Creating Layer conv6_1/dw/scale
I0601 18:37:38.413048  6142 net.cpp:406] conv6_1/dw/scale <- conv6_1/dw
I0601 18:37:38.413055  6142 net.cpp:367] conv6_1/dw/scale -> conv6_1/dw (in-place)
I0601 18:37:38.413117  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/scale
I0601 18:37:38.413307  6142 net.cpp:122] Setting up conv6_1/dw/scale
I0601 18:37:38.413321  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.413326  6142 net.cpp:137] Memory required for data: 749127720
I0601 18:37:38.413334  6142 layer_factory.cpp:63] Creating layer conv6_1/dw/ReLU
I0601 18:37:38.413342  6142 net.cpp:84] Creating Layer conv6_1/dw/ReLU
I0601 18:37:38.413348  6142 net.cpp:406] conv6_1/dw/ReLU <- conv6_1/dw
I0601 18:37:38.413357  6142 net.cpp:367] conv6_1/dw/ReLU -> conv6_1/dw (in-place)
I0601 18:37:38.414291  6142 net.cpp:122] Setting up conv6_1/dw/ReLU
I0601 18:37:38.414314  6142 net.cpp:129] Top shape: 10 480 14 14 (940800)
I0601 18:37:38.414320  6142 net.cpp:137] Memory required for data: 752890920
I0601 18:37:38.414326  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2
I0601 18:37:38.414340  6142 net.cpp:84] Creating Layer conv6_1/sep2
I0601 18:37:38.414347  6142 net.cpp:406] conv6_1/sep2 <- conv6_1/dw
I0601 18:37:38.414356  6142 net.cpp:380] conv6_1/sep2 -> conv6_1/sep2
I0601 18:37:38.418977  6142 net.cpp:122] Setting up conv6_1/sep2
I0601 18:37:38.419001  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.419008  6142 net.cpp:137] Memory required for data: 753643560
I0601 18:37:38.419016  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/bn
I0601 18:37:38.419026  6142 net.cpp:84] Creating Layer conv6_1/sep2/bn
I0601 18:37:38.419032  6142 net.cpp:406] conv6_1/sep2/bn <- conv6_1/sep2
I0601 18:37:38.419044  6142 net.cpp:367] conv6_1/sep2/bn -> conv6_1/sep2 (in-place)
I0601 18:37:38.419395  6142 net.cpp:122] Setting up conv6_1/sep2/bn
I0601 18:37:38.419411  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.419416  6142 net.cpp:137] Memory required for data: 754396200
I0601 18:37:38.419428  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/scale
I0601 18:37:38.419437  6142 net.cpp:84] Creating Layer conv6_1/sep2/scale
I0601 18:37:38.419443  6142 net.cpp:406] conv6_1/sep2/scale <- conv6_1/sep2
I0601 18:37:38.419450  6142 net.cpp:367] conv6_1/sep2/scale -> conv6_1/sep2 (in-place)
I0601 18:37:38.419517  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/scale
I0601 18:37:38.419704  6142 net.cpp:122] Setting up conv6_1/sep2/scale
I0601 18:37:38.419718  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.419723  6142 net.cpp:137] Memory required for data: 755148840
I0601 18:37:38.419732  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2/ReLU
I0601 18:37:38.419740  6142 net.cpp:84] Creating Layer conv6_1/sep2/ReLU
I0601 18:37:38.419746  6142 net.cpp:406] conv6_1/sep2/ReLU <- conv6_1/sep2
I0601 18:37:38.419755  6142 net.cpp:367] conv6_1/sep2/ReLU -> conv6_1/sep2 (in-place)
I0601 18:37:38.420696  6142 net.cpp:122] Setting up conv6_1/sep2/ReLU
I0601 18:37:38.420718  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.420724  6142 net.cpp:137] Memory required for data: 755901480
I0601 18:37:38.420729  6142 layer_factory.cpp:63] Creating layer conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.420739  6142 net.cpp:84] Creating Layer conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.420745  6142 net.cpp:406] conv6_1/sep2_conv6_1/sep2/ReLU_0_split <- conv6_1/sep2
I0601 18:37:38.420758  6142 net.cpp:380] conv6_1/sep2_conv6_1/sep2/ReLU_0_split -> conv6_1/sep2_conv6_1/sep2/ReLU_0_split_0
I0601 18:37:38.420787  6142 net.cpp:380] conv6_1/sep2_conv6_1/sep2/ReLU_0_split -> conv6_1/sep2_conv6_1/sep2/ReLU_0_split_1
I0601 18:37:38.420862  6142 net.cpp:122] Setting up conv6_1/sep2_conv6_1/sep2/ReLU_0_split
I0601 18:37:38.420872  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.420879  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.420883  6142 net.cpp:137] Memory required for data: 757406760
I0601 18:37:38.420889  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1
I0601 18:37:38.420902  6142 net.cpp:84] Creating Layer conv6_2/sep1
I0601 18:37:38.420909  6142 net.cpp:406] conv6_2/sep1 <- conv6_1/sep2_conv6_1/sep2/ReLU_0_split_0
I0601 18:37:38.420917  6142 net.cpp:380] conv6_2/sep1 -> conv6_2/sep1
I0601 18:37:38.425477  6142 net.cpp:122] Setting up conv6_2/sep1
I0601 18:37:38.425503  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.425508  6142 net.cpp:137] Memory required for data: 761922600
I0601 18:37:38.425518  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/bn
I0601 18:37:38.425529  6142 net.cpp:84] Creating Layer conv6_2/sep1/bn
I0601 18:37:38.425536  6142 net.cpp:406] conv6_2/sep1/bn <- conv6_2/sep1
I0601 18:37:38.425544  6142 net.cpp:367] conv6_2/sep1/bn -> conv6_2/sep1 (in-place)
I0601 18:37:38.425896  6142 net.cpp:122] Setting up conv6_2/sep1/bn
I0601 18:37:38.425910  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.425915  6142 net.cpp:137] Memory required for data: 766438440
I0601 18:37:38.425927  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/scale
I0601 18:37:38.425938  6142 net.cpp:84] Creating Layer conv6_2/sep1/scale
I0601 18:37:38.425945  6142 net.cpp:406] conv6_2/sep1/scale <- conv6_2/sep1
I0601 18:37:38.425951  6142 net.cpp:367] conv6_2/sep1/scale -> conv6_2/sep1 (in-place)
I0601 18:37:38.426017  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/scale
I0601 18:37:38.426209  6142 net.cpp:122] Setting up conv6_2/sep1/scale
I0601 18:37:38.426223  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.426228  6142 net.cpp:137] Memory required for data: 770954280
I0601 18:37:38.426236  6142 layer_factory.cpp:63] Creating layer conv6_2/sep1/ReLU
I0601 18:37:38.426247  6142 net.cpp:84] Creating Layer conv6_2/sep1/ReLU
I0601 18:37:38.426254  6142 net.cpp:406] conv6_2/sep1/ReLU <- conv6_2/sep1
I0601 18:37:38.426260  6142 net.cpp:367] conv6_2/sep1/ReLU -> conv6_2/sep1 (in-place)
I0601 18:37:38.427206  6142 net.cpp:122] Setting up conv6_2/sep1/ReLU
I0601 18:37:38.427229  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.427234  6142 net.cpp:137] Memory required for data: 775470120
I0601 18:37:38.427240  6142 layer_factory.cpp:63] Creating layer conv6_2/dw
I0601 18:37:38.427253  6142 net.cpp:84] Creating Layer conv6_2/dw
I0601 18:37:38.427260  6142 net.cpp:406] conv6_2/dw <- conv6_2/sep1
I0601 18:37:38.427271  6142 net.cpp:380] conv6_2/dw -> conv6_2/dw
I0601 18:37:38.427577  6142 net.cpp:122] Setting up conv6_2/dw
I0601 18:37:38.427595  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.427600  6142 net.cpp:137] Memory required for data: 779985960
I0601 18:37:38.427608  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/bn
I0601 18:37:38.427619  6142 net.cpp:84] Creating Layer conv6_2/dw/bn
I0601 18:37:38.427626  6142 net.cpp:406] conv6_2/dw/bn <- conv6_2/dw
I0601 18:37:38.427634  6142 net.cpp:367] conv6_2/dw/bn -> conv6_2/dw (in-place)
I0601 18:37:38.427966  6142 net.cpp:122] Setting up conv6_2/dw/bn
I0601 18:37:38.427979  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.427984  6142 net.cpp:137] Memory required for data: 784501800
I0601 18:37:38.427996  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/scale
I0601 18:37:38.428004  6142 net.cpp:84] Creating Layer conv6_2/dw/scale
I0601 18:37:38.428010  6142 net.cpp:406] conv6_2/dw/scale <- conv6_2/dw
I0601 18:37:38.428017  6142 net.cpp:367] conv6_2/dw/scale -> conv6_2/dw (in-place)
I0601 18:37:38.428107  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/scale
I0601 18:37:38.428299  6142 net.cpp:122] Setting up conv6_2/dw/scale
I0601 18:37:38.428315  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.428320  6142 net.cpp:137] Memory required for data: 789017640
I0601 18:37:38.428329  6142 layer_factory.cpp:63] Creating layer conv6_2/dw/ReLU
I0601 18:37:38.428337  6142 net.cpp:84] Creating Layer conv6_2/dw/ReLU
I0601 18:37:38.428344  6142 net.cpp:406] conv6_2/dw/ReLU <- conv6_2/dw
I0601 18:37:38.428350  6142 net.cpp:367] conv6_2/dw/ReLU -> conv6_2/dw (in-place)
I0601 18:37:38.429291  6142 net.cpp:122] Setting up conv6_2/dw/ReLU
I0601 18:37:38.429313  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.429319  6142 net.cpp:137] Memory required for data: 793533480
I0601 18:37:38.429325  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2
I0601 18:37:38.429339  6142 net.cpp:84] Creating Layer conv6_2/sep2
I0601 18:37:38.429347  6142 net.cpp:406] conv6_2/sep2 <- conv6_2/dw
I0601 18:37:38.429358  6142 net.cpp:380] conv6_2/sep2 -> conv6_2/sep2
I0601 18:37:38.433334  6142 net.cpp:122] Setting up conv6_2/sep2
I0601 18:37:38.433358  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.433364  6142 net.cpp:137] Memory required for data: 794286120
I0601 18:37:38.433373  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/bn
I0601 18:37:38.433385  6142 net.cpp:84] Creating Layer conv6_2/sep2/bn
I0601 18:37:38.433393  6142 net.cpp:406] conv6_2/sep2/bn <- conv6_2/sep2
I0601 18:37:38.433403  6142 net.cpp:367] conv6_2/sep2/bn -> conv6_2/sep2 (in-place)
I0601 18:37:38.433737  6142 net.cpp:122] Setting up conv6_2/sep2/bn
I0601 18:37:38.433751  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.433756  6142 net.cpp:137] Memory required for data: 795038760
I0601 18:37:38.433768  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/scale
I0601 18:37:38.433779  6142 net.cpp:84] Creating Layer conv6_2/sep2/scale
I0601 18:37:38.433784  6142 net.cpp:406] conv6_2/sep2/scale <- conv6_2/sep2
I0601 18:37:38.433792  6142 net.cpp:367] conv6_2/sep2/scale -> conv6_2/sep2 (in-place)
I0601 18:37:38.433858  6142 layer_factory.cpp:63] Creating layer conv6_2/sep2/scale
I0601 18:37:38.434052  6142 net.cpp:122] Setting up conv6_2/sep2/scale
I0601 18:37:38.434065  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.434070  6142 net.cpp:137] Memory required for data: 795791400
I0601 18:37:38.434079  6142 layer_factory.cpp:63] Creating layer conv6_2/Eltwise1
I0601 18:37:38.434089  6142 net.cpp:84] Creating Layer conv6_2/Eltwise1
I0601 18:37:38.434095  6142 net.cpp:406] conv6_2/Eltwise1 <- conv6_1/sep2_conv6_1/sep2/ReLU_0_split_1
I0601 18:37:38.434103  6142 net.cpp:406] conv6_2/Eltwise1 <- conv6_2/sep2
I0601 18:37:38.434113  6142 net.cpp:380] conv6_2/Eltwise1 -> conv6_2/Eltwise1
I0601 18:37:38.434150  6142 net.cpp:122] Setting up conv6_2/Eltwise1
I0601 18:37:38.434159  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.434163  6142 net.cpp:137] Memory required for data: 796544040
I0601 18:37:38.434168  6142 layer_factory.cpp:63] Creating layer conv6_2/Eltwise/ReLU
I0601 18:37:38.434180  6142 net.cpp:84] Creating Layer conv6_2/Eltwise/ReLU
I0601 18:37:38.434185  6142 net.cpp:406] conv6_2/Eltwise/ReLU <- conv6_2/Eltwise1
I0601 18:37:38.434192  6142 net.cpp:367] conv6_2/Eltwise/ReLU -> conv6_2/Eltwise1 (in-place)
I0601 18:37:38.435808  6142 net.cpp:122] Setting up conv6_2/Eltwise/ReLU
I0601 18:37:38.435835  6142 net.cpp:129] Top shape: 10 96 14 14 (188160)
I0601 18:37:38.435842  6142 net.cpp:137] Memory required for data: 797296680
I0601 18:37:38.435847  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1
I0601 18:37:38.435861  6142 net.cpp:84] Creating Layer conv7_1/sep1
I0601 18:37:38.435868  6142 net.cpp:406] conv7_1/sep1 <- conv6_2/Eltwise1
I0601 18:37:38.435878  6142 net.cpp:380] conv7_1/sep1 -> conv7_1/sep1
I0601 18:37:38.440033  6142 net.cpp:122] Setting up conv7_1/sep1
I0601 18:37:38.440058  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.440083  6142 net.cpp:137] Memory required for data: 801812520
I0601 18:37:38.440091  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/bn
I0601 18:37:38.440104  6142 net.cpp:84] Creating Layer conv7_1/sep1/bn
I0601 18:37:38.440111  6142 net.cpp:406] conv7_1/sep1/bn <- conv7_1/sep1
I0601 18:37:38.440119  6142 net.cpp:367] conv7_1/sep1/bn -> conv7_1/sep1 (in-place)
I0601 18:37:38.440459  6142 net.cpp:122] Setting up conv7_1/sep1/bn
I0601 18:37:38.440472  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.440477  6142 net.cpp:137] Memory required for data: 806328360
I0601 18:37:38.440490  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/scale
I0601 18:37:38.440498  6142 net.cpp:84] Creating Layer conv7_1/sep1/scale
I0601 18:37:38.440503  6142 net.cpp:406] conv7_1/sep1/scale <- conv7_1/sep1
I0601 18:37:38.440511  6142 net.cpp:367] conv7_1/sep1/scale -> conv7_1/sep1 (in-place)
I0601 18:37:38.440580  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/scale
I0601 18:37:38.440773  6142 net.cpp:122] Setting up conv7_1/sep1/scale
I0601 18:37:38.440788  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.440793  6142 net.cpp:137] Memory required for data: 810844200
I0601 18:37:38.440801  6142 layer_factory.cpp:63] Creating layer conv7_1/sep1/ReLU
I0601 18:37:38.440810  6142 net.cpp:84] Creating Layer conv7_1/sep1/ReLU
I0601 18:37:38.440815  6142 net.cpp:406] conv7_1/sep1/ReLU <- conv7_1/sep1
I0601 18:37:38.440822  6142 net.cpp:367] conv7_1/sep1/ReLU -> conv7_1/sep1 (in-place)
I0601 18:37:38.441566  6142 net.cpp:122] Setting up conv7_1/sep1/ReLU
I0601 18:37:38.441586  6142 net.cpp:129] Top shape: 10 576 14 14 (1128960)
I0601 18:37:38.441591  6142 net.cpp:137] Memory required for data: 815360040
I0601 18:37:38.441597  6142 layer_factory.cpp:63] Creating layer conv7_1/dw
I0601 18:37:38.441609  6142 net.cpp:84] Creating Layer conv7_1/dw
I0601 18:37:38.441615  6142 net.cpp:406] conv7_1/dw <- conv7_1/sep1
I0601 18:37:38.441624  6142 net.cpp:380] conv7_1/dw -> conv7_1/dw
I0601 18:37:38.442086  6142 net.cpp:122] Setting up conv7_1/dw
I0601 18:37:38.442106  6142 net.cpp:129] Top shape: 10 576 7 7 (282240)
I0601 18:37:38.442111  6142 net.cpp:137] Memory required for data: 816489000
I0601 18:37:38.442118  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/bn
I0601 18:37:38.442128  6142 net.cpp:84] Creating Layer conv7_1/dw/bn
I0601 18:37:38.442134  6142 net.cpp:406] conv7_1/dw/bn <- conv7_1/dw
I0601 18:37:38.442145  6142 net.cpp:367] conv7_1/dw/bn -> conv7_1/dw (in-place)
I0601 18:37:38.442497  6142 net.cpp:122] Setting up conv7_1/dw/bn
I0601 18:37:38.442510  6142 net.cpp:129] Top shape: 10 576 7 7 (282240)
I0601 18:37:38.442515  6142 net.cpp:137] Memory required for data: 817617960
I0601 18:37:38.442528  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/scale
I0601 18:37:38.442538  6142 net.cpp:84] Creating Layer conv7_1/dw/scale
I0601 18:37:38.442544  6142 net.cpp:406] conv7_1/dw/scale <- conv7_1/dw
I0601 18:37:38.442551  6142 net.cpp:367] conv7_1/dw/scale -> conv7_1/dw (in-place)
I0601 18:37:38.442613  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/scale
I0601 18:37:38.442804  6142 net.cpp:122] Setting up conv7_1/dw/scale
I0601 18:37:38.442817  6142 net.cpp:129] Top shape: 10 576 7 7 (282240)
I0601 18:37:38.442822  6142 net.cpp:137] Memory required for data: 818746920
I0601 18:37:38.442831  6142 layer_factory.cpp:63] Creating layer conv7_1/dw/ReLU
I0601 18:37:38.442839  6142 net.cpp:84] Creating Layer conv7_1/dw/ReLU
I0601 18:37:38.442845  6142 net.cpp:406] conv7_1/dw/ReLU <- conv7_1/dw
I0601 18:37:38.442857  6142 net.cpp:367] conv7_1/dw/ReLU -> conv7_1/dw (in-place)
I0601 18:37:38.443812  6142 net.cpp:122] Setting up conv7_1/dw/ReLU
I0601 18:37:38.443836  6142 net.cpp:129] Top shape: 10 576 7 7 (282240)
I0601 18:37:38.443842  6142 net.cpp:137] Memory required for data: 819875880
I0601 18:37:38.443848  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2
I0601 18:37:38.443862  6142 net.cpp:84] Creating Layer conv7_1/sep2
I0601 18:37:38.443868  6142 net.cpp:406] conv7_1/sep2 <- conv7_1/dw
I0601 18:37:38.443897  6142 net.cpp:380] conv7_1/sep2 -> conv7_1/sep2
I0601 18:37:38.449899  6142 net.cpp:122] Setting up conv7_1/sep2
I0601 18:37:38.449924  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.449930  6142 net.cpp:137] Memory required for data: 820252200
I0601 18:37:38.449939  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/bn
I0601 18:37:38.449951  6142 net.cpp:84] Creating Layer conv7_1/sep2/bn
I0601 18:37:38.449959  6142 net.cpp:406] conv7_1/sep2/bn <- conv7_1/sep2
I0601 18:37:38.449966  6142 net.cpp:367] conv7_1/sep2/bn -> conv7_1/sep2 (in-place)
I0601 18:37:38.450309  6142 net.cpp:122] Setting up conv7_1/sep2/bn
I0601 18:37:38.450322  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.450327  6142 net.cpp:137] Memory required for data: 820628520
I0601 18:37:38.450340  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/scale
I0601 18:37:38.450348  6142 net.cpp:84] Creating Layer conv7_1/sep2/scale
I0601 18:37:38.450354  6142 net.cpp:406] conv7_1/sep2/scale <- conv7_1/sep2
I0601 18:37:38.450361  6142 net.cpp:367] conv7_1/sep2/scale -> conv7_1/sep2 (in-place)
I0601 18:37:38.450428  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/scale
I0601 18:37:38.450618  6142 net.cpp:122] Setting up conv7_1/sep2/scale
I0601 18:37:38.450630  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.450635  6142 net.cpp:137] Memory required for data: 821004840
I0601 18:37:38.450644  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2/ReLU
I0601 18:37:38.450654  6142 net.cpp:84] Creating Layer conv7_1/sep2/ReLU
I0601 18:37:38.450660  6142 net.cpp:406] conv7_1/sep2/ReLU <- conv7_1/sep2
I0601 18:37:38.450667  6142 net.cpp:367] conv7_1/sep2/ReLU -> conv7_1/sep2 (in-place)
I0601 18:37:38.451419  6142 net.cpp:122] Setting up conv7_1/sep2/ReLU
I0601 18:37:38.451442  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.451447  6142 net.cpp:137] Memory required for data: 821381160
I0601 18:37:38.451453  6142 layer_factory.cpp:63] Creating layer conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.451462  6142 net.cpp:84] Creating Layer conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.451468  6142 net.cpp:406] conv7_1/sep2_conv7_1/sep2/ReLU_0_split <- conv7_1/sep2
I0601 18:37:38.451480  6142 net.cpp:380] conv7_1/sep2_conv7_1/sep2/ReLU_0_split -> conv7_1/sep2_conv7_1/sep2/ReLU_0_split_0
I0601 18:37:38.451491  6142 net.cpp:380] conv7_1/sep2_conv7_1/sep2/ReLU_0_split -> conv7_1/sep2_conv7_1/sep2/ReLU_0_split_1
I0601 18:37:38.451565  6142 net.cpp:122] Setting up conv7_1/sep2_conv7_1/sep2/ReLU_0_split
I0601 18:37:38.451575  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.451581  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.451586  6142 net.cpp:137] Memory required for data: 822133800
I0601 18:37:38.451591  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1
I0601 18:37:38.451604  6142 net.cpp:84] Creating Layer conv7_2/sep1
I0601 18:37:38.451611  6142 net.cpp:406] conv7_2/sep1 <- conv7_1/sep2_conv7_1/sep2/ReLU_0_split_0
I0601 18:37:38.451618  6142 net.cpp:380] conv7_2/sep1 -> conv7_2/sep1
I0601 18:37:38.460217  6142 net.cpp:122] Setting up conv7_2/sep1
I0601 18:37:38.460244  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.460250  6142 net.cpp:137] Memory required for data: 824391720
I0601 18:37:38.460259  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/bn
I0601 18:37:38.460269  6142 net.cpp:84] Creating Layer conv7_2/sep1/bn
I0601 18:37:38.460275  6142 net.cpp:406] conv7_2/sep1/bn <- conv7_2/sep1
I0601 18:37:38.460286  6142 net.cpp:367] conv7_2/sep1/bn -> conv7_2/sep1 (in-place)
I0601 18:37:38.460606  6142 net.cpp:122] Setting up conv7_2/sep1/bn
I0601 18:37:38.460620  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.460625  6142 net.cpp:137] Memory required for data: 826649640
I0601 18:37:38.460636  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/scale
I0601 18:37:38.460645  6142 net.cpp:84] Creating Layer conv7_2/sep1/scale
I0601 18:37:38.460651  6142 net.cpp:406] conv7_2/sep1/scale <- conv7_2/sep1
I0601 18:37:38.460677  6142 net.cpp:367] conv7_2/sep1/scale -> conv7_2/sep1 (in-place)
I0601 18:37:38.460748  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/scale
I0601 18:37:38.460923  6142 net.cpp:122] Setting up conv7_2/sep1/scale
I0601 18:37:38.460937  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.460942  6142 net.cpp:137] Memory required for data: 828907560
I0601 18:37:38.460952  6142 layer_factory.cpp:63] Creating layer conv7_2/sep1/ReLU
I0601 18:37:38.460960  6142 net.cpp:84] Creating Layer conv7_2/sep1/ReLU
I0601 18:37:38.460965  6142 net.cpp:406] conv7_2/sep1/ReLU <- conv7_2/sep1
I0601 18:37:38.460975  6142 net.cpp:367] conv7_2/sep1/ReLU -> conv7_2/sep1 (in-place)
I0601 18:37:38.461721  6142 net.cpp:122] Setting up conv7_2/sep1/ReLU
I0601 18:37:38.461743  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.461750  6142 net.cpp:137] Memory required for data: 831165480
I0601 18:37:38.461755  6142 layer_factory.cpp:63] Creating layer conv7_2/dw
I0601 18:37:38.461766  6142 net.cpp:84] Creating Layer conv7_2/dw
I0601 18:37:38.461771  6142 net.cpp:406] conv7_2/dw <- conv7_2/sep1
I0601 18:37:38.461782  6142 net.cpp:380] conv7_2/dw -> conv7_2/dw
I0601 18:37:38.462515  6142 net.cpp:122] Setting up conv7_2/dw
I0601 18:37:38.462535  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.462540  6142 net.cpp:137] Memory required for data: 833423400
I0601 18:37:38.462548  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/bn
I0601 18:37:38.462559  6142 net.cpp:84] Creating Layer conv7_2/dw/bn
I0601 18:37:38.462566  6142 net.cpp:406] conv7_2/dw/bn <- conv7_2/dw
I0601 18:37:38.462574  6142 net.cpp:367] conv7_2/dw/bn -> conv7_2/dw (in-place)
I0601 18:37:38.462904  6142 net.cpp:122] Setting up conv7_2/dw/bn
I0601 18:37:38.462918  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.462922  6142 net.cpp:137] Memory required for data: 835681320
I0601 18:37:38.462934  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/scale
I0601 18:37:38.462944  6142 net.cpp:84] Creating Layer conv7_2/dw/scale
I0601 18:37:38.462949  6142 net.cpp:406] conv7_2/dw/scale <- conv7_2/dw
I0601 18:37:38.462958  6142 net.cpp:367] conv7_2/dw/scale -> conv7_2/dw (in-place)
I0601 18:37:38.463022  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/scale
I0601 18:37:38.463212  6142 net.cpp:122] Setting up conv7_2/dw/scale
I0601 18:37:38.463227  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.463232  6142 net.cpp:137] Memory required for data: 837939240
I0601 18:37:38.463241  6142 layer_factory.cpp:63] Creating layer conv7_2/dw/ReLU
I0601 18:37:38.463251  6142 net.cpp:84] Creating Layer conv7_2/dw/ReLU
I0601 18:37:38.463258  6142 net.cpp:406] conv7_2/dw/ReLU <- conv7_2/dw
I0601 18:37:38.463265  6142 net.cpp:367] conv7_2/dw/ReLU -> conv7_2/dw (in-place)
I0601 18:37:38.464218  6142 net.cpp:122] Setting up conv7_2/dw/ReLU
I0601 18:37:38.464241  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.464246  6142 net.cpp:137] Memory required for data: 840197160
I0601 18:37:38.464252  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2
I0601 18:37:38.464267  6142 net.cpp:84] Creating Layer conv7_2/sep2
I0601 18:37:38.464273  6142 net.cpp:406] conv7_2/sep2 <- conv7_2/dw
I0601 18:37:38.464287  6142 net.cpp:380] conv7_2/sep2 -> conv7_2/sep2
I0601 18:37:38.472177  6142 net.cpp:122] Setting up conv7_2/sep2
I0601 18:37:38.472203  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.472208  6142 net.cpp:137] Memory required for data: 840573480
I0601 18:37:38.472218  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/bn
I0601 18:37:38.472230  6142 net.cpp:84] Creating Layer conv7_2/sep2/bn
I0601 18:37:38.472237  6142 net.cpp:406] conv7_2/sep2/bn <- conv7_2/sep2
I0601 18:37:38.472247  6142 net.cpp:367] conv7_2/sep2/bn -> conv7_2/sep2 (in-place)
I0601 18:37:38.472579  6142 net.cpp:122] Setting up conv7_2/sep2/bn
I0601 18:37:38.472594  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.472599  6142 net.cpp:137] Memory required for data: 840949800
I0601 18:37:38.472630  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/scale
I0601 18:37:38.472641  6142 net.cpp:84] Creating Layer conv7_2/sep2/scale
I0601 18:37:38.472648  6142 net.cpp:406] conv7_2/sep2/scale <- conv7_2/sep2
I0601 18:37:38.472656  6142 net.cpp:367] conv7_2/sep2/scale -> conv7_2/sep2 (in-place)
I0601 18:37:38.472725  6142 layer_factory.cpp:63] Creating layer conv7_2/sep2/scale
I0601 18:37:38.472921  6142 net.cpp:122] Setting up conv7_2/sep2/scale
I0601 18:37:38.472935  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.472940  6142 net.cpp:137] Memory required for data: 841326120
I0601 18:37:38.472949  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise1
I0601 18:37:38.472961  6142 net.cpp:84] Creating Layer conv7_2/Eltwise1
I0601 18:37:38.472967  6142 net.cpp:406] conv7_2/Eltwise1 <- conv7_1/sep2_conv7_1/sep2/ReLU_0_split_1
I0601 18:37:38.472975  6142 net.cpp:406] conv7_2/Eltwise1 <- conv7_2/sep2
I0601 18:37:38.472985  6142 net.cpp:380] conv7_2/Eltwise1 -> conv7_2/Eltwise1
I0601 18:37:38.473022  6142 net.cpp:122] Setting up conv7_2/Eltwise1
I0601 18:37:38.473031  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.473037  6142 net.cpp:137] Memory required for data: 841702440
I0601 18:37:38.473042  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise/ReLU
I0601 18:37:38.473052  6142 net.cpp:84] Creating Layer conv7_2/Eltwise/ReLU
I0601 18:37:38.473057  6142 net.cpp:406] conv7_2/Eltwise/ReLU <- conv7_2/Eltwise1
I0601 18:37:38.473065  6142 net.cpp:367] conv7_2/Eltwise/ReLU -> conv7_2/Eltwise1 (in-place)
I0601 18:37:38.473804  6142 net.cpp:122] Setting up conv7_2/Eltwise/ReLU
I0601 18:37:38.473825  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.473830  6142 net.cpp:137] Memory required for data: 842078760
I0601 18:37:38.473836  6142 layer_factory.cpp:63] Creating layer conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.473847  6142 net.cpp:84] Creating Layer conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.473855  6142 net.cpp:406] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split <- conv7_2/Eltwise1
I0601 18:37:38.473863  6142 net.cpp:380] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split -> conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.473876  6142 net.cpp:380] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split -> conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.473946  6142 net.cpp:122] Setting up conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split
I0601 18:37:38.473956  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.473963  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.473968  6142 net.cpp:137] Memory required for data: 842831400
I0601 18:37:38.473973  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1
I0601 18:37:38.473986  6142 net.cpp:84] Creating Layer conv7_3/sep1
I0601 18:37:38.473992  6142 net.cpp:406] conv7_3/sep1 <- conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_0
I0601 18:37:38.474004  6142 net.cpp:380] conv7_3/sep1 -> conv7_3/sep1
I0601 18:37:38.482602  6142 net.cpp:122] Setting up conv7_3/sep1
I0601 18:37:38.482628  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.482635  6142 net.cpp:137] Memory required for data: 845089320
I0601 18:37:38.482643  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/bn
I0601 18:37:38.482653  6142 net.cpp:84] Creating Layer conv7_3/sep1/bn
I0601 18:37:38.482659  6142 net.cpp:406] conv7_3/sep1/bn <- conv7_3/sep1
I0601 18:37:38.482673  6142 net.cpp:367] conv7_3/sep1/bn -> conv7_3/sep1 (in-place)
I0601 18:37:38.483017  6142 net.cpp:122] Setting up conv7_3/sep1/bn
I0601 18:37:38.483032  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.483038  6142 net.cpp:137] Memory required for data: 847347240
I0601 18:37:38.483049  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/scale
I0601 18:37:38.483069  6142 net.cpp:84] Creating Layer conv7_3/sep1/scale
I0601 18:37:38.483076  6142 net.cpp:406] conv7_3/sep1/scale <- conv7_3/sep1
I0601 18:37:38.483083  6142 net.cpp:367] conv7_3/sep1/scale -> conv7_3/sep1 (in-place)
I0601 18:37:38.483178  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/scale
I0601 18:37:38.483356  6142 net.cpp:122] Setting up conv7_3/sep1/scale
I0601 18:37:38.483371  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.483376  6142 net.cpp:137] Memory required for data: 849605160
I0601 18:37:38.483407  6142 layer_factory.cpp:63] Creating layer conv7_3/sep1/ReLU
I0601 18:37:38.483417  6142 net.cpp:84] Creating Layer conv7_3/sep1/ReLU
I0601 18:37:38.483422  6142 net.cpp:406] conv7_3/sep1/ReLU <- conv7_3/sep1
I0601 18:37:38.483429  6142 net.cpp:367] conv7_3/sep1/ReLU -> conv7_3/sep1 (in-place)
I0601 18:37:38.484380  6142 net.cpp:122] Setting up conv7_3/sep1/ReLU
I0601 18:37:38.484402  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.484408  6142 net.cpp:137] Memory required for data: 851863080
I0601 18:37:38.484413  6142 layer_factory.cpp:63] Creating layer conv7_3/dw
I0601 18:37:38.484424  6142 net.cpp:84] Creating Layer conv7_3/dw
I0601 18:37:38.484431  6142 net.cpp:406] conv7_3/dw <- conv7_3/sep1
I0601 18:37:38.484442  6142 net.cpp:380] conv7_3/dw -> conv7_3/dw
I0601 18:37:38.485167  6142 net.cpp:122] Setting up conv7_3/dw
I0601 18:37:38.485188  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.485193  6142 net.cpp:137] Memory required for data: 854121000
I0601 18:37:38.485200  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/bn
I0601 18:37:38.485213  6142 net.cpp:84] Creating Layer conv7_3/dw/bn
I0601 18:37:38.485219  6142 net.cpp:406] conv7_3/dw/bn <- conv7_3/dw
I0601 18:37:38.485226  6142 net.cpp:367] conv7_3/dw/bn -> conv7_3/dw (in-place)
I0601 18:37:38.485545  6142 net.cpp:122] Setting up conv7_3/dw/bn
I0601 18:37:38.485559  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.485564  6142 net.cpp:137] Memory required for data: 856378920
I0601 18:37:38.485576  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/scale
I0601 18:37:38.485587  6142 net.cpp:84] Creating Layer conv7_3/dw/scale
I0601 18:37:38.485594  6142 net.cpp:406] conv7_3/dw/scale <- conv7_3/dw
I0601 18:37:38.485600  6142 net.cpp:367] conv7_3/dw/scale -> conv7_3/dw (in-place)
I0601 18:37:38.485666  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/scale
I0601 18:37:38.485843  6142 net.cpp:122] Setting up conv7_3/dw/scale
I0601 18:37:38.485857  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.485862  6142 net.cpp:137] Memory required for data: 858636840
I0601 18:37:38.485870  6142 layer_factory.cpp:63] Creating layer conv7_3/dw/ReLU
I0601 18:37:38.485878  6142 net.cpp:84] Creating Layer conv7_3/dw/ReLU
I0601 18:37:38.485883  6142 net.cpp:406] conv7_3/dw/ReLU <- conv7_3/dw
I0601 18:37:38.485893  6142 net.cpp:367] conv7_3/dw/ReLU -> conv7_3/dw (in-place)
I0601 18:37:38.486636  6142 net.cpp:122] Setting up conv7_3/dw/ReLU
I0601 18:37:38.486656  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.486661  6142 net.cpp:137] Memory required for data: 860894760
I0601 18:37:38.486666  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2
I0601 18:37:38.486680  6142 net.cpp:84] Creating Layer conv7_3/sep2
I0601 18:37:38.486687  6142 net.cpp:406] conv7_3/sep2 <- conv7_3/dw
I0601 18:37:38.486696  6142 net.cpp:380] conv7_3/sep2 -> conv7_3/sep2
I0601 18:37:38.494628  6142 net.cpp:122] Setting up conv7_3/sep2
I0601 18:37:38.494653  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.494659  6142 net.cpp:137] Memory required for data: 861271080
I0601 18:37:38.494668  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/bn
I0601 18:37:38.494680  6142 net.cpp:84] Creating Layer conv7_3/sep2/bn
I0601 18:37:38.494688  6142 net.cpp:406] conv7_3/sep2/bn <- conv7_3/sep2
I0601 18:37:38.494697  6142 net.cpp:367] conv7_3/sep2/bn -> conv7_3/sep2 (in-place)
I0601 18:37:38.495064  6142 net.cpp:122] Setting up conv7_3/sep2/bn
I0601 18:37:38.495079  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.495085  6142 net.cpp:137] Memory required for data: 861647400
I0601 18:37:38.495096  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/scale
I0601 18:37:38.495126  6142 net.cpp:84] Creating Layer conv7_3/sep2/scale
I0601 18:37:38.495133  6142 net.cpp:406] conv7_3/sep2/scale <- conv7_3/sep2
I0601 18:37:38.495141  6142 net.cpp:367] conv7_3/sep2/scale -> conv7_3/sep2 (in-place)
I0601 18:37:38.495223  6142 layer_factory.cpp:63] Creating layer conv7_3/sep2/scale
I0601 18:37:38.495426  6142 net.cpp:122] Setting up conv7_3/sep2/scale
I0601 18:37:38.495440  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.495445  6142 net.cpp:137] Memory required for data: 862023720
I0601 18:37:38.495455  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise1
I0601 18:37:38.495466  6142 net.cpp:84] Creating Layer conv7_3/Eltwise1
I0601 18:37:38.495473  6142 net.cpp:406] conv7_3/Eltwise1 <- conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split_1
I0601 18:37:38.495481  6142 net.cpp:406] conv7_3/Eltwise1 <- conv7_3/sep2
I0601 18:37:38.495491  6142 net.cpp:380] conv7_3/Eltwise1 -> conv7_3/Eltwise1
I0601 18:37:38.495528  6142 net.cpp:122] Setting up conv7_3/Eltwise1
I0601 18:37:38.495537  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.495543  6142 net.cpp:137] Memory required for data: 862400040
I0601 18:37:38.495546  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise/ReLU
I0601 18:37:38.495558  6142 net.cpp:84] Creating Layer conv7_3/Eltwise/ReLU
I0601 18:37:38.495563  6142 net.cpp:406] conv7_3/Eltwise/ReLU <- conv7_3/Eltwise1
I0601 18:37:38.495570  6142 net.cpp:367] conv7_3/Eltwise/ReLU -> conv7_3/Eltwise1 (in-place)
I0601 18:37:38.496697  6142 net.cpp:122] Setting up conv7_3/Eltwise/ReLU
I0601 18:37:38.496721  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.496727  6142 net.cpp:137] Memory required for data: 862776360
I0601 18:37:38.496732  6142 layer_factory.cpp:63] Creating layer conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.496747  6142 net.cpp:84] Creating Layer conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.496753  6142 net.cpp:406] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split <- conv7_3/Eltwise1
I0601 18:37:38.496762  6142 net.cpp:380] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split -> conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_0
I0601 18:37:38.496776  6142 net.cpp:380] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split -> conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_1
I0601 18:37:38.496856  6142 net.cpp:122] Setting up conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split
I0601 18:37:38.496866  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.496873  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.496877  6142 net.cpp:137] Memory required for data: 863529000
I0601 18:37:38.496882  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1
I0601 18:37:38.496896  6142 net.cpp:84] Creating Layer conv7_4/sep1
I0601 18:37:38.496902  6142 net.cpp:406] conv7_4/sep1 <- conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_0
I0601 18:37:38.496913  6142 net.cpp:380] conv7_4/sep1 -> conv7_4/sep1
I0601 18:37:38.505360  6142 net.cpp:122] Setting up conv7_4/sep1
I0601 18:37:38.505385  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.505393  6142 net.cpp:137] Memory required for data: 865786920
I0601 18:37:38.505400  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/bn
I0601 18:37:38.505417  6142 net.cpp:84] Creating Layer conv7_4/sep1/bn
I0601 18:37:38.505424  6142 net.cpp:406] conv7_4/sep1/bn <- conv7_4/sep1
I0601 18:37:38.505434  6142 net.cpp:367] conv7_4/sep1/bn -> conv7_4/sep1 (in-place)
I0601 18:37:38.505755  6142 net.cpp:122] Setting up conv7_4/sep1/bn
I0601 18:37:38.505769  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.505774  6142 net.cpp:137] Memory required for data: 868044840
I0601 18:37:38.505786  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/scale
I0601 18:37:38.505795  6142 net.cpp:84] Creating Layer conv7_4/sep1/scale
I0601 18:37:38.505800  6142 net.cpp:406] conv7_4/sep1/scale <- conv7_4/sep1
I0601 18:37:38.505810  6142 net.cpp:367] conv7_4/sep1/scale -> conv7_4/sep1 (in-place)
I0601 18:37:38.505872  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/scale
I0601 18:37:38.506083  6142 net.cpp:122] Setting up conv7_4/sep1/scale
I0601 18:37:38.506098  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.506103  6142 net.cpp:137] Memory required for data: 870302760
I0601 18:37:38.506111  6142 layer_factory.cpp:63] Creating layer conv7_4/sep1/ReLU
I0601 18:37:38.506120  6142 net.cpp:84] Creating Layer conv7_4/sep1/ReLU
I0601 18:37:38.506126  6142 net.cpp:406] conv7_4/sep1/ReLU <- conv7_4/sep1
I0601 18:37:38.506134  6142 net.cpp:367] conv7_4/sep1/ReLU -> conv7_4/sep1 (in-place)
I0601 18:37:38.507105  6142 net.cpp:122] Setting up conv7_4/sep1/ReLU
I0601 18:37:38.507129  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.507135  6142 net.cpp:137] Memory required for data: 872560680
I0601 18:37:38.507141  6142 layer_factory.cpp:63] Creating layer conv7_4/dw
I0601 18:37:38.507153  6142 net.cpp:84] Creating Layer conv7_4/dw
I0601 18:37:38.507160  6142 net.cpp:406] conv7_4/dw <- conv7_4/sep1
I0601 18:37:38.507171  6142 net.cpp:380] conv7_4/dw -> conv7_4/dw
I0601 18:37:38.507905  6142 net.cpp:122] Setting up conv7_4/dw
I0601 18:37:38.507923  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.507928  6142 net.cpp:137] Memory required for data: 874818600
I0601 18:37:38.507936  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/bn
I0601 18:37:38.507946  6142 net.cpp:84] Creating Layer conv7_4/dw/bn
I0601 18:37:38.507952  6142 net.cpp:406] conv7_4/dw/bn <- conv7_4/dw
I0601 18:37:38.507961  6142 net.cpp:367] conv7_4/dw/bn -> conv7_4/dw (in-place)
I0601 18:37:38.508291  6142 net.cpp:122] Setting up conv7_4/dw/bn
I0601 18:37:38.508306  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.508311  6142 net.cpp:137] Memory required for data: 877076520
I0601 18:37:38.508322  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/scale
I0601 18:37:38.508330  6142 net.cpp:84] Creating Layer conv7_4/dw/scale
I0601 18:37:38.508337  6142 net.cpp:406] conv7_4/dw/scale <- conv7_4/dw
I0601 18:37:38.508343  6142 net.cpp:367] conv7_4/dw/scale -> conv7_4/dw (in-place)
I0601 18:37:38.508409  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/scale
I0601 18:37:38.508589  6142 net.cpp:122] Setting up conv7_4/dw/scale
I0601 18:37:38.508601  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.508606  6142 net.cpp:137] Memory required for data: 879334440
I0601 18:37:38.508615  6142 layer_factory.cpp:63] Creating layer conv7_4/dw/ReLU
I0601 18:37:38.508623  6142 net.cpp:84] Creating Layer conv7_4/dw/ReLU
I0601 18:37:38.508628  6142 net.cpp:406] conv7_4/dw/ReLU <- conv7_4/dw
I0601 18:37:38.508637  6142 net.cpp:367] conv7_4/dw/ReLU -> conv7_4/dw (in-place)
I0601 18:37:38.509385  6142 net.cpp:122] Setting up conv7_4/dw/ReLU
I0601 18:37:38.509407  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.509411  6142 net.cpp:137] Memory required for data: 881592360
I0601 18:37:38.509418  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2
I0601 18:37:38.509431  6142 net.cpp:84] Creating Layer conv7_4/sep2
I0601 18:37:38.509438  6142 net.cpp:406] conv7_4/sep2 <- conv7_4/dw
I0601 18:37:38.509449  6142 net.cpp:380] conv7_4/sep2 -> conv7_4/sep2
I0601 18:37:38.517354  6142 net.cpp:122] Setting up conv7_4/sep2
I0601 18:37:38.517379  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.517385  6142 net.cpp:137] Memory required for data: 881968680
I0601 18:37:38.517395  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/bn
I0601 18:37:38.517406  6142 net.cpp:84] Creating Layer conv7_4/sep2/bn
I0601 18:37:38.517413  6142 net.cpp:406] conv7_4/sep2/bn <- conv7_4/sep2
I0601 18:37:38.517421  6142 net.cpp:367] conv7_4/sep2/bn -> conv7_4/sep2 (in-place)
I0601 18:37:38.517776  6142 net.cpp:122] Setting up conv7_4/sep2/bn
I0601 18:37:38.517791  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.517796  6142 net.cpp:137] Memory required for data: 882345000
I0601 18:37:38.517807  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/scale
I0601 18:37:38.517817  6142 net.cpp:84] Creating Layer conv7_4/sep2/scale
I0601 18:37:38.517840  6142 net.cpp:406] conv7_4/sep2/scale <- conv7_4/sep2
I0601 18:37:38.517848  6142 net.cpp:367] conv7_4/sep2/scale -> conv7_4/sep2 (in-place)
I0601 18:37:38.517932  6142 layer_factory.cpp:63] Creating layer conv7_4/sep2/scale
I0601 18:37:38.518127  6142 net.cpp:122] Setting up conv7_4/sep2/scale
I0601 18:37:38.518141  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.518146  6142 net.cpp:137] Memory required for data: 882721320
I0601 18:37:38.518155  6142 layer_factory.cpp:63] Creating layer conv7_4/Eltwise1
I0601 18:37:38.518167  6142 net.cpp:84] Creating Layer conv7_4/Eltwise1
I0601 18:37:38.518174  6142 net.cpp:406] conv7_4/Eltwise1 <- conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split_1
I0601 18:37:38.518182  6142 net.cpp:406] conv7_4/Eltwise1 <- conv7_4/sep2
I0601 18:37:38.518189  6142 net.cpp:380] conv7_4/Eltwise1 -> conv7_4/Eltwise1
I0601 18:37:38.518229  6142 net.cpp:122] Setting up conv7_4/Eltwise1
I0601 18:37:38.518239  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.518244  6142 net.cpp:137] Memory required for data: 883097640
I0601 18:37:38.518249  6142 layer_factory.cpp:63] Creating layer conv7_4/Eltwise/ReLU
I0601 18:37:38.518257  6142 net.cpp:84] Creating Layer conv7_4/Eltwise/ReLU
I0601 18:37:38.518262  6142 net.cpp:406] conv7_4/Eltwise/ReLU <- conv7_4/Eltwise1
I0601 18:37:38.518270  6142 net.cpp:367] conv7_4/Eltwise/ReLU -> conv7_4/Eltwise1 (in-place)
I0601 18:37:38.519227  6142 net.cpp:122] Setting up conv7_4/Eltwise/ReLU
I0601 18:37:38.519251  6142 net.cpp:129] Top shape: 10 192 7 7 (94080)
I0601 18:37:38.519258  6142 net.cpp:137] Memory required for data: 883473960
I0601 18:37:38.519263  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1
I0601 18:37:38.519279  6142 net.cpp:84] Creating Layer conv8_1/sep1
I0601 18:37:38.519284  6142 net.cpp:406] conv8_1/sep1 <- conv7_4/Eltwise1
I0601 18:37:38.519299  6142 net.cpp:380] conv8_1/sep1 -> conv8_1/sep1
I0601 18:37:38.527011  6142 net.cpp:122] Setting up conv8_1/sep1
I0601 18:37:38.527036  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.527042  6142 net.cpp:137] Memory required for data: 885731880
I0601 18:37:38.527061  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/bn
I0601 18:37:38.527076  6142 net.cpp:84] Creating Layer conv8_1/sep1/bn
I0601 18:37:38.527083  6142 net.cpp:406] conv8_1/sep1/bn <- conv8_1/sep1
I0601 18:37:38.527091  6142 net.cpp:367] conv8_1/sep1/bn -> conv8_1/sep1 (in-place)
I0601 18:37:38.527415  6142 net.cpp:122] Setting up conv8_1/sep1/bn
I0601 18:37:38.527428  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.527433  6142 net.cpp:137] Memory required for data: 887989800
I0601 18:37:38.527446  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/scale
I0601 18:37:38.527456  6142 net.cpp:84] Creating Layer conv8_1/sep1/scale
I0601 18:37:38.527462  6142 net.cpp:406] conv8_1/sep1/scale <- conv8_1/sep1
I0601 18:37:38.527469  6142 net.cpp:367] conv8_1/sep1/scale -> conv8_1/sep1 (in-place)
I0601 18:37:38.527532  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/scale
I0601 18:37:38.527714  6142 net.cpp:122] Setting up conv8_1/sep1/scale
I0601 18:37:38.527726  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.527732  6142 net.cpp:137] Memory required for data: 890247720
I0601 18:37:38.527741  6142 layer_factory.cpp:63] Creating layer conv8_1/sep1/ReLU
I0601 18:37:38.527751  6142 net.cpp:84] Creating Layer conv8_1/sep1/ReLU
I0601 18:37:38.527757  6142 net.cpp:406] conv8_1/sep1/ReLU <- conv8_1/sep1
I0601 18:37:38.527765  6142 net.cpp:367] conv8_1/sep1/ReLU -> conv8_1/sep1 (in-place)
I0601 18:37:38.530213  6142 net.cpp:122] Setting up conv8_1/sep1/ReLU
I0601 18:37:38.530238  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.530244  6142 net.cpp:137] Memory required for data: 892505640
I0601 18:37:38.530251  6142 layer_factory.cpp:63] Creating layer conv8_1/dw
I0601 18:37:38.530263  6142 net.cpp:84] Creating Layer conv8_1/dw
I0601 18:37:38.530270  6142 net.cpp:406] conv8_1/dw <- conv8_1/sep1
I0601 18:37:38.530279  6142 net.cpp:380] conv8_1/dw -> conv8_1/dw
I0601 18:37:38.530705  6142 net.cpp:122] Setting up conv8_1/dw
I0601 18:37:38.530725  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.530730  6142 net.cpp:137] Memory required for data: 894763560
I0601 18:37:38.530740  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/bn
I0601 18:37:38.530748  6142 net.cpp:84] Creating Layer conv8_1/dw/bn
I0601 18:37:38.530755  6142 net.cpp:406] conv8_1/dw/bn <- conv8_1/dw
I0601 18:37:38.530766  6142 net.cpp:367] conv8_1/dw/bn -> conv8_1/dw (in-place)
I0601 18:37:38.531122  6142 net.cpp:122] Setting up conv8_1/dw/bn
I0601 18:37:38.531137  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.531142  6142 net.cpp:137] Memory required for data: 897021480
I0601 18:37:38.531154  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/scale
I0601 18:37:38.531163  6142 net.cpp:84] Creating Layer conv8_1/dw/scale
I0601 18:37:38.531169  6142 net.cpp:406] conv8_1/dw/scale <- conv8_1/dw
I0601 18:37:38.531177  6142 net.cpp:367] conv8_1/dw/scale -> conv8_1/dw (in-place)
I0601 18:37:38.531246  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/scale
I0601 18:37:38.531426  6142 net.cpp:122] Setting up conv8_1/dw/scale
I0601 18:37:38.531440  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.531445  6142 net.cpp:137] Memory required for data: 899279400
I0601 18:37:38.531453  6142 layer_factory.cpp:63] Creating layer conv8_1/dw/ReLU
I0601 18:37:38.531463  6142 net.cpp:84] Creating Layer conv8_1/dw/ReLU
I0601 18:37:38.531469  6142 net.cpp:406] conv8_1/dw/ReLU <- conv8_1/dw
I0601 18:37:38.531476  6142 net.cpp:367] conv8_1/dw/ReLU -> conv8_1/dw (in-place)
I0601 18:37:38.532424  6142 net.cpp:122] Setting up conv8_1/dw/ReLU
I0601 18:37:38.532447  6142 net.cpp:129] Top shape: 10 1152 7 7 (564480)
I0601 18:37:38.532454  6142 net.cpp:137] Memory required for data: 901537320
I0601 18:37:38.532459  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2
I0601 18:37:38.532474  6142 net.cpp:84] Creating Layer conv8_1/sep2
I0601 18:37:38.532480  6142 net.cpp:406] conv8_1/sep2 <- conv8_1/dw
I0601 18:37:38.532492  6142 net.cpp:380] conv8_1/sep2 -> conv8_1/sep2
I0601 18:37:38.543190  6142 net.cpp:122] Setting up conv8_1/sep2
I0601 18:37:38.543215  6142 net.cpp:129] Top shape: 10 320 7 7 (156800)
I0601 18:37:38.543221  6142 net.cpp:137] Memory required for data: 902164520
I0601 18:37:38.543229  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/bn
I0601 18:37:38.543242  6142 net.cpp:84] Creating Layer conv8_1/sep2/bn
I0601 18:37:38.543249  6142 net.cpp:406] conv8_1/sep2/bn <- conv8_1/sep2
I0601 18:37:38.543259  6142 net.cpp:367] conv8_1/sep2/bn -> conv8_1/sep2 (in-place)
I0601 18:37:38.543601  6142 net.cpp:122] Setting up conv8_1/sep2/bn
I0601 18:37:38.543615  6142 net.cpp:129] Top shape: 10 320 7 7 (156800)
I0601 18:37:38.543622  6142 net.cpp:137] Memory required for data: 902791720
I0601 18:37:38.543632  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/scale
I0601 18:37:38.543644  6142 net.cpp:84] Creating Layer conv8_1/sep2/scale
I0601 18:37:38.543650  6142 net.cpp:406] conv8_1/sep2/scale <- conv8_1/sep2
I0601 18:37:38.543658  6142 net.cpp:367] conv8_1/sep2/scale -> conv8_1/sep2 (in-place)
I0601 18:37:38.543721  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/scale
I0601 18:37:38.543917  6142 net.cpp:122] Setting up conv8_1/sep2/scale
I0601 18:37:38.543931  6142 net.cpp:129] Top shape: 10 320 7 7 (156800)
I0601 18:37:38.543936  6142 net.cpp:137] Memory required for data: 903418920
I0601 18:37:38.543946  6142 layer_factory.cpp:63] Creating layer conv8_1/sep2/ReLU
I0601 18:37:38.543953  6142 net.cpp:84] Creating Layer conv8_1/sep2/ReLU
I0601 18:37:38.543959  6142 net.cpp:406] conv8_1/sep2/ReLU <- conv8_1/sep2
I0601 18:37:38.543969  6142 net.cpp:367] conv8_1/sep2/ReLU -> conv8_1/sep2 (in-place)
I0601 18:37:38.544901  6142 net.cpp:122] Setting up conv8_1/sep2/ReLU
I0601 18:37:38.544924  6142 net.cpp:129] Top shape: 10 320 7 7 (156800)
I0601 18:37:38.544930  6142 net.cpp:137] Memory required for data: 904046120
I0601 18:37:38.544936  6142 layer_factory.cpp:63] Creating layer Pooling1
I0601 18:37:38.544965  6142 net.cpp:84] Creating Layer Pooling1
I0601 18:37:38.544971  6142 net.cpp:406] Pooling1 <- conv8_1/sep2
I0601 18:37:38.544986  6142 net.cpp:380] Pooling1 -> Pooling1
I0601 18:37:38.546131  6142 net.cpp:122] Setting up Pooling1
I0601 18:37:38.546155  6142 net.cpp:129] Top shape: 10 320 1 1 (3200)
I0601 18:37:38.546160  6142 net.cpp:137] Memory required for data: 904058920
I0601 18:37:38.546166  6142 layer_factory.cpp:63] Creating layer fc1
I0601 18:37:38.546180  6142 net.cpp:84] Creating Layer fc1
I0601 18:37:38.546185  6142 net.cpp:406] fc1 <- Pooling1
I0601 18:37:38.546197  6142 net.cpp:380] fc1 -> fc1
I0601 18:37:38.546382  6142 net.cpp:122] Setting up fc1
I0601 18:37:38.546396  6142 net.cpp:129] Top shape: 10 2 (20)
I0601 18:37:38.546401  6142 net.cpp:137] Memory required for data: 904059000
I0601 18:37:38.546411  6142 layer_factory.cpp:63] Creating layer acc
I0601 18:37:38.546419  6142 net.cpp:84] Creating Layer acc
I0601 18:37:38.546424  6142 net.cpp:406] acc <- fc1
I0601 18:37:38.546432  6142 net.cpp:406] acc <- label
I0601 18:37:38.546442  6142 net.cpp:380] acc -> acc
I0601 18:37:38.546453  6142 net.cpp:122] Setting up acc
I0601 18:37:38.546459  6142 net.cpp:129] Top shape: (1)
I0601 18:37:38.546464  6142 net.cpp:137] Memory required for data: 904059004
I0601 18:37:38.546469  6142 net.cpp:200] acc does not need backward computation.
I0601 18:37:38.546475  6142 net.cpp:200] fc1 does not need backward computation.
I0601 18:37:38.546481  6142 net.cpp:200] Pooling1 does not need backward computation.
I0601 18:37:38.546486  6142 net.cpp:200] conv8_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.546491  6142 net.cpp:200] conv8_1/sep2/scale does not need backward computation.
I0601 18:37:38.546496  6142 net.cpp:200] conv8_1/sep2/bn does not need backward computation.
I0601 18:37:38.546500  6142 net.cpp:200] conv8_1/sep2 does not need backward computation.
I0601 18:37:38.546506  6142 net.cpp:200] conv8_1/dw/ReLU does not need backward computation.
I0601 18:37:38.546511  6142 net.cpp:200] conv8_1/dw/scale does not need backward computation.
I0601 18:37:38.546515  6142 net.cpp:200] conv8_1/dw/bn does not need backward computation.
I0601 18:37:38.546520  6142 net.cpp:200] conv8_1/dw does not need backward computation.
I0601 18:37:38.546525  6142 net.cpp:200] conv8_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.546531  6142 net.cpp:200] conv8_1/sep1/scale does not need backward computation.
I0601 18:37:38.546535  6142 net.cpp:200] conv8_1/sep1/bn does not need backward computation.
I0601 18:37:38.546540  6142 net.cpp:200] conv8_1/sep1 does not need backward computation.
I0601 18:37:38.546546  6142 net.cpp:200] conv7_4/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.546551  6142 net.cpp:200] conv7_4/Eltwise1 does not need backward computation.
I0601 18:37:38.546557  6142 net.cpp:200] conv7_4/sep2/scale does not need backward computation.
I0601 18:37:38.546562  6142 net.cpp:200] conv7_4/sep2/bn does not need backward computation.
I0601 18:37:38.546567  6142 net.cpp:200] conv7_4/sep2 does not need backward computation.
I0601 18:37:38.546573  6142 net.cpp:200] conv7_4/dw/ReLU does not need backward computation.
I0601 18:37:38.546578  6142 net.cpp:200] conv7_4/dw/scale does not need backward computation.
I0601 18:37:38.546583  6142 net.cpp:200] conv7_4/dw/bn does not need backward computation.
I0601 18:37:38.546587  6142 net.cpp:200] conv7_4/dw does not need backward computation.
I0601 18:37:38.546593  6142 net.cpp:200] conv7_4/sep1/ReLU does not need backward computation.
I0601 18:37:38.546598  6142 net.cpp:200] conv7_4/sep1/scale does not need backward computation.
I0601 18:37:38.546603  6142 net.cpp:200] conv7_4/sep1/bn does not need backward computation.
I0601 18:37:38.546608  6142 net.cpp:200] conv7_4/sep1 does not need backward computation.
I0601 18:37:38.546614  6142 net.cpp:200] conv7_3/Eltwise1_conv7_3/Eltwise/ReLU_0_split does not need backward computation.
I0601 18:37:38.546620  6142 net.cpp:200] conv7_3/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.546641  6142 net.cpp:200] conv7_3/Eltwise1 does not need backward computation.
I0601 18:37:38.546649  6142 net.cpp:200] conv7_3/sep2/scale does not need backward computation.
I0601 18:37:38.546654  6142 net.cpp:200] conv7_3/sep2/bn does not need backward computation.
I0601 18:37:38.546659  6142 net.cpp:200] conv7_3/sep2 does not need backward computation.
I0601 18:37:38.546665  6142 net.cpp:200] conv7_3/dw/ReLU does not need backward computation.
I0601 18:37:38.546670  6142 net.cpp:200] conv7_3/dw/scale does not need backward computation.
I0601 18:37:38.546675  6142 net.cpp:200] conv7_3/dw/bn does not need backward computation.
I0601 18:37:38.546680  6142 net.cpp:200] conv7_3/dw does not need backward computation.
I0601 18:37:38.546685  6142 net.cpp:200] conv7_3/sep1/ReLU does not need backward computation.
I0601 18:37:38.546691  6142 net.cpp:200] conv7_3/sep1/scale does not need backward computation.
I0601 18:37:38.546696  6142 net.cpp:200] conv7_3/sep1/bn does not need backward computation.
I0601 18:37:38.546701  6142 net.cpp:200] conv7_3/sep1 does not need backward computation.
I0601 18:37:38.546707  6142 net.cpp:200] conv7_2/Eltwise1_conv7_2/Eltwise/ReLU_0_split does not need backward computation.
I0601 18:37:38.546713  6142 net.cpp:200] conv7_2/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.546718  6142 net.cpp:200] conv7_2/Eltwise1 does not need backward computation.
I0601 18:37:38.546727  6142 net.cpp:200] conv7_2/sep2/scale does not need backward computation.
I0601 18:37:38.546732  6142 net.cpp:200] conv7_2/sep2/bn does not need backward computation.
I0601 18:37:38.546738  6142 net.cpp:200] conv7_2/sep2 does not need backward computation.
I0601 18:37:38.546743  6142 net.cpp:200] conv7_2/dw/ReLU does not need backward computation.
I0601 18:37:38.546748  6142 net.cpp:200] conv7_2/dw/scale does not need backward computation.
I0601 18:37:38.546753  6142 net.cpp:200] conv7_2/dw/bn does not need backward computation.
I0601 18:37:38.546758  6142 net.cpp:200] conv7_2/dw does not need backward computation.
I0601 18:37:38.546764  6142 net.cpp:200] conv7_2/sep1/ReLU does not need backward computation.
I0601 18:37:38.546769  6142 net.cpp:200] conv7_2/sep1/scale does not need backward computation.
I0601 18:37:38.546774  6142 net.cpp:200] conv7_2/sep1/bn does not need backward computation.
I0601 18:37:38.546780  6142 net.cpp:200] conv7_2/sep1 does not need backward computation.
I0601 18:37:38.546787  6142 net.cpp:200] conv7_1/sep2_conv7_1/sep2/ReLU_0_split does not need backward computation.
I0601 18:37:38.546792  6142 net.cpp:200] conv7_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.546797  6142 net.cpp:200] conv7_1/sep2/scale does not need backward computation.
I0601 18:37:38.546802  6142 net.cpp:200] conv7_1/sep2/bn does not need backward computation.
I0601 18:37:38.546808  6142 net.cpp:200] conv7_1/sep2 does not need backward computation.
I0601 18:37:38.546813  6142 net.cpp:200] conv7_1/dw/ReLU does not need backward computation.
I0601 18:37:38.546818  6142 net.cpp:200] conv7_1/dw/scale does not need backward computation.
I0601 18:37:38.546823  6142 net.cpp:200] conv7_1/dw/bn does not need backward computation.
I0601 18:37:38.546828  6142 net.cpp:200] conv7_1/dw does not need backward computation.
I0601 18:37:38.546834  6142 net.cpp:200] conv7_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.546839  6142 net.cpp:200] conv7_1/sep1/scale does not need backward computation.
I0601 18:37:38.546844  6142 net.cpp:200] conv7_1/sep1/bn does not need backward computation.
I0601 18:37:38.546849  6142 net.cpp:200] conv7_1/sep1 does not need backward computation.
I0601 18:37:38.546855  6142 net.cpp:200] conv6_2/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.546860  6142 net.cpp:200] conv6_2/Eltwise1 does not need backward computation.
I0601 18:37:38.546867  6142 net.cpp:200] conv6_2/sep2/scale does not need backward computation.
I0601 18:37:38.546872  6142 net.cpp:200] conv6_2/sep2/bn does not need backward computation.
I0601 18:37:38.546885  6142 net.cpp:200] conv6_2/sep2 does not need backward computation.
I0601 18:37:38.546891  6142 net.cpp:200] conv6_2/dw/ReLU does not need backward computation.
I0601 18:37:38.546897  6142 net.cpp:200] conv6_2/dw/scale does not need backward computation.
I0601 18:37:38.546902  6142 net.cpp:200] conv6_2/dw/bn does not need backward computation.
I0601 18:37:38.546907  6142 net.cpp:200] conv6_2/dw does not need backward computation.
I0601 18:37:38.546912  6142 net.cpp:200] conv6_2/sep1/ReLU does not need backward computation.
I0601 18:37:38.546918  6142 net.cpp:200] conv6_2/sep1/scale does not need backward computation.
I0601 18:37:38.546923  6142 net.cpp:200] conv6_2/sep1/bn does not need backward computation.
I0601 18:37:38.546929  6142 net.cpp:200] conv6_2/sep1 does not need backward computation.
I0601 18:37:38.546936  6142 net.cpp:200] conv6_1/sep2_conv6_1/sep2/ReLU_0_split does not need backward computation.
I0601 18:37:38.546941  6142 net.cpp:200] conv6_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.546945  6142 net.cpp:200] conv6_1/sep2/scale does not need backward computation.
I0601 18:37:38.546952  6142 net.cpp:200] conv6_1/sep2/bn does not need backward computation.
I0601 18:37:38.546955  6142 net.cpp:200] conv6_1/sep2 does not need backward computation.
I0601 18:37:38.546962  6142 net.cpp:200] conv6_1/dw/ReLU does not need backward computation.
I0601 18:37:38.546967  6142 net.cpp:200] conv6_1/dw/scale does not need backward computation.
I0601 18:37:38.546972  6142 net.cpp:200] conv6_1/dw/bn does not need backward computation.
I0601 18:37:38.546977  6142 net.cpp:200] conv6_1/dw does not need backward computation.
I0601 18:37:38.546983  6142 net.cpp:200] conv6_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.546988  6142 net.cpp:200] conv6_1/sep1/scale does not need backward computation.
I0601 18:37:38.546993  6142 net.cpp:200] conv6_1/sep1/bn does not need backward computation.
I0601 18:37:38.546998  6142 net.cpp:200] conv6_1/sep1 does not need backward computation.
I0601 18:37:38.547003  6142 net.cpp:200] conv5_3/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547009  6142 net.cpp:200] conv5_3/Eltwise1 does not need backward computation.
I0601 18:37:38.547019  6142 net.cpp:200] conv5_3/sep2/scale does not need backward computation.
I0601 18:37:38.547024  6142 net.cpp:200] conv5_3/sep2/bn does not need backward computation.
I0601 18:37:38.547029  6142 net.cpp:200] conv5_3/sep2 does not need backward computation.
I0601 18:37:38.547034  6142 net.cpp:200] conv5_3/dw/ReLU does not need backward computation.
I0601 18:37:38.547039  6142 net.cpp:200] conv5_3/dw/scale does not need backward computation.
I0601 18:37:38.547044  6142 net.cpp:200] conv5_3/dw/bn does not need backward computation.
I0601 18:37:38.547049  6142 net.cpp:200] conv5_3/dw does not need backward computation.
I0601 18:37:38.547067  6142 net.cpp:200] conv5_3/sep1/ReLU does not need backward computation.
I0601 18:37:38.547073  6142 net.cpp:200] conv5_3/sep1/scale does not need backward computation.
I0601 18:37:38.547078  6142 net.cpp:200] conv5_3/sep1/bn does not need backward computation.
I0601 18:37:38.547083  6142 net.cpp:200] conv5_3/sep1 does not need backward computation.
I0601 18:37:38.547089  6142 net.cpp:200] conv5_2/Eltwise1_conv5_2/Eltwise/ReLU_0_split does not need backward computation.
I0601 18:37:38.547096  6142 net.cpp:200] conv5_2/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547101  6142 net.cpp:200] conv5_2/Eltwise1 does not need backward computation.
I0601 18:37:38.547107  6142 net.cpp:200] conv5_2/sep2/scale does not need backward computation.
I0601 18:37:38.547112  6142 net.cpp:200] conv5_2/sep2/bn does not need backward computation.
I0601 18:37:38.547117  6142 net.cpp:200] conv5_2/sep2 does not need backward computation.
I0601 18:37:38.547127  6142 net.cpp:200] conv5_2/dw/ReLU does not need backward computation.
I0601 18:37:38.547132  6142 net.cpp:200] conv5_2/dw/scale does not need backward computation.
I0601 18:37:38.547137  6142 net.cpp:200] conv5_2/dw/bn does not need backward computation.
I0601 18:37:38.547152  6142 net.cpp:200] conv5_2/dw does not need backward computation.
I0601 18:37:38.547158  6142 net.cpp:200] conv5_2/sep1/ReLU does not need backward computation.
I0601 18:37:38.547163  6142 net.cpp:200] conv5_2/sep1/scale does not need backward computation.
I0601 18:37:38.547168  6142 net.cpp:200] conv5_2/sep1/bn does not need backward computation.
I0601 18:37:38.547174  6142 net.cpp:200] conv5_2/sep1 does not need backward computation.
I0601 18:37:38.547180  6142 net.cpp:200] conv5_1/sep2_conv5_1/sep2/ReLU_0_split does not need backward computation.
I0601 18:37:38.547186  6142 net.cpp:200] conv5_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.547191  6142 net.cpp:200] conv5_1/sep2/scale does not need backward computation.
I0601 18:37:38.547196  6142 net.cpp:200] conv5_1/sep2/bn does not need backward computation.
I0601 18:37:38.547201  6142 net.cpp:200] conv5_1/sep2 does not need backward computation.
I0601 18:37:38.547207  6142 net.cpp:200] conv5_1/dw/ReLU does not need backward computation.
I0601 18:37:38.547214  6142 net.cpp:200] conv5_1/dw/scale does not need backward computation.
I0601 18:37:38.547219  6142 net.cpp:200] conv5_1/dw/bn does not need backward computation.
I0601 18:37:38.547224  6142 net.cpp:200] conv5_1/dw does not need backward computation.
I0601 18:37:38.547228  6142 net.cpp:200] conv5_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.547235  6142 net.cpp:200] conv5_1/sep1/scale does not need backward computation.
I0601 18:37:38.547240  6142 net.cpp:200] conv5_1/sep1/bn does not need backward computation.
I0601 18:37:38.547245  6142 net.cpp:200] conv5_1/sep1 does not need backward computation.
I0601 18:37:38.547250  6142 net.cpp:200] conv4_3/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547256  6142 net.cpp:200] conv4_3/Eltwise1 does not need backward computation.
I0601 18:37:38.547262  6142 net.cpp:200] conv4_3/sep2/scale does not need backward computation.
I0601 18:37:38.547268  6142 net.cpp:200] conv4_3/sep2/bn does not need backward computation.
I0601 18:37:38.547273  6142 net.cpp:200] conv4_3/sep2 does not need backward computation.
I0601 18:37:38.547278  6142 net.cpp:200] conv4_3/dw/ReLU does not need backward computation.
I0601 18:37:38.547284  6142 net.cpp:200] conv4_3/dw/scale does not need backward computation.
I0601 18:37:38.547289  6142 net.cpp:200] conv4_3/dw/bn does not need backward computation.
I0601 18:37:38.547294  6142 net.cpp:200] conv4_3/dw does not need backward computation.
I0601 18:37:38.547299  6142 net.cpp:200] conv4_3/sep1/ReLU does not need backward computation.
I0601 18:37:38.547305  6142 net.cpp:200] conv4_3/sep1/scale does not need backward computation.
I0601 18:37:38.547310  6142 net.cpp:200] conv4_3/sep1/bn does not need backward computation.
I0601 18:37:38.547315  6142 net.cpp:200] conv4_3/sep1 does not need backward computation.
I0601 18:37:38.547322  6142 net.cpp:200] conv4_2/Eltwise1_conv4_2/Eltwise/ReLU_0_split does not need backward computation.
I0601 18:37:38.547327  6142 net.cpp:200] conv4_2/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547333  6142 net.cpp:200] conv4_2/Eltwise1 does not need backward computation.
I0601 18:37:38.547341  6142 net.cpp:200] conv4_2/sep2/scale does not need backward computation.
I0601 18:37:38.547348  6142 net.cpp:200] conv4_2/sep2/bn does not need backward computation.
I0601 18:37:38.547353  6142 net.cpp:200] conv4_2/sep2 does not need backward computation.
I0601 18:37:38.547358  6142 net.cpp:200] conv4_2/dw/ReLU does not need backward computation.
I0601 18:37:38.547363  6142 net.cpp:200] conv4_2/dw/scale does not need backward computation.
I0601 18:37:38.547369  6142 net.cpp:200] conv4_2/dw/bn does not need backward computation.
I0601 18:37:38.547374  6142 net.cpp:200] conv4_2/dw does not need backward computation.
I0601 18:37:38.547379  6142 net.cpp:200] conv4_2/sep1/ReLU does not need backward computation.
I0601 18:37:38.547385  6142 net.cpp:200] conv4_2/sep1/scale does not need backward computation.
I0601 18:37:38.547397  6142 net.cpp:200] conv4_2/sep1/bn does not need backward computation.
I0601 18:37:38.547403  6142 net.cpp:200] conv4_2/sep1 does not need backward computation.
I0601 18:37:38.547410  6142 net.cpp:200] conv4_1/sep2_conv4_1/sep2/ReLU_0_split does not need backward computation.
I0601 18:37:38.547415  6142 net.cpp:200] conv4_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.547420  6142 net.cpp:200] conv4_1/sep2/scale does not need backward computation.
I0601 18:37:38.547425  6142 net.cpp:200] conv4_1/sep2/bn does not need backward computation.
I0601 18:37:38.547430  6142 net.cpp:200] conv4_1/sep2 does not need backward computation.
I0601 18:37:38.547436  6142 net.cpp:200] conv4_1/dw/ReLU does not need backward computation.
I0601 18:37:38.547442  6142 net.cpp:200] conv4_1/dw/scale does not need backward computation.
I0601 18:37:38.547447  6142 net.cpp:200] conv4_1/dw/bn does not need backward computation.
I0601 18:37:38.547452  6142 net.cpp:200] conv4_1/dw does not need backward computation.
I0601 18:37:38.547458  6142 net.cpp:200] conv4_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.547463  6142 net.cpp:200] conv4_1/sep1/scale does not need backward computation.
I0601 18:37:38.547468  6142 net.cpp:200] conv4_1/sep1/bn does not need backward computation.
I0601 18:37:38.547473  6142 net.cpp:200] conv4_1/sep1 does not need backward computation.
I0601 18:37:38.547479  6142 net.cpp:200] conv3_3/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547484  6142 net.cpp:200] conv3_3/Eltwise1 does not need backward computation.
I0601 18:37:38.547492  6142 net.cpp:200] conv3_3/sep2/scale does not need backward computation.
I0601 18:37:38.547497  6142 net.cpp:200] conv3_3/sep2/bn does not need backward computation.
I0601 18:37:38.547502  6142 net.cpp:200] conv3_3/sep2 does not need backward computation.
I0601 18:37:38.547508  6142 net.cpp:200] conv3_3/dw/ReLU does not need backward computation.
I0601 18:37:38.547513  6142 net.cpp:200] conv3_3/dw/scale does not need backward computation.
I0601 18:37:38.547518  6142 net.cpp:200] conv3_3/dw/bn does not need backward computation.
I0601 18:37:38.547523  6142 net.cpp:200] conv3_3/dw does not need backward computation.
I0601 18:37:38.547528  6142 net.cpp:200] conv3_3/sep1/ReLU does not need backward computation.
I0601 18:37:38.547534  6142 net.cpp:200] conv3_3/sep1/scale does not need backward computation.
I0601 18:37:38.547539  6142 net.cpp:200] conv3_3/sep1/bn does not need backward computation.
I0601 18:37:38.547544  6142 net.cpp:200] conv3_3/sep1 does not need backward computation.
I0601 18:37:38.547550  6142 net.cpp:200] conv3_2/Eltwise1_conv3_2/Eltwise/ReLU_0_split does not need backward computation.
I0601 18:37:38.547556  6142 net.cpp:200] conv3_2/Eltwise/ReLU does not need backward computation.
I0601 18:37:38.547561  6142 net.cpp:200] conv3_2/Eltwise1 does not need backward computation.
I0601 18:37:38.547569  6142 net.cpp:200] conv3_2/sep2/scale does not need backward computation.
I0601 18:37:38.547574  6142 net.cpp:200] conv3_2/sep2/bn does not need backward computation.
I0601 18:37:38.547578  6142 net.cpp:200] conv3_2/sep2 does not need backward computation.
I0601 18:37:38.547583  6142 net.cpp:200] conv3_2/dw/ReLU does not need backward computation.
I0601 18:37:38.547590  6142 net.cpp:200] conv3_2/dw/scale does not need backward computation.
I0601 18:37:38.547595  6142 net.cpp:200] conv3_2/dw/bn does not need backward computation.
I0601 18:37:38.547600  6142 net.cpp:200] conv3_2/dw does not need backward computation.
I0601 18:37:38.547605  6142 net.cpp:200] conv3_2/sep1/ReLU does not need backward computation.
I0601 18:37:38.547610  6142 net.cpp:200] conv3_2/sep1/scale does not need backward computation.
I0601 18:37:38.547616  6142 net.cpp:200] conv3_2/sep1/bn does not need backward computation.
I0601 18:37:38.547621  6142 net.cpp:200] conv3_2/sep1 does not need backward computation.
I0601 18:37:38.547628  6142 net.cpp:200] conv3_1/sep2_conv3_1/sep2/ReLU_0_split does not need backward computation.
I0601 18:37:38.547641  6142 net.cpp:200] conv3_1/sep2/ReLU does not need backward computation.
I0601 18:37:38.547647  6142 net.cpp:200] conv3_1/sep2/scale does not need backward computation.
I0601 18:37:38.547652  6142 net.cpp:200] conv3_1/sep2/bn does not need backward computation.
I0601 18:37:38.547657  6142 net.cpp:200] conv3_1/sep2 does not need backward computation.
I0601 18:37:38.547663  6142 net.cpp:200] conv3_1/dw/ReLU does not need backward computation.
I0601 18:37:38.547668  6142 net.cpp:200] conv3_1/dw/scale does not need backward computation.
I0601 18:37:38.547673  6142 net.cpp:200] conv3_1/dw/bn does not need backward computation.
I0601 18:37:38.547678  6142 net.cpp:200] conv3_1/dw does not need backward computation.
I0601 18:37:38.547684  6142 net.cpp:200] conv3_1/sep1/ReLU does not need backward computation.
I0601 18:37:38.547689  6142 net.cpp:200] conv3_1/sep1/scale does not need backward computation.
I0601 18:37:38.547694  6142 net.cpp:200] conv3_1/sep1/bn does not need backward computation.
I0601 18:37:38.547699  6142 net.cpp:200] conv3_1/sep1 does not need backward computation.
I0601 18:37:38.547705  6142 net.cpp:200] conv2_1/sep/ReLU does not need backward computation.
I0601 18:37:38.547711  6142 net.cpp:200] conv2_1/sep/scale does not need backward computation.
I0601 18:37:38.547716  6142 net.cpp:200] conv2_1/sep/bn does not need backward computation.
I0601 18:37:38.547722  6142 net.cpp:200] conv2_1/sep does not need backward computation.
I0601 18:37:38.547727  6142 net.cpp:200] conv2_1/dw/ReLU does not need backward computation.
I0601 18:37:38.547732  6142 net.cpp:200] conv2_1/dw/scale does not need backward computation.
I0601 18:37:38.547737  6142 net.cpp:200] conv2_1/dw/bn does not need backward computation.
I0601 18:37:38.547742  6142 net.cpp:200] conv2_1/dw does not need backward computation.
I0601 18:37:38.547749  6142 net.cpp:200] conv1/ReLU does not need backward computation.
I0601 18:37:38.547753  6142 net.cpp:200] conv1/scale does not need backward computation.
I0601 18:37:38.547760  6142 net.cpp:200] conv1/bn does not need backward computation.
I0601 18:37:38.547765  6142 net.cpp:200] conv1 does not need backward computation.
I0601 18:37:38.547770  6142 net.cpp:200] data does not need backward computation.
I0601 18:37:38.547775  6142 net.cpp:242] This network produces output acc
I0601 18:37:38.547926  6142 net.cpp:255] Network initialization done.
I0601 18:37:38.548533  6142 solver.cpp:56] Solver scaffolding done.
I0601 18:37:38.565775  6142 caffe.cpp:249] Starting Optimization
I0601 18:37:38.565791  6142 solver.cpp:272] Solving MnasNet
I0601 18:37:38.565796  6142 solver.cpp:273] Learning Rate Policy: multistep
I0601 18:37:38.574070  6142 solver.cpp:330] Iteration 0, Testing net (#0)
I0601 18:37:38.580040  6142 net.cpp:676] Ignoring source layer Softmax
I0601 18:37:39.315376  6142 solver.cpp:397]     Test net output #0: acc = 0.484
I0601 18:37:40.406949  6142 solver.cpp:218] Iteration 0 (2.88848e+37 iter/s, 1.84108s/100 iters), loss = 0.707666
I0601 18:37:40.407011  6142 solver.cpp:237]     Train net output #0: Softmax = 0.736222 (* 1 = 0.736222 loss)
I0601 18:37:40.407037  6142 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0601 18:38:49.832739  6142 blocking_queue.cpp:49] Waiting for data
I0601 18:39:24.706984  6142 solver.cpp:218] Iteration 100 (0.958787 iter/s, 104.298s/100 iters), loss = 0.697038
I0601 18:39:24.707146  6142 solver.cpp:237]     Train net output #0: Softmax = 0.788787 (* 1 = 0.788787 loss)
I0601 18:39:24.707165  6142 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I0601 18:41:09.255138  6142 solver.cpp:218] Iteration 200 (0.956516 iter/s, 104.546s/100 iters), loss = 0.695665
I0601 18:41:09.255306  6142 solver.cpp:237]     Train net output #0: Softmax = 0.623297 (* 1 = 0.623297 loss)
I0601 18:41:09.255324  6142 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I0601 18:42:53.802870  6142 solver.cpp:218] Iteration 300 (0.956519 iter/s, 104.546s/100 iters), loss = 0.68683
I0601 18:42:53.803082  6142 solver.cpp:237]     Train net output #0: Softmax = 0.737268 (* 1 = 0.737268 loss)
I0601 18:42:53.803102  6142 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I0601 18:43:05.368113  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 18:44:38.345077  6142 solver.cpp:218] Iteration 400 (0.956571 iter/s, 104.54s/100 iters), loss = 0.692309
I0601 18:44:38.345392  6142 solver.cpp:237]     Train net output #0: Softmax = 0.668917 (* 1 = 0.668917 loss)
I0601 18:44:38.345412  6142 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I0601 18:46:21.857174  6142 solver.cpp:330] Iteration 500, Testing net (#0)
I0601 18:46:21.857455  6142 net.cpp:676] Ignoring source layer Softmax
I0601 18:46:22.536376  6142 solver.cpp:397]     Test net output #0: acc = 0.484
I0601 18:46:23.570346  6142 solver.cpp:218] Iteration 500 (0.950364 iter/s, 105.223s/100 iters), loss = 0.685895
I0601 18:46:23.570411  6142 solver.cpp:237]     Train net output #0: Softmax = 0.728598 (* 1 = 0.728598 loss)
I0601 18:46:23.570426  6142 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I0601 18:48:08.129670  6142 solver.cpp:218] Iteration 600 (0.956415 iter/s, 104.557s/100 iters), loss = 0.660867
I0601 18:48:08.129829  6142 solver.cpp:237]     Train net output #0: Softmax = 0.540974 (* 1 = 0.540974 loss)
I0601 18:48:08.129848  6142 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I0601 18:48:32.695888  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 18:49:52.655285  6142 solver.cpp:218] Iteration 700 (0.956724 iter/s, 104.523s/100 iters), loss = 0.668632
I0601 18:49:52.655437  6142 solver.cpp:237]     Train net output #0: Softmax = 0.662081 (* 1 = 0.662081 loss)
I0601 18:49:52.655454  6142 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I0601 18:51:37.165112  6142 solver.cpp:218] Iteration 800 (0.956869 iter/s, 104.507s/100 iters), loss = 0.674676
I0601 18:51:37.165264  6142 solver.cpp:237]     Train net output #0: Softmax = 0.748527 (* 1 = 0.748527 loss)
I0601 18:51:37.165282  6142 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I0601 18:53:21.684962  6142 solver.cpp:218] Iteration 900 (0.956778 iter/s, 104.517s/100 iters), loss = 0.639485
I0601 18:53:21.685107  6142 solver.cpp:237]     Train net output #0: Softmax = 0.763473 (* 1 = 0.763473 loss)
I0601 18:53:21.685124  6142 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I0601 18:53:59.333607  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 18:55:05.186146  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_1000.caffemodel
I0601 18:55:05.395951  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_1000.solverstate
I0601 18:55:05.537240  6142 solver.cpp:330] Iteration 1000, Testing net (#0)
I0601 18:55:05.537524  6142 net.cpp:676] Ignoring source layer Softmax
I0601 18:55:06.230577  6142 solver.cpp:397]     Test net output #0: acc = 0.588
I0601 18:55:07.263669  6142 solver.cpp:218] Iteration 1000 (0.947182 iter/s, 105.576s/100 iters), loss = 0.65689
I0601 18:55:07.263731  6142 solver.cpp:237]     Train net output #0: Softmax = 0.597285 (* 1 = 0.597285 loss)
I0601 18:55:07.263748  6142 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I0601 18:56:51.883564  6142 solver.cpp:218] Iteration 1100 (0.955862 iter/s, 104.618s/100 iters), loss = 0.613416
I0601 18:56:51.883669  6142 solver.cpp:237]     Train net output #0: Softmax = 0.555016 (* 1 = 0.555016 loss)
I0601 18:56:51.883687  6142 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I0601 18:58:36.468163  6142 solver.cpp:218] Iteration 1200 (0.956185 iter/s, 104.582s/100 iters), loss = 0.620656
I0601 18:58:36.468315  6142 solver.cpp:237]     Train net output #0: Softmax = 0.598185 (* 1 = 0.598185 loss)
I0601 18:58:36.468333  6142 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I0601 18:59:27.199415  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:00:21.024825  6142 solver.cpp:218] Iteration 1300 (0.956441 iter/s, 104.554s/100 iters), loss = 0.62226
I0601 19:00:21.025019  6142 solver.cpp:237]     Train net output #0: Softmax = 0.611535 (* 1 = 0.611535 loss)
I0601 19:00:21.025038  6142 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I0601 19:02:05.730106  6142 solver.cpp:218] Iteration 1400 (0.955084 iter/s, 104.703s/100 iters), loss = 0.706603
I0601 19:02:05.730218  6142 solver.cpp:237]     Train net output #0: Softmax = 0.725264 (* 1 = 0.725264 loss)
I0601 19:02:05.730235  6142 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I0601 19:03:51.886821  6142 solver.cpp:330] Iteration 1500, Testing net (#0)
I0601 19:03:51.887169  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:03:52.599045  6142 solver.cpp:397]     Test net output #0: acc = 0.58
I0601 19:03:53.669203  6142 solver.cpp:218] Iteration 1500 (0.926472 iter/s, 107.936s/100 iters), loss = 0.677103
I0601 19:03:53.669281  6142 solver.cpp:237]     Train net output #0: Softmax = 0.547517 (* 1 = 0.547517 loss)
I0601 19:03:53.669296  6142 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I0601 19:04:59.375372  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:05:41.531615  6142 solver.cpp:218] Iteration 1600 (0.927134 iter/s, 107.859s/100 iters), loss = 0.66347
I0601 19:05:41.531769  6142 solver.cpp:237]     Train net output #0: Softmax = 0.650238 (* 1 = 0.650238 loss)
I0601 19:05:41.531786  6142 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I0601 19:07:26.681181  6142 solver.cpp:218] Iteration 1700 (0.951054 iter/s, 105.147s/100 iters), loss = 0.699287
I0601 19:07:26.681334  6142 solver.cpp:237]     Train net output #0: Softmax = 0.617125 (* 1 = 0.617125 loss)
I0601 19:07:26.681351  6142 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I0601 19:09:11.200423  6142 solver.cpp:218] Iteration 1800 (0.956789 iter/s, 104.516s/100 iters), loss = 0.636097
I0601 19:09:11.200583  6142 solver.cpp:237]     Train net output #0: Softmax = 0.854135 (* 1 = 0.854135 loss)
I0601 19:09:11.200601  6142 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I0601 19:10:28.071545  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:10:55.752622  6142 solver.cpp:218] Iteration 1900 (0.956486 iter/s, 104.549s/100 iters), loss = 0.487145
I0601 19:10:55.752684  6142 solver.cpp:237]     Train net output #0: Softmax = 0.36426 (* 1 = 0.36426 loss)
I0601 19:10:55.752698  6142 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I0601 19:12:39.276566  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_2000.caffemodel
I0601 19:12:39.446780  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_2000.solverstate
I0601 19:12:39.586277  6142 solver.cpp:330] Iteration 2000, Testing net (#0)
I0601 19:12:39.586563  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:12:40.270141  6142 solver.cpp:397]     Test net output #0: acc = 0.568
I0601 19:12:41.295328  6142 solver.cpp:218] Iteration 2000 (0.947508 iter/s, 105.54s/100 iters), loss = 0.573522
I0601 19:12:41.295404  6142 solver.cpp:237]     Train net output #0: Softmax = 0.792465 (* 1 = 0.792465 loss)
I0601 19:12:41.295419  6142 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I0601 19:14:25.858872  6142 solver.cpp:218] Iteration 2100 (0.956381 iter/s, 104.561s/100 iters), loss = 0.636842
I0601 19:14:25.859028  6142 solver.cpp:237]     Train net output #0: Softmax = 0.5602 (* 1 = 0.5602 loss)
I0601 19:14:25.859045  6142 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I0601 19:15:55.820360  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:16:10.467917  6142 solver.cpp:218] Iteration 2200 (0.955965 iter/s, 104.606s/100 iters), loss = 0.584286
I0601 19:16:10.467978  6142 solver.cpp:237]     Train net output #0: Softmax = 0.425706 (* 1 = 0.425706 loss)
I0601 19:16:10.467995  6142 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I0601 19:17:55.034970  6142 solver.cpp:218] Iteration 2300 (0.956348 iter/s, 104.564s/100 iters), loss = 0.556352
I0601 19:17:55.035147  6142 solver.cpp:237]     Train net output #0: Softmax = 0.576795 (* 1 = 0.576795 loss)
I0601 19:17:55.035167  6142 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I0601 19:19:39.557269  6142 solver.cpp:218] Iteration 2400 (0.956758 iter/s, 104.52s/100 iters), loss = 0.630302
I0601 19:19:39.557476  6142 solver.cpp:237]     Train net output #0: Softmax = 0.686049 (* 1 = 0.686049 loss)
I0601 19:19:39.557495  6142 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I0601 19:21:22.530720  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:21:23.068583  6142 solver.cpp:330] Iteration 2500, Testing net (#0)
I0601 19:21:23.068825  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:21:23.733197  6142 solver.cpp:397]     Test net output #0: acc = 0.708
I0601 19:21:24.780566  6142 solver.cpp:218] Iteration 2500 (0.950384 iter/s, 105.221s/100 iters), loss = 0.628739
I0601 19:21:24.780633  6142 solver.cpp:237]     Train net output #0: Softmax = 0.664092 (* 1 = 0.664092 loss)
I0601 19:21:24.780648  6142 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I0601 19:23:09.309262  6142 solver.cpp:218] Iteration 2600 (0.956698 iter/s, 104.526s/100 iters), loss = 0.551317
I0601 19:23:09.309412  6142 solver.cpp:237]     Train net output #0: Softmax = 0.468587 (* 1 = 0.468587 loss)
I0601 19:23:09.309429  6142 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I0601 19:24:53.787680  6142 solver.cpp:218] Iteration 2700 (0.957159 iter/s, 104.476s/100 iters), loss = 0.577371
I0601 19:24:53.787832  6142 solver.cpp:237]     Train net output #0: Softmax = 0.664426 (* 1 = 0.664426 loss)
I0601 19:24:53.787849  6142 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I0601 19:26:38.276141  6142 solver.cpp:218] Iteration 2800 (0.957068 iter/s, 104.486s/100 iters), loss = 0.616368
I0601 19:26:38.276298  6142 solver.cpp:237]     Train net output #0: Softmax = 0.754629 (* 1 = 0.754629 loss)
I0601 19:26:38.276314  6142 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I0601 19:26:49.814642  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:28:22.765570  6142 solver.cpp:218] Iteration 2900 (0.957058 iter/s, 104.487s/100 iters), loss = 0.607421
I0601 19:28:22.765722  6142 solver.cpp:237]     Train net output #0: Softmax = 0.626348 (* 1 = 0.626348 loss)
I0601 19:28:22.765740  6142 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I0601 19:30:06.191956  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_3000.caffemodel
I0601 19:30:06.360644  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_3000.solverstate
I0601 19:30:06.502496  6142 solver.cpp:330] Iteration 3000, Testing net (#0)
I0601 19:30:06.502780  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:30:07.180821  6142 solver.cpp:397]     Test net output #0: acc = 0.624
I0601 19:30:08.209496  6142 solver.cpp:218] Iteration 3000 (0.948395 iter/s, 105.441s/100 iters), loss = 0.578934
I0601 19:30:08.209558  6142 solver.cpp:237]     Train net output #0: Softmax = 0.732998 (* 1 = 0.732998 loss)
I0601 19:30:08.209574  6142 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I0601 19:31:52.753717  6142 solver.cpp:218] Iteration 3100 (0.956556 iter/s, 104.542s/100 iters), loss = 0.626941
I0601 19:31:52.753875  6142 solver.cpp:237]     Train net output #0: Softmax = 0.434764 (* 1 = 0.434764 loss)
I0601 19:31:52.753893  6142 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I0601 19:32:17.374754  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:33:37.352947  6142 solver.cpp:218] Iteration 3200 (0.956053 iter/s, 104.597s/100 iters), loss = 0.593798
I0601 19:33:37.353103  6142 solver.cpp:237]     Train net output #0: Softmax = 0.6314 (* 1 = 0.6314 loss)
I0601 19:33:37.353121  6142 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I0601 19:35:21.925601  6142 solver.cpp:218] Iteration 3300 (0.956297 iter/s, 104.57s/100 iters), loss = 0.580353
I0601 19:35:21.925756  6142 solver.cpp:237]     Train net output #0: Softmax = 0.731897 (* 1 = 0.731897 loss)
I0601 19:35:21.925773  6142 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I0601 19:37:06.513677  6142 solver.cpp:218] Iteration 3400 (0.956155 iter/s, 104.586s/100 iters), loss = 0.569206
I0601 19:37:06.513896  6142 solver.cpp:237]     Train net output #0: Softmax = 0.726089 (* 1 = 0.726089 loss)
I0601 19:37:06.513914  6142 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I0601 19:37:44.130699  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:38:49.990852  6142 solver.cpp:330] Iteration 3500, Testing net (#0)
I0601 19:38:49.991192  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:38:50.664021  6142 solver.cpp:397]     Test net output #0: acc = 0.676
I0601 19:38:51.717998  6142 solver.cpp:218] Iteration 3500 (0.950557 iter/s, 105.201s/100 iters), loss = 0.546783
I0601 19:38:51.718062  6142 solver.cpp:237]     Train net output #0: Softmax = 0.401779 (* 1 = 0.401779 loss)
I0601 19:38:51.718076  6142 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I0601 19:40:36.263070  6142 solver.cpp:218] Iteration 3600 (0.956551 iter/s, 104.542s/100 iters), loss = 0.477182
I0601 19:40:36.263177  6142 solver.cpp:237]     Train net output #0: Softmax = 0.395395 (* 1 = 0.395395 loss)
I0601 19:40:36.263195  6142 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I0601 19:42:20.844210  6142 solver.cpp:218] Iteration 3700 (0.956221 iter/s, 104.578s/100 iters), loss = 0.485578
I0601 19:42:20.844332  6142 solver.cpp:237]     Train net output #0: Softmax = 0.493009 (* 1 = 0.493009 loss)
I0601 19:42:20.844350  6142 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I0601 19:43:11.541743  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:44:05.383985  6142 solver.cpp:218] Iteration 3800 (0.956599 iter/s, 104.537s/100 iters), loss = 0.535343
I0601 19:44:05.384135  6142 solver.cpp:237]     Train net output #0: Softmax = 0.62253 (* 1 = 0.62253 loss)
I0601 19:44:05.384155  6142 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I0601 19:45:49.936228  6142 solver.cpp:218] Iteration 3900 (0.956485 iter/s, 104.55s/100 iters), loss = 0.663219
I0601 19:45:49.936331  6142 solver.cpp:237]     Train net output #0: Softmax = 0.512554 (* 1 = 0.512554 loss)
I0601 19:45:49.936347  6142 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I0601 19:47:33.495326  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_4000.caffemodel
I0601 19:47:33.662595  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_4000.solverstate
I0601 19:47:33.806583  6142 solver.cpp:330] Iteration 4000, Testing net (#0)
I0601 19:47:33.806870  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:47:34.471616  6142 solver.cpp:397]     Test net output #0: acc = 0.684
I0601 19:47:35.518478  6142 solver.cpp:218] Iteration 4000 (0.947153 iter/s, 105.58s/100 iters), loss = 0.57755
I0601 19:47:35.518540  6142 solver.cpp:237]     Train net output #0: Softmax = 0.495989 (* 1 = 0.495989 loss)
I0601 19:47:35.518555  6142 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I0601 19:48:39.338492  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:49:20.121107  6142 solver.cpp:218] Iteration 4100 (0.956023 iter/s, 104.6s/100 iters), loss = 0.646585
I0601 19:49:20.121260  6142 solver.cpp:237]     Train net output #0: Softmax = 0.680632 (* 1 = 0.680632 loss)
I0601 19:49:20.121279  6142 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I0601 19:51:04.730666  6142 solver.cpp:218] Iteration 4200 (0.95596 iter/s, 104.607s/100 iters), loss = 0.621592
I0601 19:51:04.730826  6142 solver.cpp:237]     Train net output #0: Softmax = 0.519311 (* 1 = 0.519311 loss)
I0601 19:51:04.730844  6142 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I0601 19:52:49.307756  6142 solver.cpp:218] Iteration 4300 (0.956257 iter/s, 104.574s/100 iters), loss = 0.58534
I0601 19:52:49.307907  6142 solver.cpp:237]     Train net output #0: Softmax = 0.542878 (* 1 = 0.542878 loss)
I0601 19:52:49.307925  6142 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I0601 19:54:06.191880  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:54:33.858975  6142 solver.cpp:218] Iteration 4400 (0.956493 iter/s, 104.549s/100 iters), loss = 0.40431
I0601 19:54:33.859036  6142 solver.cpp:237]     Train net output #0: Softmax = 0.300179 (* 1 = 0.300179 loss)
I0601 19:54:33.859059  6142 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I0601 19:56:17.414137  6142 solver.cpp:330] Iteration 4500, Testing net (#0)
I0601 19:56:17.414474  6142 net.cpp:676] Ignoring source layer Softmax
I0601 19:56:18.093487  6142 solver.cpp:397]     Test net output #0: acc = 0.656
I0601 19:56:19.130252  6142 solver.cpp:218] Iteration 4500 (0.94995 iter/s, 105.269s/100 iters), loss = 0.564793
I0601 19:56:19.130321  6142 solver.cpp:237]     Train net output #0: Softmax = 0.834349 (* 1 = 0.834349 loss)
I0601 19:56:19.130337  6142 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I0601 19:58:03.718716  6142 solver.cpp:218] Iteration 4600 (0.956152 iter/s, 104.586s/100 iters), loss = 0.450948
I0601 19:58:03.718874  6142 solver.cpp:237]     Train net output #0: Softmax = 0.399512 (* 1 = 0.399512 loss)
I0601 19:58:03.718892  6142 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I0601 19:59:33.648736  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 19:59:48.271973  6142 solver.cpp:218] Iteration 4700 (0.956474 iter/s, 104.551s/100 iters), loss = 0.518516
I0601 19:59:48.272051  6142 solver.cpp:237]     Train net output #0: Softmax = 0.37522 (* 1 = 0.37522 loss)
I0601 19:59:48.272068  6142 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I0601 20:01:32.898036  6142 solver.cpp:218] Iteration 4800 (0.955808 iter/s, 104.623s/100 iters), loss = 0.468628
I0601 20:01:32.898190  6142 solver.cpp:237]     Train net output #0: Softmax = 0.380944 (* 1 = 0.380944 loss)
I0601 20:01:32.898207  6142 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I0601 20:03:17.442221  6142 solver.cpp:218] Iteration 4900 (0.956557 iter/s, 104.542s/100 iters), loss = 0.470305
I0601 20:03:17.442370  6142 solver.cpp:237]     Train net output #0: Softmax = 0.320976 (* 1 = 0.320976 loss)
I0601 20:03:17.442389  6142 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I0601 20:05:00.383445  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:05:00.924389  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_5000.caffemodel
I0601 20:05:01.092525  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_5000.solverstate
I0601 20:05:01.232692  6142 solver.cpp:330] Iteration 5000, Testing net (#0)
I0601 20:05:01.232980  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:05:01.908429  6142 solver.cpp:397]     Test net output #0: acc = 0.66
I0601 20:05:02.939922  6142 solver.cpp:218] Iteration 5000 (0.947912 iter/s, 105.495s/100 iters), loss = 0.484635
I0601 20:05:02.939991  6142 solver.cpp:237]     Train net output #0: Softmax = 0.575098 (* 1 = 0.575098 loss)
I0601 20:05:02.940006  6142 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0601 20:06:47.408805  6142 solver.cpp:218] Iteration 5100 (0.957246 iter/s, 104.466s/100 iters), loss = 0.506989
I0601 20:06:47.408957  6142 solver.cpp:237]     Train net output #0: Softmax = 0.4778 (* 1 = 0.4778 loss)
I0601 20:06:47.408974  6142 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0601 20:08:31.962281  6142 solver.cpp:218] Iteration 5200 (0.956472 iter/s, 104.551s/100 iters), loss = 0.491563
I0601 20:08:31.962443  6142 solver.cpp:237]     Train net output #0: Softmax = 0.774392 (* 1 = 0.774392 loss)
I0601 20:08:31.962462  6142 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0601 20:10:16.533597  6142 solver.cpp:218] Iteration 5300 (0.956309 iter/s, 104.569s/100 iters), loss = 0.46023
I0601 20:10:16.533702  6142 solver.cpp:237]     Train net output #0: Softmax = 0.409446 (* 1 = 0.409446 loss)
I0601 20:10:16.533720  6142 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0601 20:10:28.036131  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:12:01.149194  6142 solver.cpp:218] Iteration 5400 (0.955904 iter/s, 104.613s/100 iters), loss = 0.475988
I0601 20:12:01.149343  6142 solver.cpp:237]     Train net output #0: Softmax = 0.560812 (* 1 = 0.560812 loss)
I0601 20:12:01.149360  6142 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0601 20:13:44.643890  6142 solver.cpp:330] Iteration 5500, Testing net (#0)
I0601 20:13:44.644219  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:13:45.309103  6142 solver.cpp:397]     Test net output #0: acc = 0.736
I0601 20:13:46.357484  6142 solver.cpp:218] Iteration 5500 (0.950519 iter/s, 105.206s/100 iters), loss = 0.579935
I0601 20:13:46.357544  6142 solver.cpp:237]     Train net output #0: Softmax = 1.08953 (* 1 = 1.08953 loss)
I0601 20:13:46.357560  6142 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0601 20:15:30.849133  6142 solver.cpp:218] Iteration 5600 (0.957037 iter/s, 104.489s/100 iters), loss = 0.493078
I0601 20:15:30.849261  6142 solver.cpp:237]     Train net output #0: Softmax = 0.463477 (* 1 = 0.463477 loss)
I0601 20:15:30.849278  6142 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0601 20:15:55.423180  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:17:15.371016  6142 solver.cpp:218] Iteration 5700 (0.956761 iter/s, 104.519s/100 iters), loss = 0.644637
I0601 20:17:15.371140  6142 solver.cpp:237]     Train net output #0: Softmax = 0.558814 (* 1 = 0.558814 loss)
I0601 20:17:15.371158  6142 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0601 20:18:59.821796  6142 solver.cpp:218] Iteration 5800 (0.957412 iter/s, 104.448s/100 iters), loss = 0.588814
I0601 20:18:59.821895  6142 solver.cpp:237]     Train net output #0: Softmax = 0.672666 (* 1 = 0.672666 loss)
I0601 20:18:59.821911  6142 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0601 20:20:44.303944  6142 solver.cpp:218] Iteration 5900 (0.957125 iter/s, 104.48s/100 iters), loss = 0.525314
I0601 20:20:44.304109  6142 solver.cpp:237]     Train net output #0: Softmax = 0.500076 (* 1 = 0.500076 loss)
I0601 20:20:44.304128  6142 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0601 20:21:21.973103  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:22:27.759212  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_6000.caffemodel
I0601 20:22:27.925079  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_6000.solverstate
I0601 20:22:28.071503  6142 solver.cpp:330] Iteration 6000, Testing net (#0)
I0601 20:22:28.071784  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:22:28.746014  6142 solver.cpp:397]     Test net output #0: acc = 0.772
I0601 20:22:29.796149  6142 solver.cpp:218] Iteration 6000 (0.947961 iter/s, 105.49s/100 iters), loss = 0.490437
I0601 20:22:29.796208  6142 solver.cpp:237]     Train net output #0: Softmax = 0.338374 (* 1 = 0.338374 loss)
I0601 20:22:29.796224  6142 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0601 20:24:14.398844  6142 solver.cpp:218] Iteration 6100 (0.956021 iter/s, 104.6s/100 iters), loss = 0.486927
I0601 20:24:14.398979  6142 solver.cpp:237]     Train net output #0: Softmax = 0.245286 (* 1 = 0.245286 loss)
I0601 20:24:14.398998  6142 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0601 20:25:58.938374  6142 solver.cpp:218] Iteration 6200 (0.9566 iter/s, 104.537s/100 iters), loss = 0.372706
I0601 20:25:58.938478  6142 solver.cpp:237]     Train net output #0: Softmax = 0.252804 (* 1 = 0.252804 loss)
I0601 20:25:58.938495  6142 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0601 20:26:49.636059  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:27:43.413396  6142 solver.cpp:218] Iteration 6300 (0.95719 iter/s, 104.472s/100 iters), loss = 0.422996
I0601 20:27:43.413523  6142 solver.cpp:237]     Train net output #0: Softmax = 0.324897 (* 1 = 0.324897 loss)
I0601 20:27:43.413540  6142 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0601 20:29:27.924988  6142 solver.cpp:218] Iteration 6400 (0.956855 iter/s, 104.509s/100 iters), loss = 0.493788
I0601 20:29:27.925159  6142 solver.cpp:237]     Train net output #0: Softmax = 0.225541 (* 1 = 0.225541 loss)
I0601 20:29:27.925177  6142 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0601 20:31:11.448591  6142 solver.cpp:330] Iteration 6500, Testing net (#0)
I0601 20:31:11.448909  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:31:12.135994  6142 solver.cpp:397]     Test net output #0: acc = 0.716
I0601 20:31:13.165542  6142 solver.cpp:218] Iteration 6500 (0.950228 iter/s, 105.238s/100 iters), loss = 0.453011
I0601 20:31:13.165606  6142 solver.cpp:237]     Train net output #0: Softmax = 0.30031 (* 1 = 0.30031 loss)
I0601 20:31:13.165621  6142 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0601 20:32:16.947176  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:32:57.704154  6142 solver.cpp:218] Iteration 6600 (0.956607 iter/s, 104.536s/100 iters), loss = 0.433398
I0601 20:32:57.704324  6142 solver.cpp:237]     Train net output #0: Softmax = 0.19139 (* 1 = 0.19139 loss)
I0601 20:32:57.704342  6142 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0601 20:34:42.175407  6142 solver.cpp:218] Iteration 6700 (0.957225 iter/s, 104.469s/100 iters), loss = 0.479863
I0601 20:34:42.175568  6142 solver.cpp:237]     Train net output #0: Softmax = 0.266204 (* 1 = 0.266204 loss)
I0601 20:34:42.175586  6142 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0601 20:36:26.685005  6142 solver.cpp:218] Iteration 6800 (0.956874 iter/s, 104.507s/100 iters), loss = 0.415199
I0601 20:36:26.685108  6142 solver.cpp:237]     Train net output #0: Softmax = 0.516746 (* 1 = 0.516746 loss)
I0601 20:36:26.685124  6142 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0601 20:37:43.494426  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:38:11.176087  6142 solver.cpp:218] Iteration 6900 (0.957043 iter/s, 104.488s/100 iters), loss = 0.301514
I0601 20:38:11.176146  6142 solver.cpp:237]     Train net output #0: Softmax = 0.236302 (* 1 = 0.236302 loss)
I0601 20:38:11.176160  6142 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0601 20:39:54.592440  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_7000.caffemodel
I0601 20:39:54.760316  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_7000.solverstate
I0601 20:39:54.898519  6142 solver.cpp:330] Iteration 7000, Testing net (#0)
I0601 20:39:54.898802  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:39:55.574381  6142 solver.cpp:397]     Test net output #0: acc = 0.792
I0601 20:39:56.623713  6142 solver.cpp:218] Iteration 7000 (0.948362 iter/s, 105.445s/100 iters), loss = 0.507479
I0601 20:39:56.623775  6142 solver.cpp:237]     Train net output #0: Softmax = 1.0674 (* 1 = 1.0674 loss)
I0601 20:39:56.623790  6142 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0601 20:41:41.166838  6142 solver.cpp:218] Iteration 7100 (0.956566 iter/s, 104.541s/100 iters), loss = 0.344725
I0601 20:41:41.166990  6142 solver.cpp:237]     Train net output #0: Softmax = 0.254058 (* 1 = 0.254058 loss)
I0601 20:41:41.167007  6142 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0601 20:43:11.140086  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:43:25.768404  6142 solver.cpp:218] Iteration 7200 (0.956032 iter/s, 104.599s/100 iters), loss = 0.406778
I0601 20:43:25.768466  6142 solver.cpp:237]     Train net output #0: Softmax = 0.18771 (* 1 = 0.18771 loss)
I0601 20:43:25.768481  6142 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0601 20:45:10.320778  6142 solver.cpp:218] Iteration 7300 (0.956482 iter/s, 104.55s/100 iters), loss = 0.360567
I0601 20:45:10.320926  6142 solver.cpp:237]     Train net output #0: Softmax = 0.340646 (* 1 = 0.340646 loss)
I0601 20:45:10.320945  6142 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0601 20:46:54.863075  6142 solver.cpp:218] Iteration 7400 (0.956565 iter/s, 104.541s/100 iters), loss = 0.407432
I0601 20:46:54.863219  6142 solver.cpp:237]     Train net output #0: Softmax = 0.146748 (* 1 = 0.146748 loss)
I0601 20:46:54.863235  6142 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0601 20:48:37.804847  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:48:38.327442  6142 solver.cpp:330] Iteration 7500, Testing net (#0)
I0601 20:48:38.327680  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:48:39.003399  6142 solver.cpp:397]     Test net output #0: acc = 0.8
I0601 20:48:40.030122  6142 solver.cpp:218] Iteration 7500 (0.950873 iter/s, 105.167s/100 iters), loss = 0.390817
I0601 20:48:40.030189  6142 solver.cpp:237]     Train net output #0: Softmax = 0.490122 (* 1 = 0.490122 loss)
I0601 20:48:40.030205  6142 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0601 20:50:24.540455  6142 solver.cpp:218] Iteration 7600 (0.95685 iter/s, 104.51s/100 iters), loss = 0.366945
I0601 20:50:24.540655  6142 solver.cpp:237]     Train net output #0: Softmax = 0.175151 (* 1 = 0.175151 loss)
I0601 20:50:24.540674  6142 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0601 20:52:09.010718  6142 solver.cpp:218] Iteration 7700 (0.957221 iter/s, 104.469s/100 iters), loss = 0.338235
I0601 20:52:09.010871  6142 solver.cpp:237]     Train net output #0: Softmax = 0.339438 (* 1 = 0.339438 loss)
I0601 20:52:09.010890  6142 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0601 20:53:53.443253  6142 solver.cpp:218] Iteration 7800 (0.957568 iter/s, 104.431s/100 iters), loss = 0.355724
I0601 20:53:53.443408  6142 solver.cpp:237]     Train net output #0: Softmax = 0.184117 (* 1 = 0.184117 loss)
I0601 20:53:53.443424  6142 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0601 20:54:04.965337  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 20:55:37.860519  6142 solver.cpp:218] Iteration 7900 (0.95771 iter/s, 104.416s/100 iters), loss = 0.351411
I0601 20:55:37.860680  6142 solver.cpp:237]     Train net output #0: Softmax = 0.51891 (* 1 = 0.51891 loss)
I0601 20:55:37.860698  6142 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0601 20:57:21.231578  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_8000.caffemodel
I0601 20:57:21.397122  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_8000.solverstate
I0601 20:57:21.535136  6142 solver.cpp:330] Iteration 8000, Testing net (#0)
I0601 20:57:21.535420  6142 net.cpp:676] Ignoring source layer Softmax
I0601 20:57:22.208453  6142 solver.cpp:397]     Test net output #0: acc = 0.768
I0601 20:57:23.257573  6142 solver.cpp:218] Iteration 8000 (0.948809 iter/s, 105.395s/100 iters), loss = 0.43574
I0601 20:57:23.257634  6142 solver.cpp:237]     Train net output #0: Softmax = 0.913625 (* 1 = 0.913625 loss)
I0601 20:57:23.257650  6142 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0601 20:59:07.748267  6142 solver.cpp:218] Iteration 8100 (0.957038 iter/s, 104.489s/100 iters), loss = 0.461821
I0601 20:59:07.748378  6142 solver.cpp:237]     Train net output #0: Softmax = 0.325757 (* 1 = 0.325757 loss)
I0601 20:59:07.748394  6142 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0601 20:59:32.342590  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:00:52.243697  6142 solver.cpp:218] Iteration 8200 (0.956997 iter/s, 104.494s/100 iters), loss = 0.42004
I0601 21:00:52.243824  6142 solver.cpp:237]     Train net output #0: Softmax = 0.323147 (* 1 = 0.323147 loss)
I0601 21:00:52.243841  6142 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0601 21:02:36.701385  6142 solver.cpp:218] Iteration 8300 (0.957343 iter/s, 104.456s/100 iters), loss = 0.416608
I0601 21:02:36.701509  6142 solver.cpp:237]     Train net output #0: Softmax = 0.224403 (* 1 = 0.224403 loss)
I0601 21:02:36.701526  6142 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0601 21:04:21.215080  6142 solver.cpp:218] Iteration 8400 (0.95683 iter/s, 104.512s/100 iters), loss = 0.433424
I0601 21:04:21.215224  6142 solver.cpp:237]     Train net output #0: Softmax = 0.672419 (* 1 = 0.672419 loss)
I0601 21:04:21.215242  6142 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0601 21:04:58.833012  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:06:04.681742  6142 solver.cpp:330] Iteration 8500, Testing net (#0)
I0601 21:06:04.682067  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:06:05.372105  6142 solver.cpp:397]     Test net output #0: acc = 0.824
I0601 21:06:06.396004  6142 solver.cpp:218] Iteration 8500 (0.950761 iter/s, 105.179s/100 iters), loss = 0.413327
I0601 21:06:06.396071  6142 solver.cpp:237]     Train net output #0: Softmax = 0.317206 (* 1 = 0.317206 loss)
I0601 21:06:06.396086  6142 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0601 21:07:50.898288  6142 solver.cpp:218] Iteration 8600 (0.956936 iter/s, 104.5s/100 iters), loss = 0.413651
I0601 21:07:50.898492  6142 solver.cpp:237]     Train net output #0: Softmax = 0.247139 (* 1 = 0.247139 loss)
I0601 21:07:50.898511  6142 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0601 21:09:35.383059  6142 solver.cpp:218] Iteration 8700 (0.957097 iter/s, 104.483s/100 iters), loss = 0.341777
I0601 21:09:35.383229  6142 solver.cpp:237]     Train net output #0: Softmax = 0.103094 (* 1 = 0.103094 loss)
I0601 21:09:35.383246  6142 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0601 21:10:26.053526  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:11:19.925997  6142 solver.cpp:218] Iteration 8800 (0.956565 iter/s, 104.541s/100 iters), loss = 0.267073
I0601 21:11:19.926146  6142 solver.cpp:237]     Train net output #0: Softmax = 0.517252 (* 1 = 0.517252 loss)
I0601 21:11:19.926162  6142 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0601 21:13:04.458817  6142 solver.cpp:218] Iteration 8900 (0.956657 iter/s, 104.531s/100 iters), loss = 0.450384
I0601 21:13:04.458966  6142 solver.cpp:237]     Train net output #0: Softmax = 0.174833 (* 1 = 0.174833 loss)
I0601 21:13:04.458983  6142 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0601 21:14:47.918746  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_9000.caffemodel
I0601 21:14:48.084699  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_9000.solverstate
I0601 21:14:48.224807  6142 solver.cpp:330] Iteration 9000, Testing net (#0)
I0601 21:14:48.225091  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:14:48.896073  6142 solver.cpp:397]     Test net output #0: acc = 0.78
I0601 21:14:49.941385  6142 solver.cpp:218] Iteration 9000 (0.948044 iter/s, 105.48s/100 iters), loss = 0.360107
I0601 21:14:49.941452  6142 solver.cpp:237]     Train net output #0: Softmax = 0.406672 (* 1 = 0.406672 loss)
I0601 21:14:49.941467  6142 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0601 21:15:53.713338  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:16:34.468031  6142 solver.cpp:218] Iteration 9100 (0.956714 iter/s, 104.524s/100 iters), loss = 0.393611
I0601 21:16:34.468132  6142 solver.cpp:237]     Train net output #0: Softmax = 0.650548 (* 1 = 0.650548 loss)
I0601 21:16:34.468148  6142 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0601 21:18:18.964954  6142 solver.cpp:218] Iteration 9200 (0.956986 iter/s, 104.495s/100 iters), loss = 0.343472
I0601 21:18:18.965107  6142 solver.cpp:237]     Train net output #0: Softmax = 0.280162 (* 1 = 0.280162 loss)
I0601 21:18:18.965126  6142 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0601 21:20:03.494593  6142 solver.cpp:218] Iteration 9300 (0.956687 iter/s, 104.527s/100 iters), loss = 0.354413
I0601 21:20:03.494695  6142 solver.cpp:237]     Train net output #0: Softmax = 0.422248 (* 1 = 0.422248 loss)
I0601 21:20:03.494712  6142 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0601 21:21:20.313501  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:21:47.968995  6142 solver.cpp:218] Iteration 9400 (0.957206 iter/s, 104.471s/100 iters), loss = 0.237539
I0601 21:21:47.969058  6142 solver.cpp:237]     Train net output #0: Softmax = 0.404725 (* 1 = 0.404725 loss)
I0601 21:21:47.969074  6142 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0601 21:23:31.432843  6142 solver.cpp:330] Iteration 9500, Testing net (#0)
I0601 21:23:31.433125  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:23:32.027436  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:23:32.118683  6142 solver.cpp:397]     Test net output #0: acc = 0.88
I0601 21:23:33.149835  6142 solver.cpp:218] Iteration 9500 (0.950776 iter/s, 105.177s/100 iters), loss = 0.490545
I0601 21:23:33.149894  6142 solver.cpp:237]     Train net output #0: Softmax = 1.29901 (* 1 = 1.29901 loss)
I0601 21:23:33.149910  6142 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I0601 21:25:17.598801  6142 solver.cpp:218] Iteration 9600 (0.957436 iter/s, 104.446s/100 iters), loss = 0.310056
I0601 21:25:17.598990  6142 solver.cpp:237]     Train net output #0: Softmax = 0.461284 (* 1 = 0.461284 loss)
I0601 21:25:17.599009  6142 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I0601 21:26:47.405920  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:27:02.052935  6142 solver.cpp:218] Iteration 9700 (0.957389 iter/s, 104.451s/100 iters), loss = 0.362207
I0601 21:27:02.052999  6142 solver.cpp:237]     Train net output #0: Softmax = 0.193739 (* 1 = 0.193739 loss)
I0601 21:27:02.053014  6142 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I0601 21:28:46.493503  6142 solver.cpp:218] Iteration 9800 (0.95751 iter/s, 104.438s/100 iters), loss = 0.292615
I0601 21:28:46.493657  6142 solver.cpp:237]     Train net output #0: Softmax = 0.273297 (* 1 = 0.273297 loss)
I0601 21:28:46.493675  6142 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I0601 21:30:31.000079  6142 solver.cpp:218] Iteration 9900 (0.956905 iter/s, 104.504s/100 iters), loss = 0.282243
I0601 21:30:31.000238  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0614321 (* 1 = 0.0614321 loss)
I0601 21:30:31.000257  6142 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I0601 21:32:13.906455  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:32:14.433537  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_10000.caffemodel
I0601 21:32:14.602985  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_10000.solverstate
I0601 21:32:14.741490  6142 solver.cpp:330] Iteration 10000, Testing net (#0)
I0601 21:32:14.741771  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:32:15.420827  6142 solver.cpp:397]     Test net output #0: acc = 0.856
I0601 21:32:16.471292  6142 solver.cpp:218] Iteration 10000 (0.948152 iter/s, 105.468s/100 iters), loss = 0.29826
I0601 21:32:16.471352  6142 solver.cpp:237]     Train net output #0: Softmax = 0.385985 (* 1 = 0.385985 loss)
I0601 21:32:16.471367  6142 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I0601 21:34:01.013296  6142 solver.cpp:218] Iteration 10100 (0.956578 iter/s, 104.539s/100 iters), loss = 0.257785
I0601 21:34:01.013450  6142 solver.cpp:237]     Train net output #0: Softmax = 0.16668 (* 1 = 0.16668 loss)
I0601 21:34:01.013469  6142 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I0601 21:35:45.463600  6142 solver.cpp:218] Iteration 10200 (0.957418 iter/s, 104.448s/100 iters), loss = 0.260226
I0601 21:35:45.463706  6142 solver.cpp:237]     Train net output #0: Softmax = 0.205966 (* 1 = 0.205966 loss)
I0601 21:35:45.463723  6142 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I0601 21:37:29.950568  6142 solver.cpp:218] Iteration 10300 (0.957082 iter/s, 104.484s/100 iters), loss = 0.234217
I0601 21:37:29.950734  6142 solver.cpp:237]     Train net output #0: Softmax = 0.177075 (* 1 = 0.177075 loss)
I0601 21:37:29.950753  6142 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I0601 21:37:41.453896  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:39:14.427198  6142 solver.cpp:218] Iteration 10400 (0.957177 iter/s, 104.474s/100 iters), loss = 0.389621
I0601 21:39:14.427358  6142 solver.cpp:237]     Train net output #0: Softmax = 1.10391 (* 1 = 1.10391 loss)
I0601 21:39:14.427376  6142 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I0601 21:40:57.877239  6142 solver.cpp:330] Iteration 10500, Testing net (#0)
I0601 21:40:57.877538  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:40:58.557509  6142 solver.cpp:397]     Test net output #0: acc = 0.804
I0601 21:40:59.587386  6142 solver.cpp:218] Iteration 10500 (0.950954 iter/s, 105.158s/100 iters), loss = 0.279073
I0601 21:40:59.587446  6142 solver.cpp:237]     Train net output #0: Softmax = 0.669904 (* 1 = 0.669904 loss)
I0601 21:40:59.587460  6142 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I0601 21:42:44.079514  6142 solver.cpp:218] Iteration 10600 (0.957034 iter/s, 104.489s/100 iters), loss = 0.358833
I0601 21:42:44.079710  6142 solver.cpp:237]     Train net output #0: Softmax = 0.261679 (* 1 = 0.261679 loss)
I0601 21:42:44.079728  6142 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I0601 21:43:08.682531  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:44:28.611038  6142 solver.cpp:218] Iteration 10700 (0.956673 iter/s, 104.529s/100 iters), loss = 0.403057
I0601 21:44:28.611172  6142 solver.cpp:237]     Train net output #0: Softmax = 0.530922 (* 1 = 0.530922 loss)
I0601 21:44:28.611191  6142 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I0601 21:46:13.062379  6142 solver.cpp:218] Iteration 10800 (0.957407 iter/s, 104.449s/100 iters), loss = 0.343752
I0601 21:46:13.062528  6142 solver.cpp:237]     Train net output #0: Softmax = 0.148488 (* 1 = 0.148488 loss)
I0601 21:46:13.062546  6142 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I0601 21:47:57.541430  6142 solver.cpp:218] Iteration 10900 (0.957153 iter/s, 104.477s/100 iters), loss = 0.237508
I0601 21:47:57.541589  6142 solver.cpp:237]     Train net output #0: Softmax = 0.271103 (* 1 = 0.271103 loss)
I0601 21:47:57.541607  6142 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I0601 21:48:35.171011  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:49:41.028985  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_11000.caffemodel
I0601 21:49:41.196168  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_11000.solverstate
I0601 21:49:41.341243  6142 solver.cpp:330] Iteration 11000, Testing net (#0)
I0601 21:49:41.341511  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:49:42.009979  6142 solver.cpp:397]     Test net output #0: acc = 0.864
I0601 21:49:43.062074  6142 solver.cpp:218] Iteration 11000 (0.947705 iter/s, 105.518s/100 iters), loss = 0.324251
I0601 21:49:43.062136  6142 solver.cpp:237]     Train net output #0: Softmax = 0.127764 (* 1 = 0.127764 loss)
I0601 21:49:43.062151  6142 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I0601 21:51:27.656217  6142 solver.cpp:218] Iteration 11100 (0.956099 iter/s, 104.592s/100 iters), loss = 0.207164
I0601 21:51:27.656363  6142 solver.cpp:237]     Train net output #0: Softmax = 0.199041 (* 1 = 0.199041 loss)
I0601 21:51:27.656380  6142 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I0601 21:53:12.225706  6142 solver.cpp:218] Iteration 11200 (0.956325 iter/s, 104.567s/100 iters), loss = 0.238486
I0601 21:53:12.225859  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0847002 (* 1 = 0.0847002 loss)
I0601 21:53:12.225878  6142 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I0601 21:54:02.905596  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 21:54:56.700781  6142 solver.cpp:218] Iteration 11300 (0.957189 iter/s, 104.473s/100 iters), loss = 0.225251
I0601 21:54:56.700881  6142 solver.cpp:237]     Train net output #0: Softmax = 0.631367 (* 1 = 0.631367 loss)
I0601 21:54:56.700897  6142 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I0601 21:56:41.175169  6142 solver.cpp:218] Iteration 11400 (0.957195 iter/s, 104.472s/100 iters), loss = 0.389927
I0601 21:56:41.175329  6142 solver.cpp:237]     Train net output #0: Softmax = 0.051207 (* 1 = 0.051207 loss)
I0601 21:56:41.175348  6142 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I0601 21:58:24.571740  6142 solver.cpp:330] Iteration 11500, Testing net (#0)
I0601 21:58:24.572067  6142 net.cpp:676] Ignoring source layer Softmax
I0601 21:58:25.261510  6142 solver.cpp:397]     Test net output #0: acc = 0.84
I0601 21:58:26.292179  6142 solver.cpp:218] Iteration 11500 (0.951344 iter/s, 105.114s/100 iters), loss = 0.141098
I0601 21:58:26.292238  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0575389 (* 1 = 0.0575389 loss)
I0601 21:58:26.292255  6142 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I0601 21:59:30.115783  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:00:10.889232  6142 solver.cpp:218] Iteration 11600 (0.956073 iter/s, 104.595s/100 iters), loss = 0.245834
I0601 22:00:10.889451  6142 solver.cpp:237]     Train net output #0: Softmax = 0.346724 (* 1 = 0.346724 loss)
I0601 22:00:10.889469  6142 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I0601 22:01:55.441484  6142 solver.cpp:218] Iteration 11700 (0.956483 iter/s, 104.55s/100 iters), loss = 0.185325
I0601 22:01:55.441638  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0609068 (* 1 = 0.0609068 loss)
I0601 22:01:55.441658  6142 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I0601 22:03:40.063378  6142 solver.cpp:218] Iteration 11800 (0.955845 iter/s, 104.619s/100 iters), loss = 0.183152
I0601 22:03:40.063530  6142 solver.cpp:237]     Train net output #0: Softmax = 0.194102 (* 1 = 0.194102 loss)
I0601 22:03:40.063549  6142 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I0601 22:04:56.957279  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:05:24.686873  6142 solver.cpp:218] Iteration 11900 (0.955831 iter/s, 104.621s/100 iters), loss = 0.247917
I0601 22:05:24.686939  6142 solver.cpp:237]     Train net output #0: Softmax = 0.74148 (* 1 = 0.74148 loss)
I0601 22:05:24.686954  6142 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I0601 22:07:08.192656  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_12000.caffemodel
I0601 22:07:08.359428  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_12000.solverstate
I0601 22:07:08.499800  6142 solver.cpp:330] Iteration 12000, Testing net (#0)
I0601 22:07:08.500080  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:07:09.196224  6142 solver.cpp:397]     Test net output #0: acc = 0.888
I0601 22:07:10.227187  6142 solver.cpp:218] Iteration 12000 (0.947527 iter/s, 105.538s/100 iters), loss = 0.311191
I0601 22:07:10.227267  6142 solver.cpp:237]     Train net output #0: Softmax = 0.945908 (* 1 = 0.945908 loss)
I0601 22:07:10.227283  6142 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I0601 22:08:54.667753  6142 solver.cpp:218] Iteration 12100 (0.957505 iter/s, 104.438s/100 iters), loss = 0.182965
I0601 22:08:54.667913  6142 solver.cpp:237]     Train net output #0: Softmax = 0.370707 (* 1 = 0.370707 loss)
I0601 22:08:54.667932  6142 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I0601 22:10:24.484206  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:10:39.106550  6142 solver.cpp:218] Iteration 12200 (0.957522 iter/s, 104.436s/100 iters), loss = 0.371945
I0601 22:10:39.106612  6142 solver.cpp:237]     Train net output #0: Softmax = 0.300259 (* 1 = 0.300259 loss)
I0601 22:10:39.106627  6142 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I0601 22:12:23.548061  6142 solver.cpp:218] Iteration 12300 (0.957496 iter/s, 104.439s/100 iters), loss = 0.264304
I0601 22:12:23.548219  6142 solver.cpp:237]     Train net output #0: Softmax = 0.302087 (* 1 = 0.302087 loss)
I0601 22:12:23.548238  6142 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I0601 22:14:07.983556  6142 solver.cpp:218] Iteration 12400 (0.957552 iter/s, 104.433s/100 iters), loss = 0.180763
I0601 22:14:07.983713  6142 solver.cpp:237]     Train net output #0: Softmax = 0.045739 (* 1 = 0.045739 loss)
I0601 22:14:07.983732  6142 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I0601 22:15:50.857393  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:15:51.384299  6142 solver.cpp:330] Iteration 12500, Testing net (#0)
I0601 22:15:51.384603  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:15:52.068199  6142 solver.cpp:397]     Test net output #0: acc = 0.848
I0601 22:15:53.112907  6142 solver.cpp:218] Iteration 12500 (0.951232 iter/s, 105.127s/100 iters), loss = 0.190022
I0601 22:15:53.112970  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0600764 (* 1 = 0.0600764 loss)
I0601 22:15:53.112987  6142 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I0601 22:17:37.531050  6142 solver.cpp:218] Iteration 12600 (0.95771 iter/s, 104.416s/100 iters), loss = 0.208513
I0601 22:17:37.531224  6142 solver.cpp:237]     Train net output #0: Softmax = 0.123429 (* 1 = 0.123429 loss)
I0601 22:17:37.531242  6142 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I0601 22:19:21.987699  6142 solver.cpp:218] Iteration 12700 (0.957358 iter/s, 104.454s/100 iters), loss = 0.108709
I0601 22:19:21.987918  6142 solver.cpp:237]     Train net output #0: Softmax = 0.146082 (* 1 = 0.146082 loss)
I0601 22:19:21.987937  6142 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I0601 22:21:06.406399  6142 solver.cpp:218] Iteration 12800 (0.957706 iter/s, 104.416s/100 iters), loss = 0.23249
I0601 22:21:06.406555  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0958071 (* 1 = 0.0958071 loss)
I0601 22:21:06.406574  6142 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I0601 22:21:17.912931  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:22:50.927840  6142 solver.cpp:218] Iteration 12900 (0.956764 iter/s, 104.519s/100 iters), loss = 0.315584
I0601 22:22:50.928007  6142 solver.cpp:237]     Train net output #0: Softmax = 0.901552 (* 1 = 0.901552 loss)
I0601 22:22:50.928026  6142 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I0601 22:24:34.351267  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_13000.caffemodel
I0601 22:24:34.517980  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_13000.solverstate
I0601 22:24:34.655802  6142 solver.cpp:330] Iteration 13000, Testing net (#0)
I0601 22:24:34.656076  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:24:35.349413  6142 solver.cpp:397]     Test net output #0: acc = 0.868
I0601 22:24:36.378844  6142 solver.cpp:218] Iteration 13000 (0.94833 iter/s, 105.448s/100 iters), loss = 0.227727
I0601 22:24:36.378906  6142 solver.cpp:237]     Train net output #0: Softmax = 0.372242 (* 1 = 0.372242 loss)
I0601 22:24:36.378922  6142 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I0601 22:26:20.881654  6142 solver.cpp:218] Iteration 13100 (0.956934 iter/s, 104.5s/100 iters), loss = 0.379179
I0601 22:26:20.881814  6142 solver.cpp:237]     Train net output #0: Softmax = 0.336289 (* 1 = 0.336289 loss)
I0601 22:26:20.881834  6142 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I0601 22:26:45.457883  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:28:05.423128  6142 solver.cpp:218] Iteration 13200 (0.956581 iter/s, 104.539s/100 iters), loss = 0.35508
I0601 22:28:05.423266  6142 solver.cpp:237]     Train net output #0: Softmax = 0.455339 (* 1 = 0.455339 loss)
I0601 22:28:05.423283  6142 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I0601 22:29:49.916026  6142 solver.cpp:218] Iteration 13300 (0.956992 iter/s, 104.494s/100 iters), loss = 0.462521
I0601 22:29:49.916153  6142 solver.cpp:237]     Train net output #0: Softmax = 0.37767 (* 1 = 0.37767 loss)
I0601 22:29:49.916172  6142 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I0601 22:31:34.415355  6142 solver.cpp:218] Iteration 13400 (0.956927 iter/s, 104.501s/100 iters), loss = 0.178145
I0601 22:31:34.415495  6142 solver.cpp:237]     Train net output #0: Softmax = 0.209229 (* 1 = 0.209229 loss)
I0601 22:31:34.415513  6142 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I0601 22:32:12.064939  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:33:17.871301  6142 solver.cpp:330] Iteration 13500, Testing net (#0)
I0601 22:33:17.871631  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:33:18.547340  6142 solver.cpp:397]     Test net output #0: acc = 0.884
I0601 22:33:19.590469  6142 solver.cpp:218] Iteration 13500 (0.950785 iter/s, 105.176s/100 iters), loss = 0.127622
I0601 22:33:19.590538  6142 solver.cpp:237]     Train net output #0: Softmax = 0.226908 (* 1 = 0.226908 loss)
I0601 22:33:19.590553  6142 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I0601 22:35:04.028249  6142 solver.cpp:218] Iteration 13600 (0.957502 iter/s, 104.438s/100 iters), loss = 0.162834
I0601 22:35:04.028371  6142 solver.cpp:237]     Train net output #0: Softmax = 0.080796 (* 1 = 0.080796 loss)
I0601 22:35:04.028389  6142 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I0601 22:36:48.498791  6142 solver.cpp:218] Iteration 13700 (0.957206 iter/s, 104.471s/100 iters), loss = 0.206275
I0601 22:36:48.498993  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0194357 (* 1 = 0.0194357 loss)
I0601 22:36:48.499013  6142 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I0601 22:37:39.197053  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:38:32.977025  6142 solver.cpp:218] Iteration 13800 (0.95714 iter/s, 104.478s/100 iters), loss = 0.104695
I0601 22:38:32.977180  6142 solver.cpp:237]     Train net output #0: Softmax = 0.115659 (* 1 = 0.115659 loss)
I0601 22:38:32.977198  6142 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I0601 22:40:17.440567  6142 solver.cpp:218] Iteration 13900 (0.957277 iter/s, 104.463s/100 iters), loss = 0.32941
I0601 22:40:17.440691  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0887783 (* 1 = 0.0887783 loss)
I0601 22:40:17.440709  6142 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I0601 22:42:00.900118  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_14000.caffemodel
I0601 22:42:01.068960  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_14000.solverstate
I0601 22:42:01.213065  6142 solver.cpp:330] Iteration 14000, Testing net (#0)
I0601 22:42:01.213354  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:42:01.895814  6142 solver.cpp:397]     Test net output #0: acc = 0.848
I0601 22:42:02.924413  6142 solver.cpp:218] Iteration 14000 (0.948019 iter/s, 105.483s/100 iters), loss = 0.204183
I0601 22:42:02.924474  6142 solver.cpp:237]     Train net output #0: Softmax = 0.237845 (* 1 = 0.237845 loss)
I0601 22:42:02.924489  6142 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I0601 22:43:06.662503  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:43:47.380854  6142 solver.cpp:218] Iteration 14100 (0.957345 iter/s, 104.456s/100 iters), loss = 0.219965
I0601 22:43:47.381009  6142 solver.cpp:237]     Train net output #0: Softmax = 0.155265 (* 1 = 0.155265 loss)
I0601 22:43:47.381027  6142 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I0601 22:45:31.921799  6142 solver.cpp:218] Iteration 14200 (0.956574 iter/s, 104.54s/100 iters), loss = 0.14584
I0601 22:45:31.921957  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0376018 (* 1 = 0.0376018 loss)
I0601 22:45:31.921975  6142 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I0601 22:47:16.386229  6142 solver.cpp:218] Iteration 14300 (0.957275 iter/s, 104.463s/100 iters), loss = 0.0767958
I0601 22:47:16.386386  6142 solver.cpp:237]     Train net output #0: Softmax = 0.109781 (* 1 = 0.109781 loss)
I0601 22:47:16.386404  6142 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I0601 22:48:33.131178  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:49:00.806746  6142 solver.cpp:218] Iteration 14400 (0.957679 iter/s, 104.419s/100 iters), loss = 0.140264
I0601 22:49:00.806807  6142 solver.cpp:237]     Train net output #0: Softmax = 0.108053 (* 1 = 0.108053 loss)
I0601 22:49:00.806820  6142 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I0601 22:50:44.278540  6142 solver.cpp:330] Iteration 14500, Testing net (#0)
I0601 22:50:44.278861  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:50:44.958376  6142 solver.cpp:397]     Test net output #0: acc = 0.844
I0601 22:50:45.995306  6142 solver.cpp:218] Iteration 14500 (0.950687 iter/s, 105.187s/100 iters), loss = 0.211254
I0601 22:50:45.995383  6142 solver.cpp:237]     Train net output #0: Softmax = 0.753259 (* 1 = 0.753259 loss)
I0601 22:50:45.995398  6142 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I0601 22:52:30.576719  6142 solver.cpp:218] Iteration 14600 (0.956207 iter/s, 104.58s/100 iters), loss = 0.0607947
I0601 22:52:30.576877  6142 solver.cpp:237]     Train net output #0: Softmax = 0.170044 (* 1 = 0.170044 loss)
I0601 22:52:30.576896  6142 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I0601 22:54:00.471127  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:54:15.091526  6142 solver.cpp:218] Iteration 14700 (0.956817 iter/s, 104.513s/100 iters), loss = 0.213816
I0601 22:54:15.091586  6142 solver.cpp:237]     Train net output #0: Softmax = 0.289844 (* 1 = 0.289844 loss)
I0601 22:54:15.091601  6142 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I0601 22:55:59.616034  6142 solver.cpp:218] Iteration 14800 (0.956728 iter/s, 104.523s/100 iters), loss = 0.220257
I0601 22:55:59.620045  6142 solver.cpp:237]     Train net output #0: Softmax = 0.189298 (* 1 = 0.189298 loss)
I0601 22:55:59.620066  6142 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I0601 22:57:44.193210  6142 solver.cpp:218] Iteration 14900 (0.956283 iter/s, 104.572s/100 iters), loss = 0.117984
I0601 22:57:44.193301  6142 solver.cpp:237]     Train net output #0: Softmax = 0.012947 (* 1 = 0.012947 loss)
I0601 22:57:44.193317  6142 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I0601 22:59:27.201164  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 22:59:27.722692  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_15000.caffemodel
I0601 22:59:27.892061  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_15000.solverstate
I0601 22:59:28.036198  6142 solver.cpp:330] Iteration 15000, Testing net (#0)
I0601 22:59:28.036481  6142 net.cpp:676] Ignoring source layer Softmax
I0601 22:59:28.734294  6142 solver.cpp:397]     Test net output #0: acc = 0.924
I0601 22:59:29.770198  6142 solver.cpp:218] Iteration 15000 (0.947191 iter/s, 105.575s/100 iters), loss = 0.10866
I0601 22:59:29.770267  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0232306 (* 1 = 0.0232306 loss)
I0601 22:59:29.770282  6142 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I0601 23:01:14.409736  6142 solver.cpp:218] Iteration 15100 (0.955677 iter/s, 104.638s/100 iters), loss = 0.141768
I0601 23:01:14.409886  6142 solver.cpp:237]     Train net output #0: Softmax = 0.214975 (* 1 = 0.214975 loss)
I0601 23:01:14.409904  6142 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I0601 23:02:59.014942  6142 solver.cpp:218] Iteration 15200 (0.955992 iter/s, 104.603s/100 iters), loss = 0.0726898
I0601 23:02:59.015143  6142 solver.cpp:237]     Train net output #0: Softmax = 0.116813 (* 1 = 0.116813 loss)
I0601 23:02:59.015161  6142 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I0601 23:04:43.534476  6142 solver.cpp:218] Iteration 15300 (0.956776 iter/s, 104.518s/100 iters), loss = 0.0845601
I0601 23:04:43.534579  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0372527 (* 1 = 0.0372527 loss)
I0601 23:04:43.534595  6142 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I0601 23:04:55.051362  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:06:28.097347  6142 solver.cpp:218] Iteration 15400 (0.956379 iter/s, 104.561s/100 iters), loss = 0.15673
I0601 23:06:28.097504  6142 solver.cpp:237]     Train net output #0: Softmax = 0.419268 (* 1 = 0.419268 loss)
I0601 23:06:28.097523  6142 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I0601 23:08:11.562873  6142 solver.cpp:330] Iteration 15500, Testing net (#0)
I0601 23:08:11.563195  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:08:12.245069  6142 solver.cpp:397]     Test net output #0: acc = 0.868
I0601 23:08:13.291733  6142 solver.cpp:218] Iteration 15500 (0.950638 iter/s, 105.193s/100 iters), loss = 0.159189
I0601 23:08:13.291795  6142 solver.cpp:237]     Train net output #0: Softmax = 0.32939 (* 1 = 0.32939 loss)
I0601 23:08:13.291810  6142 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I0601 23:09:57.806497  6142 solver.cpp:218] Iteration 15600 (0.956818 iter/s, 104.513s/100 iters), loss = 0.126536
I0601 23:09:57.806617  6142 solver.cpp:237]     Train net output #0: Softmax = 0.398451 (* 1 = 0.398451 loss)
I0601 23:09:57.806633  6142 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I0601 23:10:22.374212  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:11:42.299073  6142 solver.cpp:218] Iteration 15700 (0.957022 iter/s, 104.491s/100 iters), loss = 0.302662
I0601 23:11:42.299252  6142 solver.cpp:237]     Train net output #0: Softmax = 0.247277 (* 1 = 0.247277 loss)
I0601 23:11:42.299270  6142 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I0601 23:13:26.790729  6142 solver.cpp:218] Iteration 15800 (0.957032 iter/s, 104.49s/100 iters), loss = 0.100155
I0601 23:13:26.790959  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0486661 (* 1 = 0.0486661 loss)
I0601 23:13:26.790987  6142 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I0601 23:15:11.214936  6142 solver.cpp:218] Iteration 15900 (0.95765 iter/s, 104.422s/100 iters), loss = 0.105042
I0601 23:15:11.215098  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0397935 (* 1 = 0.0397935 loss)
I0601 23:15:11.215116  6142 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I0601 23:15:48.795684  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:16:54.592945  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_16000.caffemodel
I0601 23:16:54.769795  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_16000.solverstate
I0601 23:16:54.910204  6142 solver.cpp:330] Iteration 16000, Testing net (#0)
I0601 23:16:54.910490  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:16:55.580050  6142 solver.cpp:397]     Test net output #0: acc = 0.884
I0601 23:16:56.624723  6142 solver.cpp:218] Iteration 16000 (0.948695 iter/s, 105.408s/100 iters), loss = 0.197882
I0601 23:16:56.624788  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0207491 (* 1 = 0.0207491 loss)
I0601 23:16:56.624802  6142 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I0601 23:18:41.106742  6142 solver.cpp:218] Iteration 16100 (0.957119 iter/s, 104.48s/100 iters), loss = 0.0895785
I0601 23:18:41.106887  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0262519 (* 1 = 0.0262519 loss)
I0601 23:18:41.106905  6142 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I0601 23:20:25.622589  6142 solver.cpp:218] Iteration 16200 (0.95681 iter/s, 104.514s/100 iters), loss = 0.154207
I0601 23:20:25.622763  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0679911 (* 1 = 0.0679911 loss)
I0601 23:20:25.622782  6142 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I0601 23:21:16.385404  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:22:10.271101  6142 solver.cpp:218] Iteration 16300 (0.955597 iter/s, 104.647s/100 iters), loss = 0.0869793
I0601 23:22:10.271266  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0432787 (* 1 = 0.0432787 loss)
I0601 23:22:10.271284  6142 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I0601 23:23:54.954623  6142 solver.cpp:218] Iteration 16400 (0.955277 iter/s, 104.682s/100 iters), loss = 0.235841
I0601 23:23:54.954727  6142 solver.cpp:237]     Train net output #0: Softmax = 0.25951 (* 1 = 0.25951 loss)
I0601 23:23:54.954743  6142 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I0601 23:25:38.559592  6142 solver.cpp:330] Iteration 16500, Testing net (#0)
I0601 23:25:38.559867  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:25:39.239591  6142 solver.cpp:397]     Test net output #0: acc = 0.832
I0601 23:25:40.270303  6142 solver.cpp:218] Iteration 16500 (0.949543 iter/s, 105.314s/100 iters), loss = 0.14761
I0601 23:25:40.270362  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0734993 (* 1 = 0.0734993 loss)
I0601 23:25:40.270377  6142 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I0601 23:26:44.107475  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:27:24.921707  6142 solver.cpp:218] Iteration 16600 (0.955569 iter/s, 104.65s/100 iters), loss = 0.251252
I0601 23:27:24.921860  6142 solver.cpp:237]     Train net output #0: Softmax = 0.525934 (* 1 = 0.525934 loss)
I0601 23:27:24.921880  6142 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I0601 23:29:09.607275  6142 solver.cpp:218] Iteration 16700 (0.955259 iter/s, 104.684s/100 iters), loss = 0.115239
I0601 23:29:09.607425  6142 solver.cpp:237]     Train net output #0: Softmax = 0.270608 (* 1 = 0.270608 loss)
I0601 23:29:09.607442  6142 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I0601 23:30:54.267954  6142 solver.cpp:218] Iteration 16800 (0.955486 iter/s, 104.659s/100 iters), loss = 0.0649949
I0601 23:30:54.268163  6142 solver.cpp:237]     Train net output #0: Softmax = 0.19882 (* 1 = 0.19882 loss)
I0601 23:30:54.268183  6142 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I0601 23:32:11.216094  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:32:38.942080  6142 solver.cpp:218] Iteration 16900 (0.955364 iter/s, 104.672s/100 iters), loss = 0.125795
I0601 23:32:38.942140  6142 solver.cpp:237]     Train net output #0: Softmax = 0.100423 (* 1 = 0.100423 loss)
I0601 23:32:38.942157  6142 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I0601 23:34:22.598270  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_17000.caffemodel
I0601 23:34:22.765705  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_17000.solverstate
I0601 23:34:22.911209  6142 solver.cpp:330] Iteration 17000, Testing net (#0)
I0601 23:34:22.911496  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:34:23.591420  6142 solver.cpp:397]     Test net output #0: acc = 0.912
I0601 23:34:24.632745  6142 solver.cpp:218] Iteration 17000 (0.946173 iter/s, 105.689s/100 iters), loss = 0.143421
I0601 23:34:24.632809  6142 solver.cpp:237]     Train net output #0: Softmax = 0.492117 (* 1 = 0.492117 loss)
I0601 23:34:24.632824  6142 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I0601 23:36:09.241142  6142 solver.cpp:218] Iteration 17100 (0.955963 iter/s, 104.607s/100 iters), loss = 0.113841
I0601 23:36:09.241245  6142 solver.cpp:237]     Train net output #0: Softmax = 0.388789 (* 1 = 0.388789 loss)
I0601 23:36:09.241261  6142 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I0601 23:37:39.212253  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:37:53.838755  6142 solver.cpp:218] Iteration 17200 (0.956117 iter/s, 104.59s/100 iters), loss = 0.0671539
I0601 23:37:53.838820  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0293531 (* 1 = 0.0293531 loss)
I0601 23:37:53.838836  6142 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I0601 23:39:38.437551  6142 solver.cpp:218] Iteration 17300 (0.956131 iter/s, 104.588s/100 iters), loss = 0.147553
I0601 23:39:38.437700  6142 solver.cpp:237]     Train net output #0: Softmax = 0.048264 (* 1 = 0.048264 loss)
I0601 23:39:38.437716  6142 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I0601 23:41:23.106459  6142 solver.cpp:218] Iteration 17400 (0.955479 iter/s, 104.66s/100 iters), loss = 0.141835
I0601 23:41:23.106649  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00412739 (* 1 = 0.00412739 loss)
I0601 23:41:23.106667  6142 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I0601 23:43:06.192281  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:43:06.702488  6142 solver.cpp:330] Iteration 17500, Testing net (#0)
I0601 23:43:06.702738  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:43:07.389236  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0601 23:43:08.419728  6142 solver.cpp:218] Iteration 17500 (0.949623 iter/s, 105.305s/100 iters), loss = 0.0274652
I0601 23:43:08.419787  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0126591 (* 1 = 0.0126591 loss)
I0601 23:43:08.419802  6142 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I0601 23:44:53.058717  6142 solver.cpp:218] Iteration 17600 (0.955733 iter/s, 104.632s/100 iters), loss = 0.179523
I0601 23:44:53.058872  6142 solver.cpp:237]     Train net output #0: Softmax = 0.105193 (* 1 = 0.105193 loss)
I0601 23:44:53.058890  6142 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I0601 23:46:37.727344  6142 solver.cpp:218] Iteration 17700 (0.955456 iter/s, 104.662s/100 iters), loss = 0.0360842
I0601 23:46:37.727490  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00809665 (* 1 = 0.00809665 loss)
I0601 23:46:37.727509  6142 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I0601 23:48:22.405731  6142 solver.cpp:218] Iteration 17800 (0.955362 iter/s, 104.672s/100 iters), loss = 0.051225
I0601 23:48:22.405994  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0256701 (* 1 = 0.0256701 loss)
I0601 23:48:22.406013  6142 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I0601 23:48:33.912456  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:50:07.010185  6142 solver.cpp:218] Iteration 17900 (0.956033 iter/s, 104.599s/100 iters), loss = 0.14486
I0601 23:50:07.010342  6142 solver.cpp:237]     Train net output #0: Softmax = 0.175102 (* 1 = 0.175102 loss)
I0601 23:50:07.010361  6142 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I0601 23:51:50.622202  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_18000.caffemodel
I0601 23:51:50.792378  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_18000.solverstate
I0601 23:51:50.932446  6142 solver.cpp:330] Iteration 18000, Testing net (#0)
I0601 23:51:50.932730  6142 net.cpp:676] Ignoring source layer Softmax
I0601 23:51:51.626272  6142 solver.cpp:397]     Test net output #0: acc = 0.9
I0601 23:51:52.658860  6142 solver.cpp:218] Iteration 18000 (0.946579 iter/s, 105.644s/100 iters), loss = 0.0787517
I0601 23:51:52.658933  6142 solver.cpp:237]     Train net output #0: Softmax = 0.132365 (* 1 = 0.132365 loss)
I0601 23:51:52.658949  6142 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I0601 23:53:37.239272  6142 solver.cpp:218] Iteration 18100 (0.956245 iter/s, 104.576s/100 iters), loss = 0.102651
I0601 23:53:37.239435  6142 solver.cpp:237]     Train net output #0: Softmax = 0.147284 (* 1 = 0.147284 loss)
I0601 23:53:37.239454  6142 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I0601 23:54:01.838378  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0601 23:55:21.860384  6142 solver.cpp:218] Iteration 18200 (0.955871 iter/s, 104.617s/100 iters), loss = 0.265212
I0601 23:55:21.860528  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0320164 (* 1 = 0.0320164 loss)
I0601 23:55:21.860546  6142 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I0601 23:57:06.501521  6142 solver.cpp:218] Iteration 18300 (0.955686 iter/s, 104.637s/100 iters), loss = 0.214228
I0601 23:57:06.501626  6142 solver.cpp:237]     Train net output #0: Softmax = 0.280814 (* 1 = 0.280814 loss)
I0601 23:57:06.501642  6142 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I0601 23:58:51.087945  6142 solver.cpp:218] Iteration 18400 (0.956184 iter/s, 104.582s/100 iters), loss = 0.100895
I0601 23:58:51.088058  6142 solver.cpp:237]     Train net output #0: Softmax = 0.259464 (* 1 = 0.259464 loss)
I0601 23:58:51.088076  6142 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I0601 23:59:28.780830  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:00:34.638290  6142 solver.cpp:330] Iteration 18500, Testing net (#0)
I0602 00:00:34.638581  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:00:35.328956  6142 solver.cpp:397]     Test net output #0: acc = 0.884
I0602 00:00:36.357820  6142 solver.cpp:218] Iteration 18500 (0.949975 iter/s, 105.266s/100 iters), loss = 0.112949
I0602 00:00:36.357885  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0268078 (* 1 = 0.0268078 loss)
I0602 00:00:36.357901  6142 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I0602 00:02:20.851364  6142 solver.cpp:218] Iteration 18600 (0.957031 iter/s, 104.49s/100 iters), loss = 0.0606469
I0602 00:02:20.851467  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00690934 (* 1 = 0.00690934 loss)
I0602 00:02:20.851485  6142 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I0602 00:04:05.337464  6142 solver.cpp:218] Iteration 18700 (0.957099 iter/s, 104.482s/100 iters), loss = 0.0757102
I0602 00:04:05.337620  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00518924 (* 1 = 0.00518924 loss)
I0602 00:04:05.337638  6142 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I0602 00:04:56.010509  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:05:49.793550  6142 solver.cpp:218] Iteration 18800 (0.957374 iter/s, 104.452s/100 iters), loss = 0.130813
I0602 00:05:49.793766  6142 solver.cpp:237]     Train net output #0: Softmax = 0.399351 (* 1 = 0.399351 loss)
I0602 00:05:49.793785  6142 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I0602 00:07:34.287982  6142 solver.cpp:218] Iteration 18900 (0.957023 iter/s, 104.491s/100 iters), loss = 0.213711
I0602 00:07:34.288141  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0260909 (* 1 = 0.0260909 loss)
I0602 00:07:34.288158  6142 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I0602 00:09:17.687963  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_19000.caffemodel
I0602 00:09:17.859884  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_19000.solverstate
I0602 00:09:17.999459  6142 solver.cpp:330] Iteration 19000, Testing net (#0)
I0602 00:09:17.999742  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:09:18.680259  6142 solver.cpp:397]     Test net output #0: acc = 0.904
I0602 00:09:19.727069  6142 solver.cpp:218] Iteration 19000 (0.948447 iter/s, 105.435s/100 iters), loss = 0.0625052
I0602 00:09:19.727133  6142 solver.cpp:237]     Train net output #0: Softmax = 0.169754 (* 1 = 0.169754 loss)
I0602 00:09:19.727149  6142 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I0602 00:10:23.527793  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:11:04.331969  6142 solver.cpp:218] Iteration 19100 (0.956009 iter/s, 104.601s/100 iters), loss = 0.0457495
I0602 00:11:04.332090  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0205986 (* 1 = 0.0205986 loss)
I0602 00:11:04.332108  6142 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I0602 00:12:48.876322  6142 solver.cpp:218] Iteration 19200 (0.956552 iter/s, 104.542s/100 iters), loss = 0.0615777
I0602 00:12:48.876482  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0381712 (* 1 = 0.0381712 loss)
I0602 00:12:48.876500  6142 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I0602 00:14:33.452865  6142 solver.cpp:218] Iteration 19300 (0.95626 iter/s, 104.574s/100 iters), loss = 0.0395154
I0602 00:14:33.453018  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0415027 (* 1 = 0.0415027 loss)
I0602 00:14:33.453037  6142 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I0602 00:15:50.322825  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:16:18.063354  6142 solver.cpp:218] Iteration 19400 (0.955951 iter/s, 104.608s/100 iters), loss = 0.0980132
I0602 00:16:18.063416  6142 solver.cpp:237]     Train net output #0: Softmax = 0.134644 (* 1 = 0.134644 loss)
I0602 00:16:18.063432  6142 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I0602 00:18:01.592142  6142 solver.cpp:330] Iteration 19500, Testing net (#0)
I0602 00:18:01.592474  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:18:02.179800  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:18:02.286044  6142 solver.cpp:397]     Test net output #0: acc = 0.9
I0602 00:18:03.308331  6142 solver.cpp:218] Iteration 19500 (0.950187 iter/s, 105.242s/100 iters), loss = 0.16582
I0602 00:18:03.308393  6142 solver.cpp:237]     Train net output #0: Softmax = 0.361706 (* 1 = 0.361706 loss)
I0602 00:18:03.308408  6142 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I0602 00:19:47.730935  6142 solver.cpp:218] Iteration 19600 (0.957672 iter/s, 104.42s/100 iters), loss = 0.0607722
I0602 00:19:47.731128  6142 solver.cpp:237]     Train net output #0: Softmax = 0.347229 (* 1 = 0.347229 loss)
I0602 00:19:47.731146  6142 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I0602 00:21:17.617774  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:21:32.234592  6142 solver.cpp:218] Iteration 19700 (0.956931 iter/s, 104.501s/100 iters), loss = 0.0806173
I0602 00:21:32.234654  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0010368 (* 1 = 0.0010368 loss)
I0602 00:21:32.234669  6142 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I0602 00:23:16.755944  6142 solver.cpp:218] Iteration 19800 (0.956768 iter/s, 104.519s/100 iters), loss = 0.0506102
I0602 00:23:16.756137  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0458704 (* 1 = 0.0458704 loss)
I0602 00:23:16.756156  6142 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I0602 00:25:01.312155  6142 solver.cpp:218] Iteration 19900 (0.95645 iter/s, 104.553s/100 iters), loss = 0.0725623
I0602 00:25:01.312263  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00675891 (* 1 = 0.00675891 loss)
I0602 00:25:01.312281  6142 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I0602 00:26:44.290261  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:26:44.818922  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_20000.caffemodel
I0602 00:26:44.987270  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_20000.solverstate
I0602 00:26:45.128015  6142 solver.cpp:330] Iteration 20000, Testing net (#0)
I0602 00:26:45.128300  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:26:45.804034  6142 solver.cpp:397]     Test net output #0: acc = 0.928
I0602 00:26:46.849617  6142 solver.cpp:218] Iteration 20000 (0.947558 iter/s, 105.534s/100 iters), loss = 0.0560023
I0602 00:26:46.849691  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00511421 (* 1 = 0.00511421 loss)
I0602 00:26:46.849707  6142 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I0602 00:28:31.362615  6142 solver.cpp:218] Iteration 20100 (0.956846 iter/s, 104.51s/100 iters), loss = 0.0941651
I0602 00:28:31.362768  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00949782 (* 1 = 0.00949782 loss)
I0602 00:28:31.362787  6142 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I0602 00:30:15.852026  6142 solver.cpp:218] Iteration 20200 (0.957062 iter/s, 104.486s/100 iters), loss = 0.0573743
I0602 00:30:15.852147  6142 solver.cpp:237]     Train net output #0: Softmax = 0.156896 (* 1 = 0.156896 loss)
I0602 00:30:15.852165  6142 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I0602 00:32:00.455410  6142 solver.cpp:218] Iteration 20300 (0.95602 iter/s, 104.6s/100 iters), loss = 0.0617606
I0602 00:32:00.455564  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00377786 (* 1 = 0.00377786 loss)
I0602 00:32:00.455583  6142 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I0602 00:32:11.951658  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:33:45.046324  6142 solver.cpp:218] Iteration 20400 (0.956134 iter/s, 104.588s/100 iters), loss = 0.135667
I0602 00:33:45.046468  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0822813 (* 1 = 0.0822813 loss)
I0602 00:33:45.046484  6142 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I0602 00:35:28.598855  6142 solver.cpp:330] Iteration 20500, Testing net (#0)
I0602 00:35:28.599189  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:35:29.276949  6142 solver.cpp:397]     Test net output #0: acc = 0.904
I0602 00:35:30.327867  6142 solver.cpp:218] Iteration 20500 (0.949863 iter/s, 105.278s/100 iters), loss = 0.0939767
I0602 00:35:30.327934  6142 solver.cpp:237]     Train net output #0: Softmax = 0.303101 (* 1 = 0.303101 loss)
I0602 00:35:30.327949  6142 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I0602 00:37:14.919327  6142 solver.cpp:218] Iteration 20600 (0.956128 iter/s, 104.588s/100 iters), loss = 0.0969527
I0602 00:37:14.919431  6142 solver.cpp:237]     Train net output #0: Softmax = 0.133102 (* 1 = 0.133102 loss)
I0602 00:37:14.919448  6142 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I0602 00:37:39.478333  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:38:59.405045  6142 solver.cpp:218] Iteration 20700 (0.957097 iter/s, 104.483s/100 iters), loss = 0.130094
I0602 00:38:59.405201  6142 solver.cpp:237]     Train net output #0: Softmax = 0.15046 (* 1 = 0.15046 loss)
I0602 00:38:59.405220  6142 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I0602 00:40:43.927786  6142 solver.cpp:218] Iteration 20800 (0.956758 iter/s, 104.52s/100 iters), loss = 0.0453501
I0602 00:40:43.927934  6142 solver.cpp:237]     Train net output #0: Softmax = 0.139368 (* 1 = 0.139368 loss)
I0602 00:40:43.927953  6142 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I0602 00:42:28.487296  6142 solver.cpp:218] Iteration 20900 (0.956421 iter/s, 104.556s/100 iters), loss = 0.0522071
I0602 00:42:28.487466  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0265832 (* 1 = 0.0265832 loss)
I0602 00:42:28.487485  6142 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I0602 00:43:06.155997  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:44:11.987076  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_21000.caffemodel
I0602 00:44:12.157022  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_21000.solverstate
I0602 00:44:12.298799  6142 solver.cpp:330] Iteration 21000, Testing net (#0)
I0602 00:44:12.299113  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:44:12.982009  6142 solver.cpp:397]     Test net output #0: acc = 0.908
I0602 00:44:14.013501  6142 solver.cpp:218] Iteration 21000 (0.94766 iter/s, 105.523s/100 iters), loss = 0.0829875
I0602 00:44:14.013572  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0108732 (* 1 = 0.0108732 loss)
I0602 00:44:14.013587  6142 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I0602 00:45:58.591591  6142 solver.cpp:218] Iteration 21100 (0.956243 iter/s, 104.576s/100 iters), loss = 0.0463145
I0602 00:45:58.591742  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000910442 (* 1 = 0.000910442 loss)
I0602 00:45:58.591759  6142 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I0602 00:47:43.145445  6142 solver.cpp:218] Iteration 21200 (0.956459 iter/s, 104.552s/100 iters), loss = 0.0561149
I0602 00:47:43.145592  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00131409 (* 1 = 0.00131409 loss)
I0602 00:47:43.145610  6142 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I0602 00:48:33.826561  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:49:27.673130  6142 solver.cpp:218] Iteration 21300 (0.956701 iter/s, 104.526s/100 iters), loss = 0.108114
I0602 00:49:27.673296  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0473026 (* 1 = 0.0473026 loss)
I0602 00:49:27.673316  6142 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I0602 00:51:12.221467  6142 solver.cpp:218] Iteration 21400 (0.956514 iter/s, 104.546s/100 iters), loss = 0.0666367
I0602 00:51:12.221626  6142 solver.cpp:237]     Train net output #0: Softmax = 0.149563 (* 1 = 0.149563 loss)
I0602 00:51:12.221643  6142 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I0602 00:52:55.762208  6142 solver.cpp:330] Iteration 21500, Testing net (#0)
I0602 00:52:55.762503  6142 net.cpp:676] Ignoring source layer Softmax
I0602 00:52:56.431690  6142 solver.cpp:397]     Test net output #0: acc = 0.9
I0602 00:52:57.477897  6142 solver.cpp:218] Iteration 21500 (0.950081 iter/s, 105.254s/100 iters), loss = 0.0786581
I0602 00:52:57.477959  6142 solver.cpp:237]     Train net output #0: Softmax = 0.180714 (* 1 = 0.180714 loss)
I0602 00:52:57.477974  6142 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I0602 00:54:01.294409  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:54:42.022998  6142 solver.cpp:218] Iteration 21600 (0.956545 iter/s, 104.543s/100 iters), loss = 0.0179158
I0602 00:54:42.023159  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0189117 (* 1 = 0.0189117 loss)
I0602 00:54:42.023177  6142 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I0602 00:56:26.570423  6142 solver.cpp:218] Iteration 21700 (0.956526 iter/s, 104.545s/100 iters), loss = 0.0370099
I0602 00:56:26.570578  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0472653 (* 1 = 0.0472653 loss)
I0602 00:56:26.570596  6142 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I0602 00:58:11.107378  6142 solver.cpp:218] Iteration 21800 (0.956623 iter/s, 104.534s/100 iters), loss = 0.0939275
I0602 00:58:11.107487  6142 solver.cpp:237]     Train net output #0: Softmax = 0.323573 (* 1 = 0.323573 loss)
I0602 00:58:11.107506  6142 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I0602 00:59:27.919752  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 00:59:55.569510  6142 solver.cpp:218] Iteration 21900 (0.957308 iter/s, 104.46s/100 iters), loss = 0.0874837
I0602 00:59:55.569574  6142 solver.cpp:237]     Train net output #0: Softmax = 0.044276 (* 1 = 0.044276 loss)
I0602 00:59:55.569589  6142 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I0602 01:01:39.124557  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_22000.caffemodel
I0602 01:01:39.297632  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_22000.solverstate
I0602 01:01:39.441784  6142 solver.cpp:330] Iteration 22000, Testing net (#0)
I0602 01:01:39.442068  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:01:40.111467  6142 solver.cpp:397]     Test net output #0: acc = 0.928
I0602 01:01:41.156154  6142 solver.cpp:218] Iteration 22000 (0.947113 iter/s, 105.584s/100 iters), loss = 0.118004
I0602 01:01:41.156219  6142 solver.cpp:237]     Train net output #0: Softmax = 0.549755 (* 1 = 0.549755 loss)
I0602 01:01:41.156234  6142 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I0602 01:03:25.643709  6142 solver.cpp:218] Iteration 22100 (0.957076 iter/s, 104.485s/100 iters), loss = 0.132807
I0602 01:03:25.643811  6142 solver.cpp:237]     Train net output #0: Softmax = 0.682112 (* 1 = 0.682112 loss)
I0602 01:03:25.643828  6142 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I0602 01:04:55.490818  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:05:10.112499  6142 solver.cpp:218] Iteration 22200 (0.957248 iter/s, 104.466s/100 iters), loss = 0.0959125
I0602 01:05:10.112563  6142 solver.cpp:237]     Train net output #0: Softmax = 0.215551 (* 1 = 0.215551 loss)
I0602 01:05:10.112578  6142 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I0602 01:06:54.548596  6142 solver.cpp:218] Iteration 22300 (0.957548 iter/s, 104.433s/100 iters), loss = 0.0943546
I0602 01:06:54.548741  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0759009 (* 1 = 0.0759009 loss)
I0602 01:06:54.548759  6142 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I0602 01:08:38.973129  6142 solver.cpp:218] Iteration 22400 (0.957655 iter/s, 104.422s/100 iters), loss = 0.0352622
I0602 01:08:38.973287  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0137409 (* 1 = 0.0137409 loss)
I0602 01:08:38.973306  6142 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I0602 01:10:21.844215  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:10:22.367697  6142 solver.cpp:330] Iteration 22500, Testing net (#0)
I0602 01:10:22.367934  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:10:23.047871  6142 solver.cpp:397]     Test net output #0: acc = 0.908
I0602 01:10:24.094542  6142 solver.cpp:218] Iteration 22500 (0.951307 iter/s, 105.119s/100 iters), loss = 0.01128
I0602 01:10:24.094614  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0190942 (* 1 = 0.0190942 loss)
I0602 01:10:24.094630  6142 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I0602 01:12:08.677414  6142 solver.cpp:218] Iteration 22600 (0.956205 iter/s, 104.58s/100 iters), loss = 0.065886
I0602 01:12:08.677563  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00500869 (* 1 = 0.00500869 loss)
I0602 01:12:08.677582  6142 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I0602 01:13:53.190819  6142 solver.cpp:218] Iteration 22700 (0.956841 iter/s, 104.511s/100 iters), loss = 0.107082
I0602 01:13:53.190974  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0231648 (* 1 = 0.0231648 loss)
I0602 01:13:53.190992  6142 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I0602 01:15:37.673867  6142 solver.cpp:218] Iteration 22800 (0.957119 iter/s, 104.48s/100 iters), loss = 0.0746442
I0602 01:15:37.674016  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00380466 (* 1 = 0.00380466 loss)
I0602 01:15:37.674034  6142 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I0602 01:15:49.185276  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:17:22.228497  6142 solver.cpp:218] Iteration 22900 (0.956464 iter/s, 104.552s/100 iters), loss = 0.123012
I0602 01:17:22.228686  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0461103 (* 1 = 0.0461103 loss)
I0602 01:17:22.228706  6142 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I0602 01:19:05.699800  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_23000.caffemodel
I0602 01:19:05.868690  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_23000.solverstate
I0602 01:19:06.012859  6142 solver.cpp:330] Iteration 23000, Testing net (#0)
I0602 01:19:06.013142  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:19:06.693905  6142 solver.cpp:397]     Test net output #0: acc = 0.868
I0602 01:19:07.750785  6142 solver.cpp:218] Iteration 23000 (0.947694 iter/s, 105.519s/100 iters), loss = 0.0692965
I0602 01:19:07.750846  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0248904 (* 1 = 0.0248904 loss)
I0602 01:19:07.750862  6142 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I0602 01:20:52.294137  6142 solver.cpp:218] Iteration 23100 (0.956557 iter/s, 104.542s/100 iters), loss = 0.0626629
I0602 01:20:52.294292  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0908005 (* 1 = 0.0908005 loss)
I0602 01:20:52.294311  6142 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I0602 01:21:16.860343  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:22:36.831956  6142 solver.cpp:218] Iteration 23200 (0.956609 iter/s, 104.536s/100 iters), loss = 0.306252
I0602 01:22:36.832120  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0548636 (* 1 = 0.0548636 loss)
I0602 01:22:36.832139  6142 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I0602 01:24:21.357169  6142 solver.cpp:218] Iteration 23300 (0.956726 iter/s, 104.523s/100 iters), loss = 0.0850003
I0602 01:24:21.357321  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0057473 (* 1 = 0.0057473 loss)
I0602 01:24:21.357338  6142 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I0602 01:26:05.912863  6142 solver.cpp:218] Iteration 23400 (0.956448 iter/s, 104.553s/100 iters), loss = 0.0646532
I0602 01:26:05.913003  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0410248 (* 1 = 0.0410248 loss)
I0602 01:26:05.913022  6142 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I0602 01:26:43.569676  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:27:49.415217  6142 solver.cpp:330] Iteration 23500, Testing net (#0)
I0602 01:27:49.415493  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:27:50.106933  6142 solver.cpp:397]     Test net output #0: acc = 0.884
I0602 01:27:51.130987  6142 solver.cpp:218] Iteration 23500 (0.950427 iter/s, 105.216s/100 iters), loss = 0.0464372
I0602 01:27:51.131045  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00219234 (* 1 = 0.00219234 loss)
I0602 01:27:51.131072  6142 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I0602 01:29:35.711192  6142 solver.cpp:218] Iteration 23600 (0.956225 iter/s, 104.578s/100 iters), loss = 0.0476606
I0602 01:29:35.711315  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0471752 (* 1 = 0.0471752 loss)
I0602 01:29:35.711333  6142 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I0602 01:31:20.276062  6142 solver.cpp:218] Iteration 23700 (0.956366 iter/s, 104.562s/100 iters), loss = 0.055193
I0602 01:31:20.276216  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00584788 (* 1 = 0.00584788 loss)
I0602 01:31:20.276233  6142 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I0602 01:32:10.981732  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:33:04.776094  6142 solver.cpp:218] Iteration 23800 (0.95696 iter/s, 104.498s/100 iters), loss = 0.0980678
I0602 01:33:04.776257  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0273356 (* 1 = 0.0273356 loss)
I0602 01:33:04.776276  6142 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I0602 01:34:49.316251  6142 solver.cpp:218] Iteration 23900 (0.956594 iter/s, 104.538s/100 iters), loss = 0.0765777
I0602 01:34:49.316399  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0431133 (* 1 = 0.0431133 loss)
I0602 01:34:49.316416  6142 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I0602 01:36:32.842492  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_24000.caffemodel
I0602 01:36:33.008610  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_24000.solverstate
I0602 01:36:33.148524  6142 solver.cpp:330] Iteration 24000, Testing net (#0)
I0602 01:36:33.148804  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:36:33.837785  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0602 01:36:34.873121  6142 solver.cpp:218] Iteration 24000 (0.94738 iter/s, 105.554s/100 iters), loss = 0.0815967
I0602 01:36:34.873184  6142 solver.cpp:237]     Train net output #0: Softmax = 0.32024 (* 1 = 0.32024 loss)
I0602 01:36:34.873200  6142 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I0602 01:37:38.670496  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:38:19.399585  6142 solver.cpp:218] Iteration 24100 (0.956718 iter/s, 104.524s/100 iters), loss = 0.0345884
I0602 01:38:19.399734  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000903423 (* 1 = 0.000903423 loss)
I0602 01:38:19.399752  6142 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I0602 01:40:03.880595  6142 solver.cpp:218] Iteration 24200 (0.957136 iter/s, 104.478s/100 iters), loss = 0.0510046
I0602 01:40:03.880710  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000997594 (* 1 = 0.000997594 loss)
I0602 01:40:03.880728  6142 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I0602 01:41:48.393152  6142 solver.cpp:218] Iteration 24300 (0.956847 iter/s, 104.51s/100 iters), loss = 0.117477
I0602 01:41:48.393347  6142 solver.cpp:237]     Train net output #0: Softmax = 0.023138 (* 1 = 0.023138 loss)
I0602 01:41:48.393366  6142 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I0602 01:43:05.262966  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:43:32.923714  6142 solver.cpp:218] Iteration 24400 (0.956683 iter/s, 104.528s/100 iters), loss = 0.0532132
I0602 01:43:32.923776  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0559965 (* 1 = 0.0559965 loss)
I0602 01:43:32.923791  6142 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I0602 01:45:16.394448  6142 solver.cpp:330] Iteration 24500, Testing net (#0)
I0602 01:45:16.394796  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:45:17.073745  6142 solver.cpp:397]     Test net output #0: acc = 0.896
I0602 01:45:18.126690  6142 solver.cpp:218] Iteration 24500 (0.950568 iter/s, 105.2s/100 iters), loss = 0.0636117
I0602 01:45:18.126754  6142 solver.cpp:237]     Train net output #0: Softmax = 0.283147 (* 1 = 0.283147 loss)
I0602 01:45:18.126770  6142 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I0602 01:47:02.577224  6142 solver.cpp:218] Iteration 24600 (0.957415 iter/s, 104.448s/100 iters), loss = 0.128632
I0602 01:47:02.577371  6142 solver.cpp:237]     Train net output #0: Softmax = 0.457175 (* 1 = 0.457175 loss)
I0602 01:47:02.577389  6142 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I0602 01:48:32.436353  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:48:47.041698  6142 solver.cpp:218] Iteration 24700 (0.957288 iter/s, 104.462s/100 iters), loss = 0.117391
I0602 01:48:47.041761  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0664087 (* 1 = 0.0664087 loss)
I0602 01:48:47.041776  6142 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I0602 01:50:31.498145  6142 solver.cpp:218] Iteration 24800 (0.957361 iter/s, 104.454s/100 iters), loss = 0.0746535
I0602 01:50:31.498255  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0630101 (* 1 = 0.0630101 loss)
I0602 01:50:31.498271  6142 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I0602 01:52:15.986608  6142 solver.cpp:218] Iteration 24900 (0.957068 iter/s, 104.486s/100 iters), loss = 0.0291132
I0602 01:52:15.986774  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00625261 (* 1 = 0.00625261 loss)
I0602 01:52:15.986793  6142 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I0602 01:53:58.895812  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 01:53:59.426049  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_25000.caffemodel
I0602 01:53:59.595391  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_25000.solverstate
I0602 01:53:59.736258  6142 solver.cpp:330] Iteration 25000, Testing net (#0)
I0602 01:53:59.736544  6142 net.cpp:676] Ignoring source layer Softmax
I0602 01:54:00.443405  6142 solver.cpp:397]     Test net output #0: acc = 0.924
I0602 01:54:01.487182  6142 solver.cpp:218] Iteration 25000 (0.947891 iter/s, 105.497s/100 iters), loss = 0.072045
I0602 01:54:01.487246  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0475416 (* 1 = 0.0475416 loss)
I0602 01:54:01.487262  6142 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I0602 01:55:46.037057  6142 solver.cpp:218] Iteration 25100 (0.956514 iter/s, 104.546s/100 iters), loss = 0.11602
I0602 01:55:46.037207  6142 solver.cpp:237]     Train net output #0: Softmax = 0.533518 (* 1 = 0.533518 loss)
I0602 01:55:46.037225  6142 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I0602 01:57:30.548600  6142 solver.cpp:218] Iteration 25200 (0.956864 iter/s, 104.508s/100 iters), loss = 0.0328059
I0602 01:57:30.548756  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00178366 (* 1 = 0.00178366 loss)
I0602 01:57:30.548774  6142 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I0602 01:59:15.039189  6142 solver.cpp:218] Iteration 25300 (0.957055 iter/s, 104.487s/100 iters), loss = 0.032018
I0602 01:59:15.039295  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00700181 (* 1 = 0.00700181 loss)
I0602 01:59:15.039312  6142 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I0602 01:59:26.520706  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:00:59.549285  6142 solver.cpp:218] Iteration 25400 (0.956876 iter/s, 104.507s/100 iters), loss = 0.0544674
I0602 02:00:59.549437  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00905204 (* 1 = 0.00905204 loss)
I0602 02:00:59.549454  6142 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I0602 02:02:43.044042  6142 solver.cpp:330] Iteration 25500, Testing net (#0)
I0602 02:02:43.044363  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:02:43.723446  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0602 02:02:44.765822  6142 solver.cpp:218] Iteration 25500 (0.95045 iter/s, 105.213s/100 iters), loss = 0.0399973
I0602 02:02:44.765888  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0214463 (* 1 = 0.0214463 loss)
I0602 02:02:44.765904  6142 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I0602 02:04:29.355504  6142 solver.cpp:218] Iteration 25600 (0.956146 iter/s, 104.587s/100 iters), loss = 0.137475
I0602 02:04:29.355659  6142 solver.cpp:237]     Train net output #0: Softmax = 0.033465 (* 1 = 0.033465 loss)
I0602 02:04:29.355677  6142 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I0602 02:04:53.899029  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:06:13.911707  6142 solver.cpp:218] Iteration 25700 (0.956452 iter/s, 104.553s/100 iters), loss = 0.126005
I0602 02:06:13.911844  6142 solver.cpp:237]     Train net output #0: Softmax = 0.390158 (* 1 = 0.390158 loss)
I0602 02:06:13.911860  6142 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I0602 02:07:58.419935  6142 solver.cpp:218] Iteration 25800 (0.956893 iter/s, 104.505s/100 iters), loss = 0.0292099
I0602 02:07:58.420085  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0319942 (* 1 = 0.0319942 loss)
I0602 02:07:58.420104  6142 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I0602 02:09:43.020906  6142 solver.cpp:218] Iteration 25900 (0.956042 iter/s, 104.598s/100 iters), loss = 0.0393877
I0602 02:09:43.021054  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00595171 (* 1 = 0.00595171 loss)
I0602 02:09:43.021071  6142 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I0602 02:10:20.647804  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:11:26.440179  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_26000.caffemodel
I0602 02:11:26.607437  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_26000.solverstate
I0602 02:11:26.747347  6142 solver.cpp:330] Iteration 26000, Testing net (#0)
I0602 02:11:26.747635  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:11:27.440003  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 02:11:28.472553  6142 solver.cpp:218] Iteration 26000 (0.948329 iter/s, 105.449s/100 iters), loss = 0.0558724
I0602 02:11:28.472635  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00465566 (* 1 = 0.00465566 loss)
I0602 02:11:28.472651  6142 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I0602 02:13:13.030419  6142 solver.cpp:218] Iteration 26100 (0.956435 iter/s, 104.555s/100 iters), loss = 0.0420375
I0602 02:13:13.030665  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0044269 (* 1 = 0.0044269 loss)
I0602 02:13:13.030684  6142 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I0602 02:14:57.541815  6142 solver.cpp:218] Iteration 26200 (0.956861 iter/s, 104.508s/100 iters), loss = 0.0818108
I0602 02:14:57.541960  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00545366 (* 1 = 0.00545366 loss)
I0602 02:14:57.541977  6142 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I0602 02:15:48.285166  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:16:42.078896  6142 solver.cpp:218] Iteration 26300 (0.956625 iter/s, 104.534s/100 iters), loss = 0.0420705
I0602 02:16:42.079145  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00941234 (* 1 = 0.00941234 loss)
I0602 02:16:42.079174  6142 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I0602 02:18:26.578029  6142 solver.cpp:218] Iteration 26400 (0.956974 iter/s, 104.496s/100 iters), loss = 0.231605
I0602 02:18:26.578178  6142 solver.cpp:237]     Train net output #0: Softmax = 0.035373 (* 1 = 0.035373 loss)
I0602 02:18:26.578197  6142 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I0602 02:20:09.994892  6142 solver.cpp:330] Iteration 26500, Testing net (#0)
I0602 02:20:09.995245  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:20:10.662458  6142 solver.cpp:397]     Test net output #0: acc = 0.896
I0602 02:20:11.715207  6142 solver.cpp:218] Iteration 26500 (0.951165 iter/s, 105.134s/100 iters), loss = 0.116583
I0602 02:20:11.715268  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0455604 (* 1 = 0.0455604 loss)
I0602 02:20:11.715284  6142 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I0602 02:21:15.496467  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:21:56.230993  6142 solver.cpp:218] Iteration 26600 (0.956819 iter/s, 104.513s/100 iters), loss = 0.0259794
I0602 02:21:56.231160  6142 solver.cpp:237]     Train net output #0: Softmax = 0.01818 (* 1 = 0.01818 loss)
I0602 02:21:56.231179  6142 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I0602 02:23:40.707921  6142 solver.cpp:218] Iteration 26700 (0.957176 iter/s, 104.474s/100 iters), loss = 0.0137454
I0602 02:23:40.708068  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00599532 (* 1 = 0.00599532 loss)
I0602 02:23:40.708086  6142 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I0602 02:25:25.174698  6142 solver.cpp:218] Iteration 26800 (0.957269 iter/s, 104.464s/100 iters), loss = 0.0112735
I0602 02:25:25.174849  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00332317 (* 1 = 0.00332317 loss)
I0602 02:25:25.174866  6142 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I0602 02:26:41.976794  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:27:09.701310  6142 solver.cpp:218] Iteration 26900 (0.95672 iter/s, 104.524s/100 iters), loss = 0.123399
I0602 02:27:09.701373  6142 solver.cpp:237]     Train net output #0: Softmax = 0.606555 (* 1 = 0.606555 loss)
I0602 02:27:09.701390  6142 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I0602 02:28:53.229297  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_27000.caffemodel
I0602 02:28:53.397925  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_27000.solverstate
I0602 02:28:53.551589  6142 solver.cpp:330] Iteration 27000, Testing net (#0)
I0602 02:28:53.551882  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:28:54.221792  6142 solver.cpp:397]     Test net output #0: acc = 0.936
I0602 02:28:55.269901  6142 solver.cpp:218] Iteration 27000 (0.947269 iter/s, 105.567s/100 iters), loss = 0.0738496
I0602 02:28:55.269963  6142 solver.cpp:237]     Train net output #0: Softmax = 0.443023 (* 1 = 0.443023 loss)
I0602 02:28:55.269979  6142 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I0602 02:30:39.843328  6142 solver.cpp:218] Iteration 27100 (0.956283 iter/s, 104.572s/100 iters), loss = 0.0281071
I0602 02:30:39.843506  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0157081 (* 1 = 0.0157081 loss)
I0602 02:30:39.843525  6142 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I0602 02:32:09.790007  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:32:24.396569  6142 solver.cpp:218] Iteration 27200 (0.95647 iter/s, 104.551s/100 iters), loss = 0.113308
I0602 02:32:24.396636  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00293892 (* 1 = 0.00293892 loss)
I0602 02:32:24.396652  6142 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I0602 02:34:08.935850  6142 solver.cpp:218] Iteration 27300 (0.956598 iter/s, 104.537s/100 iters), loss = 0.0308903
I0602 02:34:08.936005  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0688893 (* 1 = 0.0688893 loss)
I0602 02:34:08.936023  6142 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I0602 02:35:53.417685  6142 solver.cpp:218] Iteration 27400 (0.957125 iter/s, 104.48s/100 iters), loss = 0.00558225
I0602 02:35:53.417843  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00290622 (* 1 = 0.00290622 loss)
I0602 02:35:53.417861  6142 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I0602 02:37:36.386543  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:37:36.904892  6142 solver.cpp:330] Iteration 27500, Testing net (#0)
I0602 02:37:36.905133  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:37:37.586367  6142 solver.cpp:397]     Test net output #0: acc = 0.956
I0602 02:37:38.629484  6142 solver.cpp:218] Iteration 27500 (0.950485 iter/s, 105.209s/100 iters), loss = 0.011117
I0602 02:37:38.629550  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00836299 (* 1 = 0.00836299 loss)
I0602 02:37:38.629566  6142 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I0602 02:39:23.177618  6142 solver.cpp:218] Iteration 27600 (0.956518 iter/s, 104.546s/100 iters), loss = 0.0296409
I0602 02:39:23.177774  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00160858 (* 1 = 0.00160858 loss)
I0602 02:39:23.177793  6142 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I0602 02:41:07.751307  6142 solver.cpp:218] Iteration 27700 (0.956286 iter/s, 104.571s/100 iters), loss = 0.0887771
I0602 02:41:07.751425  6142 solver.cpp:237]     Train net output #0: Softmax = 0.209887 (* 1 = 0.209887 loss)
I0602 02:41:07.751441  6142 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I0602 02:42:52.304612  6142 solver.cpp:218] Iteration 27800 (0.956472 iter/s, 104.551s/100 iters), loss = 0.0986653
I0602 02:42:52.304760  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00169549 (* 1 = 0.00169549 loss)
I0602 02:42:52.304778  6142 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I0602 02:43:03.853667  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:44:36.902068  6142 solver.cpp:218] Iteration 27900 (0.95607 iter/s, 104.595s/100 iters), loss = 0.0299573
I0602 02:44:36.902217  6142 solver.cpp:237]     Train net output #0: Softmax = 0.118665 (* 1 = 0.118665 loss)
I0602 02:44:36.902235  6142 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I0602 02:46:20.418798  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_28000.caffemodel
I0602 02:46:20.587379  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_28000.solverstate
I0602 02:46:20.733258  6142 solver.cpp:330] Iteration 28000, Testing net (#0)
I0602 02:46:20.733546  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:46:21.402777  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0602 02:46:22.451223  6142 solver.cpp:218] Iteration 28000 (0.947449 iter/s, 105.547s/100 iters), loss = 0.0243872
I0602 02:46:22.451287  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0396821 (* 1 = 0.0396821 loss)
I0602 02:46:22.451303  6142 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I0602 02:48:07.024629  6142 solver.cpp:218] Iteration 28100 (0.956289 iter/s, 104.571s/100 iters), loss = 0.185169
I0602 02:48:07.024734  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00870669 (* 1 = 0.00870669 loss)
I0602 02:48:07.024751  6142 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I0602 02:48:31.615257  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:49:51.583348  6142 solver.cpp:218] Iteration 28200 (0.956424 iter/s, 104.556s/100 iters), loss = 0.078622
I0602 02:49:51.583532  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0368179 (* 1 = 0.0368179 loss)
I0602 02:49:51.583552  6142 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I0602 02:51:36.147864  6142 solver.cpp:218] Iteration 28300 (0.956372 iter/s, 104.562s/100 iters), loss = 0.0079511
I0602 02:51:36.147969  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0046218 (* 1 = 0.0046218 loss)
I0602 02:51:36.147984  6142 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I0602 02:53:20.707798  6142 solver.cpp:218] Iteration 28400 (0.956413 iter/s, 104.557s/100 iters), loss = 0.0681833
I0602 02:53:20.707948  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00596153 (* 1 = 0.00596153 loss)
I0602 02:53:20.707967  6142 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I0602 02:53:58.397753  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 02:55:04.199446  6142 solver.cpp:330] Iteration 28500, Testing net (#0)
I0602 02:55:04.199779  6142 net.cpp:676] Ignoring source layer Softmax
I0602 02:55:04.880220  6142 solver.cpp:397]     Test net output #0: acc = 0.892
I0602 02:55:05.928665  6142 solver.cpp:218] Iteration 28500 (0.950406 iter/s, 105.218s/100 iters), loss = 0.0351459
I0602 02:55:05.928726  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00271835 (* 1 = 0.00271835 loss)
I0602 02:55:05.928742  6142 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I0602 02:56:50.460870  6142 solver.cpp:218] Iteration 28600 (0.956666 iter/s, 104.53s/100 iters), loss = 0.00662848
I0602 02:56:50.460976  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00235193 (* 1 = 0.00235193 loss)
I0602 02:56:50.460994  6142 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I0602 02:58:35.014276  6142 solver.cpp:218] Iteration 28700 (0.956473 iter/s, 104.551s/100 iters), loss = 0.110332
I0602 02:58:35.014381  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00469355 (* 1 = 0.00469355 loss)
I0602 02:58:35.014398  6142 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I0602 02:59:25.726275  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:00:19.538012  6142 solver.cpp:218] Iteration 28800 (0.956744 iter/s, 104.521s/100 iters), loss = 0.0334572
I0602 03:00:19.538117  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0056783 (* 1 = 0.0056783 loss)
I0602 03:00:19.538136  6142 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I0602 03:02:04.044576  6142 solver.cpp:218] Iteration 28900 (0.956901 iter/s, 104.504s/100 iters), loss = 0.118836
I0602 03:02:04.044749  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0127925 (* 1 = 0.0127925 loss)
I0602 03:02:04.044768  6142 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I0602 03:03:47.526473  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_29000.caffemodel
I0602 03:03:47.697394  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_29000.solverstate
I0602 03:03:47.842123  6142 solver.cpp:330] Iteration 29000, Testing net (#0)
I0602 03:03:47.842411  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:03:48.537089  6142 solver.cpp:397]     Test net output #0: acc = 0.912
I0602 03:03:49.566663  6142 solver.cpp:218] Iteration 29000 (0.94769 iter/s, 105.52s/100 iters), loss = 0.0305903
I0602 03:03:49.566726  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0714736 (* 1 = 0.0714736 loss)
I0602 03:03:49.566741  6142 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I0602 03:04:53.355384  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:05:34.140686  6142 solver.cpp:218] Iteration 29100 (0.956281 iter/s, 104.572s/100 iters), loss = 0.0707473
I0602 03:05:34.140836  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00288464 (* 1 = 0.00288464 loss)
I0602 03:05:34.140853  6142 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I0602 03:07:18.662752  6142 solver.cpp:218] Iteration 29200 (0.956757 iter/s, 104.52s/100 iters), loss = 0.0135108
I0602 03:07:18.663077  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0125719 (* 1 = 0.0125719 loss)
I0602 03:07:18.663097  6142 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I0602 03:09:03.249516  6142 solver.cpp:218] Iteration 29300 (0.956167 iter/s, 104.584s/100 iters), loss = 0.0247219
I0602 03:09:03.249670  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0821553 (* 1 = 0.0821553 loss)
I0602 03:09:03.249688  6142 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I0602 03:10:20.081990  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:10:47.767585  6142 solver.cpp:218] Iteration 29400 (0.956795 iter/s, 104.516s/100 iters), loss = 0.0431285
I0602 03:10:47.767650  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0153711 (* 1 = 0.0153711 loss)
I0602 03:10:47.767665  6142 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I0602 03:12:31.256705  6142 solver.cpp:330] Iteration 29500, Testing net (#0)
I0602 03:12:31.257031  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:12:31.835883  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:12:31.935497  6142 solver.cpp:397]     Test net output #0: acc = 0.924
I0602 03:12:32.983748  6142 solver.cpp:218] Iteration 29500 (0.950446 iter/s, 105.214s/100 iters), loss = 0.188815
I0602 03:12:32.983808  6142 solver.cpp:237]     Train net output #0: Softmax = 0.824918 (* 1 = 0.824918 loss)
I0602 03:12:32.983824  6142 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I0602 03:14:17.571717  6142 solver.cpp:218] Iteration 29600 (0.956155 iter/s, 104.586s/100 iters), loss = 0.0100519
I0602 03:14:17.571875  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0397287 (* 1 = 0.0397287 loss)
I0602 03:14:17.571893  6142 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I0602 03:15:47.485795  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:16:02.138155  6142 solver.cpp:218] Iteration 29700 (0.956353 iter/s, 104.564s/100 iters), loss = 0.0438531
I0602 03:16:02.138217  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00591129 (* 1 = 0.00591129 loss)
I0602 03:16:02.138232  6142 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I0602 03:17:46.683377  6142 solver.cpp:218] Iteration 29800 (0.956546 iter/s, 104.543s/100 iters), loss = 0.113356
I0602 03:17:46.683527  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0227622 (* 1 = 0.0227622 loss)
I0602 03:17:46.683545  6142 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I0602 03:19:31.278520  6142 solver.cpp:218] Iteration 29900 (0.956091 iter/s, 104.593s/100 iters), loss = 0.0119469
I0602 03:19:31.278697  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000941936 (* 1 = 0.000941936 loss)
I0602 03:19:31.278717  6142 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I0602 03:21:14.287650  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:21:14.801160  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_30000.caffemodel
I0602 03:21:14.969792  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_30000.solverstate
I0602 03:21:15.115238  6142 solver.cpp:330] Iteration 30000, Testing net (#0)
I0602 03:21:15.115526  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:21:15.795370  6142 solver.cpp:397]     Test net output #0: acc = 0.944
I0602 03:21:16.845170  6142 solver.cpp:218] Iteration 30000 (0.947293 iter/s, 105.564s/100 iters), loss = 0.0318663
I0602 03:21:16.845232  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0228623 (* 1 = 0.0228623 loss)
I0602 03:21:16.845247  6142 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I0602 03:23:01.447554  6142 solver.cpp:218] Iteration 30100 (0.956024 iter/s, 104.6s/100 iters), loss = 0.0199112
I0602 03:23:01.447723  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00291959 (* 1 = 0.00291959 loss)
I0602 03:23:01.447742  6142 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I0602 03:24:46.037040  6142 solver.cpp:218] Iteration 30200 (0.956143 iter/s, 104.587s/100 iters), loss = 0.0380517
I0602 03:24:46.037195  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0376588 (* 1 = 0.0376588 loss)
I0602 03:24:46.037214  6142 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I0602 03:26:30.584689  6142 solver.cpp:218] Iteration 30300 (0.956526 iter/s, 104.545s/100 iters), loss = 0.0665002
I0602 03:26:30.584836  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00864297 (* 1 = 0.00864297 loss)
I0602 03:26:30.584854  6142 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I0602 03:26:42.114368  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:28:15.213913  6142 solver.cpp:218] Iteration 30400 (0.95578 iter/s, 104.627s/100 iters), loss = 0.102894
I0602 03:28:15.214041  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0883546 (* 1 = 0.0883546 loss)
I0602 03:28:15.214059  6142 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I0602 03:29:58.687063  6142 solver.cpp:330] Iteration 30500, Testing net (#0)
I0602 03:29:58.687400  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:29:59.367451  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 03:30:00.417906  6142 solver.cpp:218] Iteration 30500 (0.950558 iter/s, 105.201s/100 iters), loss = 0.0802327
I0602 03:30:00.417977  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0911424 (* 1 = 0.0911424 loss)
I0602 03:30:00.417994  6142 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I0602 03:31:45.013273  6142 solver.cpp:218] Iteration 30600 (0.956089 iter/s, 104.593s/100 iters), loss = 0.117822
I0602 03:31:45.013432  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0131841 (* 1 = 0.0131841 loss)
I0602 03:31:45.013449  6142 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I0602 03:32:09.643460  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:33:29.592814  6142 solver.cpp:218] Iteration 30700 (0.956234 iter/s, 104.577s/100 iters), loss = 0.0467184
I0602 03:33:29.592970  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00119749 (* 1 = 0.00119749 loss)
I0602 03:33:29.592988  6142 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I0602 03:35:14.082839  6142 solver.cpp:218] Iteration 30800 (0.957053 iter/s, 104.487s/100 iters), loss = 0.100584
I0602 03:35:14.082993  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00481026 (* 1 = 0.00481026 loss)
I0602 03:35:14.083011  6142 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I0602 03:36:58.585556  6142 solver.cpp:218] Iteration 30900 (0.956937 iter/s, 104.5s/100 iters), loss = 0.0452407
I0602 03:36:58.585723  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00609879 (* 1 = 0.00609879 loss)
I0602 03:36:58.585742  6142 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I0602 03:37:36.249876  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:38:42.053455  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_31000.caffemodel
I0602 03:38:42.221985  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_31000.solverstate
I0602 03:38:42.366214  6142 solver.cpp:330] Iteration 31000, Testing net (#0)
I0602 03:38:42.366495  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:38:43.060644  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0602 03:38:44.089875  6142 solver.cpp:218] Iteration 31000 (0.947852 iter/s, 105.502s/100 iters), loss = 0.0260794
I0602 03:38:44.089939  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000474834 (* 1 = 0.000474834 loss)
I0602 03:38:44.089954  6142 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I0602 03:40:28.573279  6142 solver.cpp:218] Iteration 31100 (0.957113 iter/s, 104.481s/100 iters), loss = 0.0284517
I0602 03:40:28.573444  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00355198 (* 1 = 0.00355198 loss)
I0602 03:40:28.573463  6142 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I0602 03:42:13.093680  6142 solver.cpp:218] Iteration 31200 (0.956775 iter/s, 104.518s/100 iters), loss = 0.0238762
I0602 03:42:13.093784  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000838916 (* 1 = 0.000838916 loss)
I0602 03:42:13.093801  6142 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I0602 03:43:03.747256  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:43:57.535754  6142 solver.cpp:218] Iteration 31300 (0.957492 iter/s, 104.44s/100 iters), loss = 0.0886112
I0602 03:43:57.535907  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0260476 (* 1 = 0.0260476 loss)
I0602 03:43:57.535926  6142 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I0602 03:45:42.098477  6142 solver.cpp:218] Iteration 31400 (0.956388 iter/s, 104.56s/100 iters), loss = 0.0140641
I0602 03:45:42.098628  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00155627 (* 1 = 0.00155627 loss)
I0602 03:45:42.098646  6142 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I0602 03:47:25.726657  6142 solver.cpp:330] Iteration 31500, Testing net (#0)
I0602 03:47:25.726933  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:47:26.405689  6142 solver.cpp:397]     Test net output #0: acc = 0.924
I0602 03:47:27.454048  6142 solver.cpp:218] Iteration 31500 (0.949191 iter/s, 105.353s/100 iters), loss = 0.045308
I0602 03:47:27.454113  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0039602 (* 1 = 0.0039602 loss)
I0602 03:47:27.454128  6142 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I0602 03:48:31.290406  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:49:12.093832  6142 solver.cpp:218] Iteration 31600 (0.955682 iter/s, 104.637s/100 iters), loss = 0.0280588
I0602 03:49:12.093940  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0088798 (* 1 = 0.0088798 loss)
I0602 03:49:12.093956  6142 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I0602 03:50:56.693138  6142 solver.cpp:218] Iteration 31700 (0.956053 iter/s, 104.597s/100 iters), loss = 0.0316795
I0602 03:50:56.693321  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00346998 (* 1 = 0.00346998 loss)
I0602 03:50:56.693341  6142 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I0602 03:52:41.288062  6142 solver.cpp:218] Iteration 31800 (0.956094 iter/s, 104.592s/100 iters), loss = 0.0294894
I0602 03:52:41.288216  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0128348 (* 1 = 0.0128348 loss)
I0602 03:52:41.288234  6142 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I0602 03:53:58.206300  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:54:25.904631  6142 solver.cpp:218] Iteration 31900 (0.955895 iter/s, 104.614s/100 iters), loss = 0.0602925
I0602 03:54:25.904696  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00497197 (* 1 = 0.00497197 loss)
I0602 03:54:25.904712  6142 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I0602 03:56:09.488559  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_32000.caffemodel
I0602 03:56:09.676440  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_32000.solverstate
I0602 03:56:09.824097  6142 solver.cpp:330] Iteration 32000, Testing net (#0)
I0602 03:56:09.824379  6142 net.cpp:676] Ignoring source layer Softmax
I0602 03:56:10.493943  6142 solver.cpp:397]     Test net output #0: acc = 0.92
I0602 03:56:11.545473  6142 solver.cpp:218] Iteration 32000 (0.946627 iter/s, 105.638s/100 iters), loss = 0.0455145
I0602 03:56:11.545534  6142 solver.cpp:237]     Train net output #0: Softmax = 0.241709 (* 1 = 0.241709 loss)
I0602 03:56:11.545547  6142 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0602 03:56:11.545555  6142 sgd_solver.cpp:105] Iteration 32000, lr = 0.001
I0602 03:57:56.051074  6142 solver.cpp:218] Iteration 32100 (0.95691 iter/s, 104.503s/100 iters), loss = 0.021982
I0602 03:57:56.051247  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00931882 (* 1 = 0.00931882 loss)
I0602 03:57:56.051265  6142 sgd_solver.cpp:105] Iteration 32100, lr = 0.001
I0602 03:59:25.988268  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 03:59:40.588224  6142 solver.cpp:218] Iteration 32200 (0.956622 iter/s, 104.535s/100 iters), loss = 0.0150173
I0602 03:59:40.588299  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00384683 (* 1 = 0.00384683 loss)
I0602 03:59:40.588315  6142 sgd_solver.cpp:105] Iteration 32200, lr = 0.001
I0602 04:01:25.196375  6142 solver.cpp:218] Iteration 32300 (0.955972 iter/s, 104.606s/100 iters), loss = 0.0282463
I0602 04:01:25.196532  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00622934 (* 1 = 0.00622934 loss)
I0602 04:01:25.196550  6142 sgd_solver.cpp:105] Iteration 32300, lr = 0.001
I0602 04:03:09.761634  6142 solver.cpp:218] Iteration 32400 (0.956365 iter/s, 104.563s/100 iters), loss = 0.00512655
I0602 04:03:09.761787  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000360425 (* 1 = 0.000360425 loss)
I0602 04:03:09.761804  6142 sgd_solver.cpp:105] Iteration 32400, lr = 0.001
I0602 04:04:52.776547  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:04:53.288434  6142 solver.cpp:330] Iteration 32500, Testing net (#0)
I0602 04:04:53.288679  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:04:53.975797  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 04:04:55.005270  6142 solver.cpp:218] Iteration 32500 (0.9502 iter/s, 105.241s/100 iters), loss = 0.0449256
I0602 04:04:55.005331  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00346192 (* 1 = 0.00346192 loss)
I0602 04:04:55.005345  6142 sgd_solver.cpp:105] Iteration 32500, lr = 0.001
I0602 04:06:39.603277  6142 solver.cpp:218] Iteration 32600 (0.956066 iter/s, 104.595s/100 iters), loss = 0.00462467
I0602 04:06:39.603443  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00118795 (* 1 = 0.00118795 loss)
I0602 04:06:39.603461  6142 sgd_solver.cpp:105] Iteration 32600, lr = 0.001
I0602 04:08:24.199731  6142 solver.cpp:218] Iteration 32700 (0.956079 iter/s, 104.594s/100 iters), loss = 0.0024354
I0602 04:08:24.199894  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00139843 (* 1 = 0.00139843 loss)
I0602 04:08:24.199913  6142 sgd_solver.cpp:105] Iteration 32700, lr = 0.001
I0602 04:10:08.766294  6142 solver.cpp:218] Iteration 32800 (0.956353 iter/s, 104.564s/100 iters), loss = 0.00717817
I0602 04:10:08.766446  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00024555 (* 1 = 0.00024555 loss)
I0602 04:10:08.766464  6142 sgd_solver.cpp:105] Iteration 32800, lr = 0.001
I0602 04:10:20.287425  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:11:53.324213  6142 solver.cpp:218] Iteration 32900 (0.956431 iter/s, 104.555s/100 iters), loss = 0.0187807
I0602 04:11:53.324342  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0127512 (* 1 = 0.0127512 loss)
I0602 04:11:53.324360  6142 sgd_solver.cpp:105] Iteration 32900, lr = 0.001
I0602 04:13:36.780972  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_33000.caffemodel
I0602 04:13:36.953227  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_33000.solverstate
I0602 04:13:37.100041  6142 solver.cpp:330] Iteration 33000, Testing net (#0)
I0602 04:13:37.100322  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:13:37.781980  6142 solver.cpp:397]     Test net output #0: acc = 0.928
I0602 04:13:38.808825  6142 solver.cpp:218] Iteration 33000 (0.948029 iter/s, 105.482s/100 iters), loss = 0.00245145
I0602 04:13:38.808888  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00949737 (* 1 = 0.00949737 loss)
I0602 04:13:38.808903  6142 sgd_solver.cpp:105] Iteration 33000, lr = 0.001
I0602 04:15:23.368474  6142 solver.cpp:218] Iteration 33100 (0.956415 iter/s, 104.557s/100 iters), loss = 0.0543453
I0602 04:15:23.368635  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00181648 (* 1 = 0.00181648 loss)
I0602 04:15:23.368654  6142 sgd_solver.cpp:105] Iteration 33100, lr = 0.001
I0602 04:15:47.907286  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:17:07.885324  6142 solver.cpp:218] Iteration 33200 (0.956807 iter/s, 104.514s/100 iters), loss = 0.00421513
I0602 04:17:07.885432  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00266481 (* 1 = 0.00266481 loss)
I0602 04:17:07.885449  6142 sgd_solver.cpp:105] Iteration 33200, lr = 0.001
I0602 04:18:52.456909  6142 solver.cpp:218] Iteration 33300 (0.956306 iter/s, 104.569s/100 iters), loss = 0.0136626
I0602 04:18:52.457011  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0684005 (* 1 = 0.0684005 loss)
I0602 04:18:52.457027  6142 sgd_solver.cpp:105] Iteration 33300, lr = 0.001
I0602 04:20:36.993479  6142 solver.cpp:218] Iteration 33400 (0.956626 iter/s, 104.534s/100 iters), loss = 0.00325836
I0602 04:20:36.993643  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00214538 (* 1 = 0.00214538 loss)
I0602 04:20:36.993661  6142 sgd_solver.cpp:105] Iteration 33400, lr = 0.001
I0602 04:21:14.643975  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:22:20.513090  6142 solver.cpp:330] Iteration 33500, Testing net (#0)
I0602 04:22:20.513403  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:22:21.191254  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 04:22:22.241472  6142 solver.cpp:218] Iteration 33500 (0.950161 iter/s, 105.245s/100 iters), loss = 0.0057689
I0602 04:22:22.241534  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000147675 (* 1 = 0.000147675 loss)
I0602 04:22:22.241549  6142 sgd_solver.cpp:105] Iteration 33500, lr = 0.001
I0602 04:24:06.697707  6142 solver.cpp:218] Iteration 33600 (0.957362 iter/s, 104.454s/100 iters), loss = 0.00436158
I0602 04:24:06.697850  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000266726 (* 1 = 0.000266726 loss)
I0602 04:24:06.697870  6142 sgd_solver.cpp:105] Iteration 33600, lr = 0.001
I0602 04:25:51.274945  6142 solver.cpp:218] Iteration 33700 (0.956255 iter/s, 104.575s/100 iters), loss = 0.0116439
I0602 04:25:51.276335  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000704944 (* 1 = 0.000704944 loss)
I0602 04:25:51.276355  6142 sgd_solver.cpp:105] Iteration 33700, lr = 0.001
I0602 04:26:41.997872  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:27:35.861568  6142 solver.cpp:218] Iteration 33800 (0.95618 iter/s, 104.583s/100 iters), loss = 0.00347237
I0602 04:27:35.861714  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00377681 (* 1 = 0.00377681 loss)
I0602 04:27:35.861732  6142 sgd_solver.cpp:105] Iteration 33800, lr = 0.001
I0602 04:29:20.428730  6142 solver.cpp:218] Iteration 33900 (0.956347 iter/s, 104.565s/100 iters), loss = 0.019114
I0602 04:29:20.428886  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00732291 (* 1 = 0.00732291 loss)
I0602 04:29:20.428905  6142 sgd_solver.cpp:105] Iteration 33900, lr = 0.001
I0602 04:31:03.904712  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_34000.caffemodel
I0602 04:31:04.077356  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_34000.solverstate
I0602 04:31:04.230072  6142 solver.cpp:330] Iteration 34000, Testing net (#0)
I0602 04:31:04.230355  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:31:04.900179  6142 solver.cpp:397]     Test net output #0: acc = 0.928
I0602 04:31:05.944722  6142 solver.cpp:218] Iteration 34000 (0.947747 iter/s, 105.513s/100 iters), loss = 0.0304228
I0602 04:31:05.944782  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0186139 (* 1 = 0.0186139 loss)
I0602 04:31:05.944797  6142 sgd_solver.cpp:105] Iteration 34000, lr = 0.001
I0602 04:32:09.641558  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:32:50.342902  6142 solver.cpp:218] Iteration 34100 (0.957895 iter/s, 104.396s/100 iters), loss = 0.0036965
I0602 04:32:50.343087  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00133374 (* 1 = 0.00133374 loss)
I0602 04:32:50.343107  6142 sgd_solver.cpp:105] Iteration 34100, lr = 0.001
I0602 04:34:34.884492  6142 solver.cpp:218] Iteration 34200 (0.956581 iter/s, 104.539s/100 iters), loss = 0.021553
I0602 04:34:34.884593  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00104381 (* 1 = 0.00104381 loss)
I0602 04:34:34.884609  6142 sgd_solver.cpp:105] Iteration 34200, lr = 0.001
I0602 04:36:19.458066  6142 solver.cpp:218] Iteration 34300 (0.956288 iter/s, 104.571s/100 iters), loss = 0.00453048
I0602 04:36:19.458209  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0258205 (* 1 = 0.0258205 loss)
I0602 04:36:19.458225  6142 sgd_solver.cpp:105] Iteration 34300, lr = 0.001
I0602 04:37:36.256311  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:38:03.969332  6142 solver.cpp:218] Iteration 34400 (0.956858 iter/s, 104.509s/100 iters), loss = 0.00147863
I0602 04:38:03.969410  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000461122 (* 1 = 0.000461122 loss)
I0602 04:38:03.969426  6142 sgd_solver.cpp:105] Iteration 34400, lr = 0.001
I0602 04:39:47.471509  6142 solver.cpp:330] Iteration 34500, Testing net (#0)
I0602 04:39:47.471828  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:39:48.151144  6142 solver.cpp:397]     Test net output #0: acc = 0.936
I0602 04:39:49.195451  6142 solver.cpp:218] Iteration 34500 (0.950358 iter/s, 105.224s/100 iters), loss = 0.025639
I0602 04:39:49.195515  6142 solver.cpp:237]     Train net output #0: Softmax = 0.153442 (* 1 = 0.153442 loss)
I0602 04:39:49.195530  6142 sgd_solver.cpp:105] Iteration 34500, lr = 0.001
I0602 04:41:33.730216  6142 solver.cpp:218] Iteration 34600 (0.956643 iter/s, 104.532s/100 iters), loss = 0.00285846
I0602 04:41:33.730366  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00179244 (* 1 = 0.00179244 loss)
I0602 04:41:33.730386  6142 sgd_solver.cpp:105] Iteration 34600, lr = 0.001
I0602 04:43:03.619185  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:43:18.226562  6142 solver.cpp:218] Iteration 34700 (0.956995 iter/s, 104.494s/100 iters), loss = 0.00279052
I0602 04:43:18.226622  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000170454 (* 1 = 0.000170454 loss)
I0602 04:43:18.226637  6142 sgd_solver.cpp:105] Iteration 34700, lr = 0.001
I0602 04:45:02.707470  6142 solver.cpp:218] Iteration 34800 (0.957135 iter/s, 104.478s/100 iters), loss = 0.0039553
I0602 04:45:02.707641  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00823701 (* 1 = 0.00823701 loss)
I0602 04:45:02.707659  6142 sgd_solver.cpp:105] Iteration 34800, lr = 0.001
I0602 04:46:47.114684  6142 solver.cpp:218] Iteration 34900 (0.957811 iter/s, 104.405s/100 iters), loss = 0.0086336
I0602 04:46:47.114836  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000233083 (* 1 = 0.000233083 loss)
I0602 04:46:47.114853  6142 sgd_solver.cpp:105] Iteration 34900, lr = 0.001
I0602 04:48:30.057013  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:48:30.567896  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_35000.caffemodel
I0602 04:48:30.743124  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_35000.solverstate
I0602 04:48:30.884522  6142 solver.cpp:330] Iteration 35000, Testing net (#0)
I0602 04:48:30.884809  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:48:31.556092  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 04:48:32.604612  6142 solver.cpp:218] Iteration 35000 (0.94798 iter/s, 105.487s/100 iters), loss = 0.00166118
I0602 04:48:32.604678  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00467767 (* 1 = 0.00467767 loss)
I0602 04:48:32.604693  6142 sgd_solver.cpp:105] Iteration 35000, lr = 0.001
I0602 04:50:17.058430  6142 solver.cpp:218] Iteration 35100 (0.957383 iter/s, 104.451s/100 iters), loss = 0.0028
I0602 04:50:17.058598  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000612324 (* 1 = 0.000612324 loss)
I0602 04:50:17.058619  6142 sgd_solver.cpp:105] Iteration 35100, lr = 0.001
I0602 04:52:01.508719  6142 solver.cpp:218] Iteration 35200 (0.957417 iter/s, 104.448s/100 iters), loss = 0.0144037
I0602 04:52:01.508834  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000833761 (* 1 = 0.000833761 loss)
I0602 04:52:01.508852  6142 sgd_solver.cpp:105] Iteration 35200, lr = 0.001
I0602 04:53:46.000613  6142 solver.cpp:218] Iteration 35300 (0.957035 iter/s, 104.489s/100 iters), loss = 0.001939
I0602 04:53:46.000774  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000142424 (* 1 = 0.000142424 loss)
I0602 04:53:46.000792  6142 sgd_solver.cpp:105] Iteration 35300, lr = 0.001
I0602 04:53:57.520618  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 04:55:30.546348  6142 solver.cpp:218] Iteration 35400 (0.956542 iter/s, 104.543s/100 iters), loss = 0.00165351
I0602 04:55:30.546502  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00127745 (* 1 = 0.00127745 loss)
I0602 04:55:30.546520  6142 sgd_solver.cpp:105] Iteration 35400, lr = 0.001
I0602 04:57:14.057140  6142 solver.cpp:330] Iteration 35500, Testing net (#0)
I0602 04:57:14.057462  6142 net.cpp:676] Ignoring source layer Softmax
I0602 04:57:14.736660  6142 solver.cpp:397]     Test net output #0: acc = 0.948
I0602 04:57:15.785773  6142 solver.cpp:218] Iteration 35500 (0.950237 iter/s, 105.237s/100 iters), loss = 0.00263287
I0602 04:57:15.785833  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0122027 (* 1 = 0.0122027 loss)
I0602 04:57:15.785848  6142 sgd_solver.cpp:105] Iteration 35500, lr = 0.001
I0602 04:59:00.268044  6142 solver.cpp:218] Iteration 35600 (0.957123 iter/s, 104.48s/100 iters), loss = 0.00462834
I0602 04:59:00.268174  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000896607 (* 1 = 0.000896607 loss)
I0602 04:59:00.268193  6142 sgd_solver.cpp:105] Iteration 35600, lr = 0.001
I0602 04:59:24.882369  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:00:44.829280  6142 solver.cpp:218] Iteration 35700 (0.956401 iter/s, 104.559s/100 iters), loss = 0.013852
I0602 05:00:44.829427  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00329278 (* 1 = 0.00329278 loss)
I0602 05:00:44.829443  6142 sgd_solver.cpp:105] Iteration 35700, lr = 0.001
I0602 05:02:29.339464  6142 solver.cpp:218] Iteration 35800 (0.956868 iter/s, 104.508s/100 iters), loss = 0.00121933
I0602 05:02:29.339581  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000598805 (* 1 = 0.000598805 loss)
I0602 05:02:29.339598  6142 sgd_solver.cpp:105] Iteration 35800, lr = 0.001
I0602 05:04:13.878756  6142 solver.cpp:218] Iteration 35900 (0.956602 iter/s, 104.537s/100 iters), loss = 0.00241833
I0602 05:04:13.878857  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00160808 (* 1 = 0.00160808 loss)
I0602 05:04:13.878875  6142 sgd_solver.cpp:105] Iteration 35900, lr = 0.001
I0602 05:04:51.497282  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:05:57.363647  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_36000.caffemodel
I0602 05:05:57.532361  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_36000.solverstate
I0602 05:05:57.673588  6142 solver.cpp:330] Iteration 36000, Testing net (#0)
I0602 05:05:57.673876  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:05:58.354494  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 05:05:59.405236  6142 solver.cpp:218] Iteration 36000 (0.947652 iter/s, 105.524s/100 iters), loss = 0.00108437
I0602 05:05:59.405301  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000274426 (* 1 = 0.000274426 loss)
I0602 05:05:59.405316  6142 sgd_solver.cpp:105] Iteration 36000, lr = 0.001
I0602 05:07:43.962641  6142 solver.cpp:218] Iteration 36100 (0.956435 iter/s, 104.555s/100 iters), loss = 0.00219262
I0602 05:07:43.962831  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00492217 (* 1 = 0.00492217 loss)
I0602 05:07:43.962850  6142 sgd_solver.cpp:105] Iteration 36100, lr = 0.001
I0602 05:09:28.525508  6142 solver.cpp:218] Iteration 36200 (0.956387 iter/s, 104.56s/100 iters), loss = 0.000519288
I0602 05:09:28.525663  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000604823 (* 1 = 0.000604823 loss)
I0602 05:09:28.525681  6142 sgd_solver.cpp:105] Iteration 36200, lr = 0.001
I0602 05:10:19.221665  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:11:13.051519  6142 solver.cpp:218] Iteration 36300 (0.956723 iter/s, 104.523s/100 iters), loss = 0.00189617
I0602 05:11:13.051621  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000833471 (* 1 = 0.000833471 loss)
I0602 05:11:13.051638  6142 sgd_solver.cpp:105] Iteration 36300, lr = 0.001
I0602 05:12:57.501109  6142 solver.cpp:218] Iteration 36400 (0.957423 iter/s, 104.447s/100 iters), loss = 0.00223535
I0602 05:12:57.501272  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00114915 (* 1 = 0.00114915 loss)
I0602 05:12:57.501291  6142 sgd_solver.cpp:105] Iteration 36400, lr = 0.001
I0602 05:14:40.907488  6142 solver.cpp:330] Iteration 36500, Testing net (#0)
I0602 05:14:40.907789  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:14:41.589129  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 05:14:42.624035  6142 solver.cpp:218] Iteration 36500 (0.951291 iter/s, 105.12s/100 iters), loss = 0.000902887
I0602 05:14:42.624111  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00194429 (* 1 = 0.00194429 loss)
I0602 05:14:42.624127  6142 sgd_solver.cpp:105] Iteration 36500, lr = 0.001
I0602 05:15:46.425655  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:16:27.217483  6142 solver.cpp:218] Iteration 36600 (0.956106 iter/s, 104.591s/100 iters), loss = 0.00134616
I0602 05:16:27.217630  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000810301 (* 1 = 0.000810301 loss)
I0602 05:16:27.217648  6142 sgd_solver.cpp:105] Iteration 36600, lr = 0.001
I0602 05:18:11.656630  6142 solver.cpp:218] Iteration 36700 (0.957519 iter/s, 104.437s/100 iters), loss = 0.00864386
I0602 05:18:11.656793  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0011589 (* 1 = 0.0011589 loss)
I0602 05:18:11.656810  6142 sgd_solver.cpp:105] Iteration 36700, lr = 0.001
I0602 05:19:56.106549  6142 solver.cpp:218] Iteration 36800 (0.957422 iter/s, 104.447s/100 iters), loss = 0.00410836
I0602 05:19:56.106667  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000318681 (* 1 = 0.000318681 loss)
I0602 05:19:56.106683  6142 sgd_solver.cpp:105] Iteration 36800, lr = 0.001
I0602 05:21:12.890976  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:21:40.542285  6142 solver.cpp:218] Iteration 36900 (0.957552 iter/s, 104.433s/100 iters), loss = 0.0147399
I0602 05:21:40.542345  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000661483 (* 1 = 0.000661483 loss)
I0602 05:21:40.542361  6142 sgd_solver.cpp:105] Iteration 36900, lr = 0.001
I0602 05:23:24.000286  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_37000.caffemodel
I0602 05:23:24.171862  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_37000.solverstate
I0602 05:23:24.314600  6142 solver.cpp:330] Iteration 37000, Testing net (#0)
I0602 05:23:24.314888  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:23:24.984489  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 05:23:26.032899  6142 solver.cpp:218] Iteration 37000 (0.947976 iter/s, 105.488s/100 iters), loss = 0.0509485
I0602 05:23:26.032971  6142 solver.cpp:237]     Train net output #0: Softmax = 0.297346 (* 1 = 0.297346 loss)
I0602 05:23:26.032987  6142 sgd_solver.cpp:105] Iteration 37000, lr = 0.001
I0602 05:25:10.603621  6142 solver.cpp:218] Iteration 37100 (0.956315 iter/s, 104.568s/100 iters), loss = 0.00254732
I0602 05:25:10.603821  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00396638 (* 1 = 0.00396638 loss)
I0602 05:25:10.603839  6142 sgd_solver.cpp:105] Iteration 37100, lr = 0.001
I0602 05:26:40.485636  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:26:55.086985  6142 solver.cpp:218] Iteration 37200 (0.957115 iter/s, 104.481s/100 iters), loss = 0.000730994
I0602 05:26:55.087072  6142 solver.cpp:237]     Train net output #0: Softmax = 9.42043e-05 (* 1 = 9.42043e-05 loss)
I0602 05:26:55.087090  6142 sgd_solver.cpp:105] Iteration 37200, lr = 0.001
I0602 05:28:39.571884  6142 solver.cpp:218] Iteration 37300 (0.9571 iter/s, 104.482s/100 iters), loss = 0.00342706
I0602 05:28:39.572012  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00292102 (* 1 = 0.00292102 loss)
I0602 05:28:39.572031  6142 sgd_solver.cpp:105] Iteration 37300, lr = 0.001
I0602 05:30:24.080708  6142 solver.cpp:218] Iteration 37400 (0.956881 iter/s, 104.506s/100 iters), loss = 0.000667386
I0602 05:30:24.080941  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000178609 (* 1 = 0.000178609 loss)
I0602 05:30:24.080969  6142 sgd_solver.cpp:105] Iteration 37400, lr = 0.001
I0602 05:32:07.107210  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:32:07.614686  6142 solver.cpp:330] Iteration 37500, Testing net (#0)
I0602 05:32:07.614922  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:32:08.306053  6142 solver.cpp:397]     Test net output #0: acc = 0.956
I0602 05:32:09.334805  6142 solver.cpp:218] Iteration 37500 (0.950107 iter/s, 105.251s/100 iters), loss = 0.00432439
I0602 05:32:09.334868  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00292745 (* 1 = 0.00292745 loss)
I0602 05:32:09.334884  6142 sgd_solver.cpp:105] Iteration 37500, lr = 0.001
I0602 05:33:53.924922  6142 solver.cpp:218] Iteration 37600 (0.956137 iter/s, 104.588s/100 iters), loss = 0.00311944
I0602 05:33:53.925081  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000652259 (* 1 = 0.000652259 loss)
I0602 05:33:53.925098  6142 sgd_solver.cpp:105] Iteration 37600, lr = 0.001
I0602 05:35:38.520726  6142 solver.cpp:218] Iteration 37700 (0.956086 iter/s, 104.593s/100 iters), loss = 0.000682523
I0602 05:35:38.520876  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0012735 (* 1 = 0.0012735 loss)
I0602 05:35:38.520895  6142 sgd_solver.cpp:105] Iteration 37700, lr = 0.001
I0602 05:37:23.104072  6142 solver.cpp:218] Iteration 37800 (0.956199 iter/s, 104.581s/100 iters), loss = 0.00288995
I0602 05:37:23.104221  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00045859 (* 1 = 0.00045859 loss)
I0602 05:37:23.104239  6142 sgd_solver.cpp:105] Iteration 37800, lr = 0.001
I0602 05:37:34.634047  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:39:07.685171  6142 solver.cpp:218] Iteration 37900 (0.95622 iter/s, 104.578s/100 iters), loss = 0.00363411
I0602 05:39:07.685277  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000393811 (* 1 = 0.000393811 loss)
I0602 05:39:07.685295  6142 sgd_solver.cpp:105] Iteration 37900, lr = 0.001
I0602 05:40:51.218292  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_38000.caffemodel
I0602 05:40:51.386799  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_38000.solverstate
I0602 05:40:51.537588  6142 solver.cpp:330] Iteration 38000, Testing net (#0)
I0602 05:40:51.537871  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:40:52.219316  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 05:40:53.252652  6142 solver.cpp:218] Iteration 38000 (0.947285 iter/s, 105.565s/100 iters), loss = 0.00176328
I0602 05:40:53.252713  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00772946 (* 1 = 0.00772946 loss)
I0602 05:40:53.252728  6142 sgd_solver.cpp:105] Iteration 38000, lr = 0.001
I0602 05:42:37.880494  6142 solver.cpp:218] Iteration 38100 (0.955792 iter/s, 104.625s/100 iters), loss = 0.0257696
I0602 05:42:37.880694  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00150728 (* 1 = 0.00150728 loss)
I0602 05:42:37.880712  6142 sgd_solver.cpp:105] Iteration 38100, lr = 0.001
I0602 05:43:02.483625  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:44:22.487118  6142 solver.cpp:218] Iteration 38200 (0.955987 iter/s, 104.604s/100 iters), loss = 0.0268498
I0602 05:44:22.487277  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00034366 (* 1 = 0.00034366 loss)
I0602 05:44:22.487294  6142 sgd_solver.cpp:105] Iteration 38200, lr = 0.001
I0602 05:46:07.115975  6142 solver.cpp:218] Iteration 38300 (0.955784 iter/s, 104.626s/100 iters), loss = 0.00126355
I0602 05:46:07.116127  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000816843 (* 1 = 0.000816843 loss)
I0602 05:46:07.116144  6142 sgd_solver.cpp:105] Iteration 38300, lr = 0.001
I0602 05:47:51.695912  6142 solver.cpp:218] Iteration 38400 (0.95623 iter/s, 104.577s/100 iters), loss = 0.00120001
I0602 05:47:51.696063  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00130776 (* 1 = 0.00130776 loss)
I0602 05:47:51.696082  6142 sgd_solver.cpp:105] Iteration 38400, lr = 0.001
I0602 05:48:29.368314  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:49:35.275192  6142 solver.cpp:330] Iteration 38500, Testing net (#0)
I0602 05:49:35.275513  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:49:35.944190  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 05:49:36.990330  6142 solver.cpp:218] Iteration 38500 (0.949742 iter/s, 105.292s/100 iters), loss = 0.000533769
I0602 05:49:36.990392  6142 solver.cpp:237]     Train net output #0: Softmax = 7.63366e-05 (* 1 = 7.63366e-05 loss)
I0602 05:49:36.990406  6142 sgd_solver.cpp:105] Iteration 38500, lr = 0.001
I0602 05:51:21.571822  6142 solver.cpp:218] Iteration 38600 (0.956215 iter/s, 104.579s/100 iters), loss = 0.00897662
I0602 05:51:21.571975  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000257028 (* 1 = 0.000257028 loss)
I0602 05:51:21.571993  6142 sgd_solver.cpp:105] Iteration 38600, lr = 0.001
I0602 05:53:06.140697  6142 solver.cpp:218] Iteration 38700 (0.956331 iter/s, 104.566s/100 iters), loss = 0.00343054
I0602 05:53:06.140853  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000221865 (* 1 = 0.000221865 loss)
I0602 05:53:06.140872  6142 sgd_solver.cpp:105] Iteration 38700, lr = 0.001
I0602 05:53:56.786926  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 05:54:50.586241  6142 solver.cpp:218] Iteration 38800 (0.95746 iter/s, 104.443s/100 iters), loss = 0.000881064
I0602 05:54:50.586401  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00111678 (* 1 = 0.00111678 loss)
I0602 05:54:50.586421  6142 sgd_solver.cpp:105] Iteration 38800, lr = 0.001
I0602 05:56:35.073760  6142 solver.cpp:218] Iteration 38900 (0.957075 iter/s, 104.485s/100 iters), loss = 0.0204711
I0602 05:56:35.073923  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00164275 (* 1 = 0.00164275 loss)
I0602 05:56:35.073941  6142 sgd_solver.cpp:105] Iteration 38900, lr = 0.001
I0602 05:58:18.518824  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_39000.caffemodel
I0602 05:58:18.696693  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_39000.solverstate
I0602 05:58:18.848474  6142 solver.cpp:330] Iteration 39000, Testing net (#0)
I0602 05:58:18.848757  6142 net.cpp:676] Ignoring source layer Softmax
I0602 05:58:19.518112  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 05:58:20.565167  6142 solver.cpp:218] Iteration 39000 (0.947968 iter/s, 105.489s/100 iters), loss = 0.000805908
I0602 05:58:20.565232  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000719524 (* 1 = 0.000719524 loss)
I0602 05:58:20.565246  6142 sgd_solver.cpp:105] Iteration 39000, lr = 0.001
I0602 05:59:24.308809  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:00:05.076018  6142 solver.cpp:218] Iteration 39100 (0.956861 iter/s, 104.508s/100 iters), loss = 0.00118471
I0602 06:00:05.076158  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000816953 (* 1 = 0.000816953 loss)
I0602 06:00:05.076175  6142 sgd_solver.cpp:105] Iteration 39100, lr = 0.001
I0602 06:01:49.647163  6142 solver.cpp:218] Iteration 39200 (0.95631 iter/s, 104.569s/100 iters), loss = 0.00178752
I0602 06:01:49.647310  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000772721 (* 1 = 0.000772721 loss)
I0602 06:01:49.647327  6142 sgd_solver.cpp:105] Iteration 39200, lr = 0.001
I0602 06:03:34.158466  6142 solver.cpp:218] Iteration 39300 (0.956858 iter/s, 104.509s/100 iters), loss = 0.0022352
I0602 06:03:34.158619  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00026988 (* 1 = 0.00026988 loss)
I0602 06:03:34.158637  6142 sgd_solver.cpp:105] Iteration 39300, lr = 0.001
I0602 06:04:50.997990  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:05:18.695211  6142 solver.cpp:218] Iteration 39400 (0.956625 iter/s, 104.534s/100 iters), loss = 0.000757199
I0602 06:05:18.695276  6142 solver.cpp:237]     Train net output #0: Softmax = 9.37893e-05 (* 1 = 9.37893e-05 loss)
I0602 06:05:18.695291  6142 sgd_solver.cpp:105] Iteration 39400, lr = 0.001
I0602 06:07:02.196899  6142 solver.cpp:330] Iteration 39500, Testing net (#0)
I0602 06:07:02.197232  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:07:02.781953  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:07:02.888658  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 06:07:03.915696  6142 solver.cpp:218] Iteration 39500 (0.950408 iter/s, 105.218s/100 iters), loss = 0.0151664
I0602 06:07:03.915760  6142 solver.cpp:237]     Train net output #0: Softmax = 0.114569 (* 1 = 0.114569 loss)
I0602 06:07:03.915774  6142 sgd_solver.cpp:105] Iteration 39500, lr = 0.001
I0602 06:08:48.466547  6142 solver.cpp:218] Iteration 39600 (0.956495 iter/s, 104.548s/100 iters), loss = 0.000997168
I0602 06:08:48.466723  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00172544 (* 1 = 0.00172544 loss)
I0602 06:08:48.466742  6142 sgd_solver.cpp:105] Iteration 39600, lr = 0.001
I0602 06:10:18.458930  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:10:33.112493  6142 solver.cpp:218] Iteration 39700 (0.955627 iter/s, 104.643s/100 iters), loss = 0.00210845
I0602 06:10:33.112552  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000286031 (* 1 = 0.000286031 loss)
I0602 06:10:33.112571  6142 sgd_solver.cpp:105] Iteration 39700, lr = 0.001
I0602 06:12:17.670719  6142 solver.cpp:218] Iteration 39800 (0.956428 iter/s, 104.556s/100 iters), loss = 0.000727873
I0602 06:12:17.670895  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000995891 (* 1 = 0.000995891 loss)
I0602 06:12:17.670913  6142 sgd_solver.cpp:105] Iteration 39800, lr = 0.001
I0602 06:14:02.243618  6142 solver.cpp:218] Iteration 39900 (0.956295 iter/s, 104.57s/100 iters), loss = 0.00062443
I0602 06:14:02.243777  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000243653 (* 1 = 0.000243653 loss)
I0602 06:14:02.243795  6142 sgd_solver.cpp:105] Iteration 39900, lr = 0.001
I0602 06:15:45.184407  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:15:45.722054  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_40000.caffemodel
I0602 06:15:45.889715  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_40000.solverstate
I0602 06:15:46.030828  6142 solver.cpp:330] Iteration 40000, Testing net (#0)
I0602 06:15:46.031145  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:15:46.711520  6142 solver.cpp:397]     Test net output #0: acc = 0.972
I0602 06:15:47.760421  6142 solver.cpp:218] Iteration 40000 (0.94774 iter/s, 105.514s/100 iters), loss = 0.00133492
I0602 06:15:47.760484  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00402042 (* 1 = 0.00402042 loss)
I0602 06:15:47.760500  6142 sgd_solver.cpp:105] Iteration 40000, lr = 0.001
I0602 06:17:32.259541  6142 solver.cpp:218] Iteration 40100 (0.956969 iter/s, 104.497s/100 iters), loss = 0.00314195
I0602 06:17:32.259745  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000850875 (* 1 = 0.000850875 loss)
I0602 06:17:32.259764  6142 sgd_solver.cpp:105] Iteration 40100, lr = 0.001
I0602 06:19:16.824765  6142 solver.cpp:218] Iteration 40200 (0.956366 iter/s, 104.563s/100 iters), loss = 0.00044011
I0602 06:19:16.824923  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000357576 (* 1 = 0.000357576 loss)
I0602 06:19:16.824941  6142 sgd_solver.cpp:105] Iteration 40200, lr = 0.001
I0602 06:21:01.355389  6142 solver.cpp:218] Iteration 40300 (0.956681 iter/s, 104.528s/100 iters), loss = 0.00217526
I0602 06:21:01.355522  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000121233 (* 1 = 0.000121233 loss)
I0602 06:21:01.355540  6142 sgd_solver.cpp:105] Iteration 40300, lr = 0.001
I0602 06:21:12.870044  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:22:45.867317  6142 solver.cpp:218] Iteration 40400 (0.956853 iter/s, 104.509s/100 iters), loss = 0.00459663
I0602 06:22:45.867439  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000238878 (* 1 = 0.000238878 loss)
I0602 06:22:45.867457  6142 sgd_solver.cpp:105] Iteration 40400, lr = 0.001
I0602 06:24:29.304697  6142 solver.cpp:330] Iteration 40500, Testing net (#0)
I0602 06:24:29.304980  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:24:29.998412  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 06:24:31.023932  6142 solver.cpp:218] Iteration 40500 (0.950986 iter/s, 105.154s/100 iters), loss = 0.00566929
I0602 06:24:31.023995  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0044352 (* 1 = 0.0044352 loss)
I0602 06:24:31.024014  6142 sgd_solver.cpp:105] Iteration 40500, lr = 0.001
I0602 06:26:15.532287  6142 solver.cpp:218] Iteration 40600 (0.956885 iter/s, 104.506s/100 iters), loss = 0.00400578
I0602 06:26:15.532436  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000323895 (* 1 = 0.000323895 loss)
I0602 06:26:15.532454  6142 sgd_solver.cpp:105] Iteration 40600, lr = 0.001
I0602 06:26:40.091006  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:28:00.049177  6142 solver.cpp:218] Iteration 40700 (0.956808 iter/s, 104.514s/100 iters), loss = 0.00316198
I0602 06:28:00.049332  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0119474 (* 1 = 0.0119474 loss)
I0602 06:28:00.049350  6142 sgd_solver.cpp:105] Iteration 40700, lr = 0.001
I0602 06:29:44.597985  6142 solver.cpp:218] Iteration 40800 (0.956516 iter/s, 104.546s/100 iters), loss = 0.00171759
I0602 06:29:44.598152  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000496076 (* 1 = 0.000496076 loss)
I0602 06:29:44.598170  6142 sgd_solver.cpp:105] Iteration 40800, lr = 0.001
I0602 06:31:29.170692  6142 solver.cpp:218] Iteration 40900 (0.956297 iter/s, 104.57s/100 iters), loss = 0.0021629
I0602 06:31:29.170841  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000764925 (* 1 = 0.000764925 loss)
I0602 06:31:29.170859  6142 sgd_solver.cpp:105] Iteration 40900, lr = 0.001
I0602 06:32:06.784961  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:33:12.612352  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_41000.caffemodel
I0602 06:33:12.783447  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_41000.solverstate
I0602 06:33:12.926482  6142 solver.cpp:330] Iteration 41000, Testing net (#0)
I0602 06:33:12.926766  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:33:13.615769  6142 solver.cpp:397]     Test net output #0: acc = 0.976
I0602 06:33:14.654206  6142 solver.cpp:218] Iteration 41000 (0.94804 iter/s, 105.481s/100 iters), loss = 0.00161693
I0602 06:33:14.654271  6142 solver.cpp:237]     Train net output #0: Softmax = 7.23489e-05 (* 1 = 7.23489e-05 loss)
I0602 06:33:14.654286  6142 sgd_solver.cpp:105] Iteration 41000, lr = 0.001
I0602 06:34:59.145162  6142 solver.cpp:218] Iteration 41100 (0.957045 iter/s, 104.488s/100 iters), loss = 0.00148879
I0602 06:34:59.145368  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00165681 (* 1 = 0.00165681 loss)
I0602 06:34:59.145387  6142 sgd_solver.cpp:105] Iteration 41100, lr = 0.001
I0602 06:36:43.628581  6142 solver.cpp:218] Iteration 41200 (0.957115 iter/s, 104.481s/100 iters), loss = 0.000882732
I0602 06:36:43.628746  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000497065 (* 1 = 0.000497065 loss)
I0602 06:36:43.628764  6142 sgd_solver.cpp:105] Iteration 41200, lr = 0.001
I0602 06:37:34.268762  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:38:28.153434  6142 solver.cpp:218] Iteration 41300 (0.956735 iter/s, 104.522s/100 iters), loss = 0.00711193
I0602 06:38:28.153537  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00100088 (* 1 = 0.00100088 loss)
I0602 06:38:28.153553  6142 sgd_solver.cpp:105] Iteration 41300, lr = 0.001
I0602 06:40:12.701885  6142 solver.cpp:218] Iteration 41400 (0.956518 iter/s, 104.546s/100 iters), loss = 0.00145003
I0602 06:40:12.702044  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000167963 (* 1 = 0.000167963 loss)
I0602 06:40:12.702064  6142 sgd_solver.cpp:105] Iteration 41400, lr = 0.001
I0602 06:41:56.298195  6142 solver.cpp:330] Iteration 41500, Testing net (#0)
I0602 06:41:56.298527  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:41:56.967897  6142 solver.cpp:397]     Test net output #0: acc = 0.972
I0602 06:41:58.017298  6142 solver.cpp:218] Iteration 41500 (0.949553 iter/s, 105.313s/100 iters), loss = 0.000589187
I0602 06:41:58.017362  6142 solver.cpp:237]     Train net output #0: Softmax = 9.40177e-05 (* 1 = 9.40177e-05 loss)
I0602 06:41:58.017377  6142 sgd_solver.cpp:105] Iteration 41500, lr = 0.001
I0602 06:43:01.806499  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:43:42.578761  6142 solver.cpp:218] Iteration 41600 (0.956399 iter/s, 104.559s/100 iters), loss = 0.000828383
I0602 06:43:42.578922  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000126084 (* 1 = 0.000126084 loss)
I0602 06:43:42.578941  6142 sgd_solver.cpp:105] Iteration 41600, lr = 0.001
I0602 06:45:27.159358  6142 solver.cpp:218] Iteration 41700 (0.956225 iter/s, 104.578s/100 iters), loss = 0.00112707
I0602 06:45:27.159519  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000618112 (* 1 = 0.000618112 loss)
I0602 06:45:27.159538  6142 sgd_solver.cpp:105] Iteration 41700, lr = 0.001
I0602 06:47:11.726156  6142 solver.cpp:218] Iteration 41800 (0.956351 iter/s, 104.564s/100 iters), loss = 0.00150103
I0602 06:47:11.726316  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00645763 (* 1 = 0.00645763 loss)
I0602 06:47:11.726336  6142 sgd_solver.cpp:105] Iteration 41800, lr = 0.001
I0602 06:48:28.538892  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:48:56.201560  6142 solver.cpp:218] Iteration 41900 (0.957188 iter/s, 104.473s/100 iters), loss = 0.001195
I0602 06:48:56.201623  6142 solver.cpp:237]     Train net output #0: Softmax = 3.82374e-05 (* 1 = 3.82374e-05 loss)
I0602 06:48:56.201638  6142 sgd_solver.cpp:105] Iteration 41900, lr = 0.001
I0602 06:50:39.674486  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_42000.caffemodel
I0602 06:50:39.845978  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_42000.solverstate
I0602 06:50:39.998935  6142 solver.cpp:330] Iteration 42000, Testing net (#0)
I0602 06:50:39.999254  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:50:40.668808  6142 solver.cpp:397]     Test net output #0: acc = 0.972
I0602 06:50:41.709494  6142 solver.cpp:218] Iteration 42000 (0.94782 iter/s, 105.505s/100 iters), loss = 0.0102538
I0602 06:50:41.709558  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0774843 (* 1 = 0.0774843 loss)
I0602 06:50:41.709573  6142 sgd_solver.cpp:105] Iteration 42000, lr = 0.001
I0602 06:52:26.169315  6142 solver.cpp:218] Iteration 42100 (0.95733 iter/s, 104.457s/100 iters), loss = 0.000519244
I0602 06:52:26.171357  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00215633 (* 1 = 0.00215633 loss)
I0602 06:52:26.171377  6142 sgd_solver.cpp:105] Iteration 42100, lr = 0.001
I0602 06:53:56.024192  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:54:10.636456  6142 solver.cpp:218] Iteration 42200 (0.957281 iter/s, 104.463s/100 iters), loss = 0.000801931
I0602 06:54:10.636523  6142 solver.cpp:237]     Train net output #0: Softmax = 4.67615e-05 (* 1 = 4.67615e-05 loss)
I0602 06:54:10.636538  6142 sgd_solver.cpp:105] Iteration 42200, lr = 0.001
I0602 06:55:55.141973  6142 solver.cpp:218] Iteration 42300 (0.956911 iter/s, 104.503s/100 iters), loss = 0.00511272
I0602 06:55:55.142125  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0345504 (* 1 = 0.0345504 loss)
I0602 06:55:55.142143  6142 sgd_solver.cpp:105] Iteration 42300, lr = 0.001
I0602 06:57:39.696790  6142 solver.cpp:218] Iteration 42400 (0.956461 iter/s, 104.552s/100 iters), loss = 0.000373665
I0602 06:57:39.696939  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000185794 (* 1 = 0.000185794 loss)
I0602 06:57:39.696957  6142 sgd_solver.cpp:105] Iteration 42400, lr = 0.001
I0602 06:59:22.726155  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 06:59:23.247153  6142 solver.cpp:330] Iteration 42500, Testing net (#0)
I0602 06:59:23.247388  6142 net.cpp:676] Ignoring source layer Softmax
I0602 06:59:23.926879  6142 solver.cpp:397]     Test net output #0: acc = 0.948
I0602 06:59:24.972435  6142 solver.cpp:218] Iteration 42500 (0.949912 iter/s, 105.273s/100 iters), loss = 0.00116717
I0602 06:59:24.972496  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00271637 (* 1 = 0.00271637 loss)
I0602 06:59:24.972512  6142 sgd_solver.cpp:105] Iteration 42500, lr = 0.001
I0602 07:01:09.443487  6142 solver.cpp:218] Iteration 42600 (0.957227 iter/s, 104.468s/100 iters), loss = 0.00560685
I0602 07:01:09.443653  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000142053 (* 1 = 0.000142053 loss)
I0602 07:01:09.443672  6142 sgd_solver.cpp:105] Iteration 42600, lr = 0.001
I0602 07:02:54.046145  6142 solver.cpp:218] Iteration 42700 (0.956024 iter/s, 104.6s/100 iters), loss = 0.0002817
I0602 07:02:54.046298  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000816945 (* 1 = 0.000816945 loss)
I0602 07:02:54.046315  6142 sgd_solver.cpp:105] Iteration 42700, lr = 0.001
I0602 07:04:38.669144  6142 solver.cpp:218] Iteration 42800 (0.955837 iter/s, 104.62s/100 iters), loss = 0.000514161
I0602 07:04:38.669311  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000152666 (* 1 = 0.000152666 loss)
I0602 07:04:38.669328  6142 sgd_solver.cpp:105] Iteration 42800, lr = 0.001
I0602 07:04:50.182512  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:06:23.257691  6142 solver.cpp:218] Iteration 42900 (0.956153 iter/s, 104.586s/100 iters), loss = 0.00189231
I0602 07:06:23.257844  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000222824 (* 1 = 0.000222824 loss)
I0602 07:06:23.257861  6142 sgd_solver.cpp:105] Iteration 42900, lr = 0.001
I0602 07:08:06.839375  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_43000.caffemodel
I0602 07:08:07.009698  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_43000.solverstate
I0602 07:08:07.156558  6142 solver.cpp:330] Iteration 43000, Testing net (#0)
I0602 07:08:07.156843  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:08:07.826376  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 07:08:08.875299  6142 solver.cpp:218] Iteration 43000 (0.946836 iter/s, 105.615s/100 iters), loss = 0.000486808
I0602 07:08:08.875365  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000542287 (* 1 = 0.000542287 loss)
I0602 07:08:08.875380  6142 sgd_solver.cpp:105] Iteration 43000, lr = 0.001
I0602 07:09:53.393381  6142 solver.cpp:218] Iteration 43100 (0.956796 iter/s, 104.515s/100 iters), loss = 0.00153054
I0602 07:09:53.393579  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000376437 (* 1 = 0.000376437 loss)
I0602 07:09:53.393597  6142 sgd_solver.cpp:105] Iteration 43100, lr = 0.001
I0602 07:10:18.001948  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:11:37.952672  6142 solver.cpp:218] Iteration 43200 (0.95642 iter/s, 104.557s/100 iters), loss = 0.00104601
I0602 07:11:37.952828  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000641457 (* 1 = 0.000641457 loss)
I0602 07:11:37.952847  6142 sgd_solver.cpp:105] Iteration 43200, lr = 0.001
I0602 07:13:22.527958  6142 solver.cpp:218] Iteration 43300 (0.956274 iter/s, 104.573s/100 iters), loss = 0.00100802
I0602 07:13:22.528113  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000847627 (* 1 = 0.000847627 loss)
I0602 07:13:22.528131  6142 sgd_solver.cpp:105] Iteration 43300, lr = 0.001
I0602 07:15:07.075906  6142 solver.cpp:218] Iteration 43400 (0.956524 iter/s, 104.545s/100 iters), loss = 0.000412209
I0602 07:15:07.076062  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000543442 (* 1 = 0.000543442 loss)
I0602 07:15:07.076081  6142 sgd_solver.cpp:105] Iteration 43400, lr = 0.001
I0602 07:15:44.702308  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:16:50.551625  6142 solver.cpp:330] Iteration 43500, Testing net (#0)
I0602 07:16:50.551919  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:16:51.243345  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 07:16:52.277181  6142 solver.cpp:218] Iteration 43500 (0.950583 iter/s, 105.199s/100 iters), loss = 0.000676859
I0602 07:16:52.277263  6142 solver.cpp:237]     Train net output #0: Softmax = 6.5755e-05 (* 1 = 6.5755e-05 loss)
I0602 07:16:52.277279  6142 sgd_solver.cpp:105] Iteration 43500, lr = 0.001
I0602 07:18:36.805187  6142 solver.cpp:218] Iteration 43600 (0.956706 iter/s, 104.525s/100 iters), loss = 0.00173825
I0602 07:18:36.805294  6142 solver.cpp:237]     Train net output #0: Softmax = 4.53605e-05 (* 1 = 4.53605e-05 loss)
I0602 07:18:36.805310  6142 sgd_solver.cpp:105] Iteration 43600, lr = 0.001
I0602 07:20:21.320387  6142 solver.cpp:218] Iteration 43700 (0.956823 iter/s, 104.513s/100 iters), loss = 0.000443046
I0602 07:20:21.320539  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000127168 (* 1 = 0.000127168 loss)
I0602 07:20:21.320556  6142 sgd_solver.cpp:105] Iteration 43700, lr = 0.001
I0602 07:21:12.042194  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:22:05.839821  6142 solver.cpp:218] Iteration 43800 (0.956785 iter/s, 104.517s/100 iters), loss = 0.000823069
I0602 07:22:05.839975  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0009705 (* 1 = 0.0009705 loss)
I0602 07:22:05.839993  6142 sgd_solver.cpp:105] Iteration 43800, lr = 0.001
I0602 07:23:50.316308  6142 solver.cpp:218] Iteration 43900 (0.957178 iter/s, 104.474s/100 iters), loss = 0.00301229
I0602 07:23:50.316459  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00100875 (* 1 = 0.00100875 loss)
I0602 07:23:50.316478  6142 sgd_solver.cpp:105] Iteration 43900, lr = 0.001
I0602 07:25:33.758934  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_44000.caffemodel
I0602 07:25:33.930896  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_44000.solverstate
I0602 07:25:34.072135  6142 solver.cpp:330] Iteration 44000, Testing net (#0)
I0602 07:25:34.072420  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:25:34.755867  6142 solver.cpp:397]     Test net output #0: acc = 0.944
I0602 07:25:35.799643  6142 solver.cpp:218] Iteration 44000 (0.948041 iter/s, 105.481s/100 iters), loss = 0.000714211
I0602 07:25:35.799708  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00022033 (* 1 = 0.00022033 loss)
I0602 07:25:35.799723  6142 sgd_solver.cpp:105] Iteration 44000, lr = 0.001
I0602 07:26:39.623814  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:27:20.409790  6142 solver.cpp:218] Iteration 44100 (0.955954 iter/s, 104.608s/100 iters), loss = 0.000616491
I0602 07:27:20.409916  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000127014 (* 1 = 0.000127014 loss)
I0602 07:27:20.409934  6142 sgd_solver.cpp:105] Iteration 44100, lr = 0.001
I0602 07:29:04.976857  6142 solver.cpp:218] Iteration 44200 (0.956349 iter/s, 104.564s/100 iters), loss = 0.000764743
I0602 07:29:04.977010  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000586179 (* 1 = 0.000586179 loss)
I0602 07:29:04.977027  6142 sgd_solver.cpp:105] Iteration 44200, lr = 0.001
I0602 07:30:49.575088  6142 solver.cpp:218] Iteration 44300 (0.956064 iter/s, 104.596s/100 iters), loss = 0.00282209
I0602 07:30:49.575245  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000891494 (* 1 = 0.000891494 loss)
I0602 07:30:49.575263  6142 sgd_solver.cpp:105] Iteration 44300, lr = 0.001
I0602 07:32:06.453764  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:32:34.156328  6142 solver.cpp:218] Iteration 44400 (0.956219 iter/s, 104.579s/100 iters), loss = 0.00347734
I0602 07:32:34.156392  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000387956 (* 1 = 0.000387956 loss)
I0602 07:32:34.156407  6142 sgd_solver.cpp:105] Iteration 44400, lr = 0.001
I0602 07:34:17.678020  6142 solver.cpp:330] Iteration 44500, Testing net (#0)
I0602 07:34:17.678346  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:34:18.356652  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 07:34:19.407649  6142 solver.cpp:218] Iteration 44500 (0.950131 iter/s, 105.249s/100 iters), loss = 0.00885939
I0602 07:34:19.407708  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0660116 (* 1 = 0.0660116 loss)
I0602 07:34:19.407723  6142 sgd_solver.cpp:105] Iteration 44500, lr = 0.001
I0602 07:36:04.035645  6142 solver.cpp:218] Iteration 44600 (0.95579 iter/s, 104.625s/100 iters), loss = 0.0015682
I0602 07:36:04.035822  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00853697 (* 1 = 0.00853697 loss)
I0602 07:36:04.035842  6142 sgd_solver.cpp:105] Iteration 44600, lr = 0.001
I0602 07:37:33.930728  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:37:48.548354  6142 solver.cpp:218] Iteration 44700 (0.956846 iter/s, 104.51s/100 iters), loss = 0.0017467
I0602 07:37:48.548418  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000446041 (* 1 = 0.000446041 loss)
I0602 07:37:48.548434  6142 sgd_solver.cpp:105] Iteration 44700, lr = 0.001
I0602 07:39:33.077095  6142 solver.cpp:218] Iteration 44800 (0.956698 iter/s, 104.526s/100 iters), loss = 0.000587814
I0602 07:39:33.077241  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00131986 (* 1 = 0.00131986 loss)
I0602 07:39:33.077260  6142 sgd_solver.cpp:105] Iteration 44800, lr = 0.001
I0602 07:41:17.672735  6142 solver.cpp:218] Iteration 44900 (0.956087 iter/s, 104.593s/100 iters), loss = 0.000255205
I0602 07:41:17.672842  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000150598 (* 1 = 0.000150598 loss)
I0602 07:41:17.672857  6142 sgd_solver.cpp:105] Iteration 44900, lr = 0.001
I0602 07:43:00.645135  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:43:01.169402  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_45000.caffemodel
I0602 07:43:01.345245  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_45000.solverstate
I0602 07:43:01.486966  6142 solver.cpp:330] Iteration 45000, Testing net (#0)
I0602 07:43:01.487301  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:43:02.167238  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 07:43:03.215037  6142 solver.cpp:218] Iteration 45000 (0.947511 iter/s, 105.54s/100 iters), loss = 0.000903386
I0602 07:43:03.215106  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0027941 (* 1 = 0.0027941 loss)
I0602 07:43:03.215121  6142 sgd_solver.cpp:105] Iteration 45000, lr = 0.001
I0602 07:44:47.713325  6142 solver.cpp:218] Iteration 45100 (0.956977 iter/s, 104.496s/100 iters), loss = 0.00292584
I0602 07:44:47.713493  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000730306 (* 1 = 0.000730306 loss)
I0602 07:44:47.713512  6142 sgd_solver.cpp:105] Iteration 45100, lr = 0.001
I0602 07:46:32.271445  6142 solver.cpp:218] Iteration 45200 (0.956431 iter/s, 104.555s/100 iters), loss = 0.000460567
I0602 07:46:32.271606  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000326306 (* 1 = 0.000326306 loss)
I0602 07:46:32.271625  6142 sgd_solver.cpp:105] Iteration 45200, lr = 0.001
I0602 07:48:16.820631  6142 solver.cpp:218] Iteration 45300 (0.956512 iter/s, 104.547s/100 iters), loss = 0.000486659
I0602 07:48:16.820787  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00011391 (* 1 = 0.00011391 loss)
I0602 07:48:16.820806  6142 sgd_solver.cpp:105] Iteration 45300, lr = 0.001
I0602 07:48:28.342590  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:50:01.326841  6142 solver.cpp:218] Iteration 45400 (0.956905 iter/s, 104.504s/100 iters), loss = 0.000465114
I0602 07:50:01.327004  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000706265 (* 1 = 0.000706265 loss)
I0602 07:50:01.327023  6142 sgd_solver.cpp:105] Iteration 45400, lr = 0.001
I0602 07:51:44.818848  6142 solver.cpp:330] Iteration 45500, Testing net (#0)
I0602 07:51:44.819197  6142 net.cpp:676] Ignoring source layer Softmax
I0602 07:51:45.499732  6142 solver.cpp:397]     Test net output #0: acc = 0.948
I0602 07:51:46.541018  6142 solver.cpp:218] Iteration 45500 (0.950467 iter/s, 105.211s/100 iters), loss = 0.00034909
I0602 07:51:46.541083  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000634696 (* 1 = 0.000634696 loss)
I0602 07:51:46.541098  6142 sgd_solver.cpp:105] Iteration 45500, lr = 0.001
I0602 07:53:31.086555  6142 solver.cpp:218] Iteration 45600 (0.956545 iter/s, 104.543s/100 iters), loss = 0.00139608
I0602 07:53:31.086707  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00027741 (* 1 = 0.00027741 loss)
I0602 07:53:31.086725  6142 sgd_solver.cpp:105] Iteration 45600, lr = 0.001
I0602 07:53:55.623929  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 07:55:15.622047  6142 solver.cpp:218] Iteration 45700 (0.956637 iter/s, 104.533s/100 iters), loss = 0.00190829
I0602 07:55:15.622200  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000215841 (* 1 = 0.000215841 loss)
I0602 07:55:15.622217  6142 sgd_solver.cpp:105] Iteration 45700, lr = 0.001
I0602 07:57:00.149121  6142 solver.cpp:218] Iteration 45800 (0.956714 iter/s, 104.524s/100 iters), loss = 0.00180568
I0602 07:57:00.149299  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0019337 (* 1 = 0.0019337 loss)
I0602 07:57:00.149318  6142 sgd_solver.cpp:105] Iteration 45800, lr = 0.001
I0602 07:58:44.677876  6142 solver.cpp:218] Iteration 45900 (0.9567 iter/s, 104.526s/100 iters), loss = 0.000464951
I0602 07:58:44.678031  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000684374 (* 1 = 0.000684374 loss)
I0602 07:58:44.678050  6142 sgd_solver.cpp:105] Iteration 45900, lr = 0.001
I0602 07:59:22.349319  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:00:28.158295  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_46000.caffemodel
I0602 08:00:28.329068  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_46000.solverstate
I0602 08:00:28.471596  6142 solver.cpp:330] Iteration 46000, Testing net (#0)
I0602 08:00:28.471880  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:00:29.150677  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 08:00:30.195184  6142 solver.cpp:218] Iteration 46000 (0.947736 iter/s, 105.515s/100 iters), loss = 0.000768361
I0602 08:00:30.195248  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000157539 (* 1 = 0.000157539 loss)
I0602 08:00:30.195263  6142 sgd_solver.cpp:105] Iteration 46000, lr = 0.001
I0602 08:02:14.837682  6142 solver.cpp:218] Iteration 46100 (0.955659 iter/s, 104.64s/100 iters), loss = 0.0032635
I0602 08:02:14.837877  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000420716 (* 1 = 0.000420716 loss)
I0602 08:02:14.837896  6142 sgd_solver.cpp:105] Iteration 46100, lr = 0.001
I0602 08:03:59.419045  6142 solver.cpp:218] Iteration 46200 (0.956218 iter/s, 104.579s/100 iters), loss = 0.000434711
I0602 08:03:59.419272  6142 solver.cpp:237]     Train net output #0: Softmax = 6.98707e-05 (* 1 = 6.98707e-05 loss)
I0602 08:03:59.419299  6142 sgd_solver.cpp:105] Iteration 46200, lr = 0.001
I0602 08:04:50.179312  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:05:44.045238  6142 solver.cpp:218] Iteration 46300 (0.955809 iter/s, 104.623s/100 iters), loss = 0.000873742
I0602 08:05:44.045388  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0015798 (* 1 = 0.0015798 loss)
I0602 08:05:44.045406  6142 sgd_solver.cpp:105] Iteration 46300, lr = 0.001
I0602 08:07:28.634080  6142 solver.cpp:218] Iteration 46400 (0.95615 iter/s, 104.586s/100 iters), loss = 0.000799857
I0602 08:07:28.634230  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000128745 (* 1 = 0.000128745 loss)
I0602 08:07:28.634248  6142 sgd_solver.cpp:105] Iteration 46400, lr = 0.001
I0602 08:09:12.205699  6142 solver.cpp:330] Iteration 46500, Testing net (#0)
I0602 08:09:12.206013  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:09:12.886029  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 08:09:13.925318  6142 solver.cpp:218] Iteration 46500 (0.949771 iter/s, 105.289s/100 iters), loss = 0.000352363
I0602 08:09:13.925392  6142 solver.cpp:237]     Train net output #0: Softmax = 8.6962e-05 (* 1 = 8.6962e-05 loss)
I0602 08:09:13.925410  6142 sgd_solver.cpp:105] Iteration 46500, lr = 0.001
I0602 08:10:17.746940  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:10:58.511878  6142 solver.cpp:218] Iteration 46600 (0.956172 iter/s, 104.584s/100 iters), loss = 0.00054697
I0602 08:10:58.512029  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000159825 (* 1 = 0.000159825 loss)
I0602 08:10:58.512048  6142 sgd_solver.cpp:105] Iteration 46600, lr = 0.001
I0602 08:12:43.106015  6142 solver.cpp:218] Iteration 46700 (0.956103 iter/s, 104.591s/100 iters), loss = 0.000773658
I0602 08:12:43.106164  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000723761 (* 1 = 0.000723761 loss)
I0602 08:12:43.106181  6142 sgd_solver.cpp:105] Iteration 46700, lr = 0.001
I0602 08:14:27.704562  6142 solver.cpp:218] Iteration 46800 (0.956064 iter/s, 104.596s/100 iters), loss = 0.000871296
I0602 08:14:27.704715  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000748649 (* 1 = 0.000748649 loss)
I0602 08:14:27.704732  6142 sgd_solver.cpp:105] Iteration 46800, lr = 0.001
I0602 08:15:44.524134  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:16:12.247673  6142 solver.cpp:218] Iteration 46900 (0.956569 iter/s, 104.54s/100 iters), loss = 0.00197336
I0602 08:16:12.247735  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00137785 (* 1 = 0.00137785 loss)
I0602 08:16:12.247750  6142 sgd_solver.cpp:105] Iteration 46900, lr = 0.001
I0602 08:17:55.710841  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_47000.caffemodel
I0602 08:17:55.878345  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_47000.solverstate
I0602 08:17:56.027818  6142 solver.cpp:330] Iteration 47000, Testing net (#0)
I0602 08:17:56.028091  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:17:56.708317  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 08:17:57.746659  6142 solver.cpp:218] Iteration 47000 (0.947901 iter/s, 105.496s/100 iters), loss = 0.0147806
I0602 08:17:57.746722  6142 solver.cpp:237]     Train net output #0: Softmax = 0.102049 (* 1 = 0.102049 loss)
I0602 08:17:57.746739  6142 sgd_solver.cpp:105] Iteration 47000, lr = 0.001
I0602 08:19:42.317229  6142 solver.cpp:218] Iteration 47100 (0.956317 iter/s, 104.568s/100 iters), loss = 0.000312365
I0602 08:19:42.317435  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000386865 (* 1 = 0.000386865 loss)
I0602 08:19:42.317454  6142 sgd_solver.cpp:105] Iteration 47100, lr = 0.001
I0602 08:21:12.348119  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:21:26.918547  6142 solver.cpp:218] Iteration 47200 (0.956037 iter/s, 104.598s/100 iters), loss = 0.000940764
I0602 08:21:26.918615  6142 solver.cpp:237]     Train net output #0: Softmax = 5.57712e-05 (* 1 = 5.57712e-05 loss)
I0602 08:21:26.918630  6142 sgd_solver.cpp:105] Iteration 47200, lr = 0.001
I0602 08:23:11.559038  6142 solver.cpp:218] Iteration 47300 (0.955677 iter/s, 104.638s/100 iters), loss = 0.000557777
I0602 08:23:11.559195  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000897814 (* 1 = 0.000897814 loss)
I0602 08:23:11.559211  6142 sgd_solver.cpp:105] Iteration 47300, lr = 0.001
I0602 08:24:56.167784  6142 solver.cpp:218] Iteration 47400 (0.955968 iter/s, 104.606s/100 iters), loss = 0.00132478
I0602 08:24:56.167949  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000135908 (* 1 = 0.000135908 loss)
I0602 08:24:56.167968  6142 sgd_solver.cpp:105] Iteration 47400, lr = 0.001
I0602 08:26:39.203234  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:26:39.711566  6142 solver.cpp:330] Iteration 47500, Testing net (#0)
I0602 08:26:39.711804  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:26:40.404379  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 08:26:41.434526  6142 solver.cpp:218] Iteration 47500 (0.949993 iter/s, 105.264s/100 iters), loss = 0.00159453
I0602 08:26:41.434587  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00371114 (* 1 = 0.00371114 loss)
I0602 08:26:41.434604  6142 sgd_solver.cpp:105] Iteration 47500, lr = 0.001
I0602 08:28:25.999521  6142 solver.cpp:218] Iteration 47600 (0.956367 iter/s, 104.562s/100 iters), loss = 0.00102318
I0602 08:28:25.999688  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000248857 (* 1 = 0.000248857 loss)
I0602 08:28:25.999706  6142 sgd_solver.cpp:105] Iteration 47600, lr = 0.001
I0602 08:30:10.525446  6142 solver.cpp:218] Iteration 47700 (0.956726 iter/s, 104.523s/100 iters), loss = 0.000232164
I0602 08:30:10.525593  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000560087 (* 1 = 0.000560087 loss)
I0602 08:30:10.525610  6142 sgd_solver.cpp:105] Iteration 47700, lr = 0.001
I0602 08:31:55.084327  6142 solver.cpp:218] Iteration 47800 (0.956424 iter/s, 104.556s/100 iters), loss = 0.000476492
I0602 08:31:55.084475  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000101578 (* 1 = 0.000101578 loss)
I0602 08:31:55.084493  6142 sgd_solver.cpp:105] Iteration 47800, lr = 0.001
I0602 08:32:06.621258  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:33:39.687939  6142 solver.cpp:218] Iteration 47900 (0.956015 iter/s, 104.601s/100 iters), loss = 0.00105243
I0602 08:33:39.688043  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000557549 (* 1 = 0.000557549 loss)
I0602 08:33:39.688060  6142 sgd_solver.cpp:105] Iteration 47900, lr = 0.001
I0602 08:35:23.163103  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_48000.caffemodel
I0602 08:35:23.334342  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_48000.solverstate
I0602 08:35:23.476167  6142 solver.cpp:330] Iteration 48000, Testing net (#0)
I0602 08:35:23.476446  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:35:24.158717  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 08:35:25.203877  6142 solver.cpp:218] Iteration 48000 (0.947748 iter/s, 105.513s/100 iters), loss = 0.000804023
I0602 08:35:25.203943  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00395858 (* 1 = 0.00395858 loss)
I0602 08:35:25.203955  6142 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0602 08:35:25.203963  6142 sgd_solver.cpp:105] Iteration 48000, lr = 0.0001
I0602 08:37:09.765061  6142 solver.cpp:218] Iteration 48100 (0.956402 iter/s, 104.559s/100 iters), loss = 0.0021789
I0602 08:37:09.765219  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000533069 (* 1 = 0.000533069 loss)
I0602 08:37:09.765239  6142 sgd_solver.cpp:105] Iteration 48100, lr = 0.0001
I0602 08:37:34.353190  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:38:54.307008  6142 solver.cpp:218] Iteration 48200 (0.956579 iter/s, 104.539s/100 iters), loss = 0.00101903
I0602 08:38:54.307178  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000218778 (* 1 = 0.000218778 loss)
I0602 08:38:54.307195  6142 sgd_solver.cpp:105] Iteration 48200, lr = 0.0001
I0602 08:40:38.908834  6142 solver.cpp:218] Iteration 48300 (0.956031 iter/s, 104.599s/100 iters), loss = 0.00088351
I0602 08:40:38.908991  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000288938 (* 1 = 0.000288938 loss)
I0602 08:40:38.909009  6142 sgd_solver.cpp:105] Iteration 48300, lr = 0.0001
I0602 08:42:23.448537  6142 solver.cpp:218] Iteration 48400 (0.956599 iter/s, 104.537s/100 iters), loss = 0.000832869
I0602 08:42:23.448688  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000732306 (* 1 = 0.000732306 loss)
I0602 08:42:23.448705  6142 sgd_solver.cpp:105] Iteration 48400, lr = 0.0001
I0602 08:43:01.157678  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:44:07.003156  6142 solver.cpp:330] Iteration 48500, Testing net (#0)
I0602 08:44:07.003475  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:44:07.682366  6142 solver.cpp:397]     Test net output #0: acc = 0.944
I0602 08:44:08.730525  6142 solver.cpp:218] Iteration 48500 (0.949854 iter/s, 105.279s/100 iters), loss = 0.000615939
I0602 08:44:08.730587  6142 solver.cpp:237]     Train net output #0: Softmax = 6.34898e-05 (* 1 = 6.34898e-05 loss)
I0602 08:44:08.730602  6142 sgd_solver.cpp:105] Iteration 48500, lr = 0.0001
I0602 08:45:53.187499  6142 solver.cpp:218] Iteration 48600 (0.957355 iter/s, 104.454s/100 iters), loss = 0.000725425
I0602 08:45:53.187696  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000226845 (* 1 = 0.000226845 loss)
I0602 08:45:53.187716  6142 sgd_solver.cpp:105] Iteration 48600, lr = 0.0001
I0602 08:47:37.691313  6142 solver.cpp:218] Iteration 48700 (0.956928 iter/s, 104.501s/100 iters), loss = 0.000318201
I0602 08:47:37.691416  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000221709 (* 1 = 0.000221709 loss)
I0602 08:47:37.691433  6142 sgd_solver.cpp:105] Iteration 48700, lr = 0.0001
I0602 08:48:28.434286  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:49:22.231067  6142 solver.cpp:218] Iteration 48800 (0.956598 iter/s, 104.537s/100 iters), loss = 0.000819875
I0602 08:49:22.231194  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00188057 (* 1 = 0.00188057 loss)
I0602 08:49:22.231211  6142 sgd_solver.cpp:105] Iteration 48800, lr = 0.0001
I0602 08:51:06.745288  6142 solver.cpp:218] Iteration 48900 (0.956832 iter/s, 104.512s/100 iters), loss = 0.00173298
I0602 08:51:06.745438  6142 solver.cpp:237]     Train net output #0: Softmax = 6.47936e-05 (* 1 = 6.47936e-05 loss)
I0602 08:51:06.745457  6142 sgd_solver.cpp:105] Iteration 48900, lr = 0.0001
I0602 08:52:50.225394  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_49000.caffemodel
I0602 08:52:50.395742  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_49000.solverstate
I0602 08:52:50.537973  6142 solver.cpp:330] Iteration 49000, Testing net (#0)
I0602 08:52:50.538256  6142 net.cpp:676] Ignoring source layer Softmax
I0602 08:52:51.230779  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 08:52:52.258589  6142 solver.cpp:218] Iteration 49000 (0.947772 iter/s, 105.511s/100 iters), loss = 0.000395049
I0602 08:52:52.258651  6142 solver.cpp:237]     Train net output #0: Softmax = 5.15006e-05 (* 1 = 5.15006e-05 loss)
I0602 08:52:52.258667  6142 sgd_solver.cpp:105] Iteration 49000, lr = 0.0001
I0602 08:53:56.105741  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:54:36.904507  6142 solver.cpp:218] Iteration 49100 (0.955629 iter/s, 104.643s/100 iters), loss = 0.000599458
I0602 08:54:36.904660  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0001394 (* 1 = 0.0001394 loss)
I0602 08:54:36.904678  6142 sgd_solver.cpp:105] Iteration 49100, lr = 0.0001
I0602 08:56:21.435525  6142 solver.cpp:218] Iteration 49200 (0.956679 iter/s, 104.528s/100 iters), loss = 0.000603674
I0602 08:56:21.435669  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000598875 (* 1 = 0.000598875 loss)
I0602 08:56:21.435688  6142 sgd_solver.cpp:105] Iteration 49200, lr = 0.0001
I0602 08:58:05.918766  6142 solver.cpp:218] Iteration 49300 (0.957116 iter/s, 104.481s/100 iters), loss = 0.00105344
I0602 08:58:05.918922  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000183105 (* 1 = 0.000183105 loss)
I0602 08:58:05.918941  6142 sgd_solver.cpp:105] Iteration 49300, lr = 0.0001
I0602 08:59:22.725035  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 08:59:50.400291  6142 solver.cpp:218] Iteration 49400 (0.957132 iter/s, 104.479s/100 iters), loss = 0.00693649
I0602 08:59:50.400357  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000104566 (* 1 = 0.000104566 loss)
I0602 08:59:50.400373  6142 sgd_solver.cpp:105] Iteration 49400, lr = 0.0001
I0602 09:01:33.853147  6142 solver.cpp:330] Iteration 49500, Testing net (#0)
I0602 09:01:33.853452  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:01:34.421382  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:01:34.521297  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 09:01:35.570616  6142 solver.cpp:218] Iteration 49500 (0.950862 iter/s, 105.168s/100 iters), loss = 0.0101915
I0602 09:01:35.570679  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0722642 (* 1 = 0.0722642 loss)
I0602 09:01:35.570694  6142 sgd_solver.cpp:105] Iteration 49500, lr = 0.0001
I0602 09:03:20.069442  6142 solver.cpp:218] Iteration 49600 (0.956972 iter/s, 104.496s/100 iters), loss = 0.00116142
I0602 09:03:20.069597  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00108824 (* 1 = 0.00108824 loss)
I0602 09:03:20.069615  6142 sgd_solver.cpp:105] Iteration 49600, lr = 0.0001
I0602 09:04:49.885423  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:05:04.508983  6142 solver.cpp:218] Iteration 49700 (0.957516 iter/s, 104.437s/100 iters), loss = 0.00068084
I0602 09:05:04.509052  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000339286 (* 1 = 0.000339286 loss)
I0602 09:05:04.509066  6142 sgd_solver.cpp:105] Iteration 49700, lr = 0.0001
I0602 09:06:48.936575  6142 solver.cpp:218] Iteration 49800 (0.957626 iter/s, 104.425s/100 iters), loss = 0.000744128
I0602 09:06:48.936728  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000765071 (* 1 = 0.000765071 loss)
I0602 09:06:48.936746  6142 sgd_solver.cpp:105] Iteration 49800, lr = 0.0001
I0602 09:08:33.457865  6142 solver.cpp:218] Iteration 49900 (0.956768 iter/s, 104.519s/100 iters), loss = 0.000328584
I0602 09:08:33.457974  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000192339 (* 1 = 0.000192339 loss)
I0602 09:08:33.457991  6142 sgd_solver.cpp:105] Iteration 49900, lr = 0.0001
I0602 09:10:16.429855  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:10:16.936125  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_50000.caffemodel
I0602 09:10:17.105620  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_50000.solverstate
I0602 09:10:17.255728  6142 solver.cpp:330] Iteration 50000, Testing net (#0)
I0602 09:10:17.256065  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:10:17.935705  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 09:10:18.974903  6142 solver.cpp:218] Iteration 50000 (0.947739 iter/s, 105.514s/100 iters), loss = 0.000903046
I0602 09:10:18.974980  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00271579 (* 1 = 0.00271579 loss)
I0602 09:10:18.974997  6142 sgd_solver.cpp:105] Iteration 50000, lr = 0.0001
I0602 09:12:03.533565  6142 solver.cpp:218] Iteration 50100 (0.956425 iter/s, 104.556s/100 iters), loss = 0.000819732
I0602 09:12:03.533756  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000138633 (* 1 = 0.000138633 loss)
I0602 09:12:03.533774  6142 sgd_solver.cpp:105] Iteration 50100, lr = 0.0001
I0602 09:13:48.096266  6142 solver.cpp:218] Iteration 50200 (0.956389 iter/s, 104.56s/100 iters), loss = 0.000336373
I0602 09:13:48.096417  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000515632 (* 1 = 0.000515632 loss)
I0602 09:13:48.096434  6142 sgd_solver.cpp:105] Iteration 50200, lr = 0.0001
I0602 09:15:32.632153  6142 solver.cpp:218] Iteration 50300 (0.956634 iter/s, 104.533s/100 iters), loss = 0.00049042
I0602 09:15:32.632284  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000104621 (* 1 = 0.000104621 loss)
I0602 09:15:32.632302  6142 sgd_solver.cpp:105] Iteration 50300, lr = 0.0001
I0602 09:15:44.147714  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:17:17.144538  6142 solver.cpp:218] Iteration 50400 (0.956849 iter/s, 104.51s/100 iters), loss = 0.000678041
I0602 09:17:17.144690  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00186274 (* 1 = 0.00186274 loss)
I0602 09:17:17.144708  6142 sgd_solver.cpp:105] Iteration 50400, lr = 0.0001
I0602 09:19:00.649451  6142 solver.cpp:330] Iteration 50500, Testing net (#0)
I0602 09:19:00.649741  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:19:01.332064  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 09:19:02.378183  6142 solver.cpp:218] Iteration 50500 (0.95029 iter/s, 105.231s/100 iters), loss = 0.000469418
I0602 09:19:02.378245  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000490644 (* 1 = 0.000490644 loss)
I0602 09:19:02.378260  6142 sgd_solver.cpp:105] Iteration 50500, lr = 0.0001
I0602 09:20:46.948585  6142 solver.cpp:218] Iteration 50600 (0.956316 iter/s, 104.568s/100 iters), loss = 0.00179983
I0602 09:20:46.948750  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000455651 (* 1 = 0.000455651 loss)
I0602 09:20:46.948768  6142 sgd_solver.cpp:105] Iteration 50600, lr = 0.0001
I0602 09:21:11.551971  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:22:31.466922  6142 solver.cpp:218] Iteration 50700 (0.956794 iter/s, 104.516s/100 iters), loss = 0.00249395
I0602 09:22:31.467092  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000196421 (* 1 = 0.000196421 loss)
I0602 09:22:31.467111  6142 sgd_solver.cpp:105] Iteration 50700, lr = 0.0001
I0602 09:24:15.986050  6142 solver.cpp:218] Iteration 50800 (0.956787 iter/s, 104.517s/100 iters), loss = 0.00116348
I0602 09:24:15.986193  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00243119 (* 1 = 0.00243119 loss)
I0602 09:24:15.986212  6142 sgd_solver.cpp:105] Iteration 50800, lr = 0.0001
I0602 09:26:00.515223  6142 solver.cpp:218] Iteration 50900 (0.956695 iter/s, 104.527s/100 iters), loss = 0.00152546
I0602 09:26:00.515357  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000670207 (* 1 = 0.000670207 loss)
I0602 09:26:00.515374  6142 sgd_solver.cpp:105] Iteration 50900, lr = 0.0001
I0602 09:26:38.162178  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:27:43.994730  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_51000.caffemodel
I0602 09:27:44.168390  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_51000.solverstate
I0602 09:27:44.310498  6142 solver.cpp:330] Iteration 51000, Testing net (#0)
I0602 09:27:44.310781  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:27:44.990998  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 09:27:46.044277  6142 solver.cpp:218] Iteration 51000 (0.94763 iter/s, 105.526s/100 iters), loss = 0.000396789
I0602 09:27:46.044337  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00013391 (* 1 = 0.00013391 loss)
I0602 09:27:46.044351  6142 sgd_solver.cpp:105] Iteration 51000, lr = 0.0001
I0602 09:29:30.555634  6142 solver.cpp:218] Iteration 51100 (0.956857 iter/s, 104.509s/100 iters), loss = 0.00092737
I0602 09:29:30.555845  6142 solver.cpp:237]     Train net output #0: Softmax = 5.74319e-05 (* 1 = 5.74319e-05 loss)
I0602 09:29:30.555864  6142 sgd_solver.cpp:105] Iteration 51100, lr = 0.0001
I0602 09:31:15.154059  6142 solver.cpp:218] Iteration 51200 (0.956062 iter/s, 104.596s/100 iters), loss = 0.00036959
I0602 09:31:15.154255  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000137941 (* 1 = 0.000137941 loss)
I0602 09:31:15.154279  6142 sgd_solver.cpp:105] Iteration 51200, lr = 0.0001
I0602 09:32:05.910020  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:32:59.702450  6142 solver.cpp:218] Iteration 51300 (0.95652 iter/s, 104.546s/100 iters), loss = 0.00188425
I0602 09:32:59.702606  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00144845 (* 1 = 0.00144845 loss)
I0602 09:32:59.702625  6142 sgd_solver.cpp:105] Iteration 51300, lr = 0.0001
I0602 09:34:44.279366  6142 solver.cpp:218] Iteration 51400 (0.956258 iter/s, 104.574s/100 iters), loss = 0.000836629
I0602 09:34:44.279511  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000281252 (* 1 = 0.000281252 loss)
I0602 09:34:44.279531  6142 sgd_solver.cpp:105] Iteration 51400, lr = 0.0001
I0602 09:36:27.812636  6142 solver.cpp:330] Iteration 51500, Testing net (#0)
I0602 09:36:27.812968  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:36:28.505237  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 09:36:29.537228  6142 solver.cpp:218] Iteration 51500 (0.950072 iter/s, 105.255s/100 iters), loss = 0.000740383
I0602 09:36:29.537289  6142 solver.cpp:237]     Train net output #0: Softmax = 7.15973e-05 (* 1 = 7.15973e-05 loss)
I0602 09:36:29.537305  6142 sgd_solver.cpp:105] Iteration 51500, lr = 0.0001
I0602 09:37:33.376497  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:38:14.151006  6142 solver.cpp:218] Iteration 51600 (0.955921 iter/s, 104.611s/100 iters), loss = 0.000523959
I0602 09:38:14.151160  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000251263 (* 1 = 0.000251263 loss)
I0602 09:38:14.151178  6142 sgd_solver.cpp:105] Iteration 51600, lr = 0.0001
I0602 09:39:58.695726  6142 solver.cpp:218] Iteration 51700 (0.956553 iter/s, 104.542s/100 iters), loss = 0.0160532
I0602 09:39:58.695833  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000739729 (* 1 = 0.000739729 loss)
I0602 09:39:58.695852  6142 sgd_solver.cpp:105] Iteration 51700, lr = 0.0001
I0602 09:41:43.239140  6142 solver.cpp:218] Iteration 51800 (0.956564 iter/s, 104.541s/100 iters), loss = 0.000547834
I0602 09:41:43.239240  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000218326 (* 1 = 0.000218326 loss)
I0602 09:41:43.239256  6142 sgd_solver.cpp:105] Iteration 51800, lr = 0.0001
I0602 09:43:00.102591  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:43:27.836123  6142 solver.cpp:218] Iteration 51900 (0.956074 iter/s, 104.594s/100 iters), loss = 0.000796552
I0602 09:43:27.836187  6142 solver.cpp:237]     Train net output #0: Softmax = 7.47476e-05 (* 1 = 7.47476e-05 loss)
I0602 09:43:27.836203  6142 sgd_solver.cpp:105] Iteration 51900, lr = 0.0001
I0602 09:45:11.393823  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_52000.caffemodel
I0602 09:45:11.563738  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_52000.solverstate
I0602 09:45:11.705319  6142 solver.cpp:330] Iteration 52000, Testing net (#0)
I0602 09:45:11.705600  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:45:12.398272  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 09:45:13.427737  6142 solver.cpp:218] Iteration 52000 (0.947068 iter/s, 105.589s/100 iters), loss = 0.00931186
I0602 09:45:13.427799  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0701229 (* 1 = 0.0701229 loss)
I0602 09:45:13.427814  6142 sgd_solver.cpp:105] Iteration 52000, lr = 0.0001
I0602 09:46:57.933712  6142 solver.cpp:218] Iteration 52100 (0.956906 iter/s, 104.503s/100 iters), loss = 0.000303065
I0602 09:46:57.933918  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00108275 (* 1 = 0.00108275 loss)
I0602 09:46:57.933938  6142 sgd_solver.cpp:105] Iteration 52100, lr = 0.0001
I0602 09:48:27.824220  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:48:42.417305  6142 solver.cpp:218] Iteration 52200 (0.957113 iter/s, 104.481s/100 iters), loss = 0.000661692
I0602 09:48:42.417369  6142 solver.cpp:237]     Train net output #0: Softmax = 3.90719e-05 (* 1 = 3.90719e-05 loss)
I0602 09:48:42.417384  6142 sgd_solver.cpp:105] Iteration 52200, lr = 0.0001
I0602 09:50:26.903877  6142 solver.cpp:218] Iteration 52300 (0.957084 iter/s, 104.484s/100 iters), loss = 0.000565874
I0602 09:50:26.903981  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000780798 (* 1 = 0.000780798 loss)
I0602 09:50:26.903998  6142 sgd_solver.cpp:105] Iteration 52300, lr = 0.0001
I0602 09:52:11.361124  6142 solver.cpp:218] Iteration 52400 (0.957354 iter/s, 104.455s/100 iters), loss = 0.00132681
I0602 09:52:11.361290  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000188582 (* 1 = 0.000188582 loss)
I0602 09:52:11.361308  6142 sgd_solver.cpp:105] Iteration 52400, lr = 0.0001
I0602 09:53:54.237160  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 09:53:54.763697  6142 solver.cpp:330] Iteration 52500, Testing net (#0)
I0602 09:53:54.763945  6142 net.cpp:676] Ignoring source layer Softmax
I0602 09:53:55.435856  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 09:53:56.484421  6142 solver.cpp:218] Iteration 52500 (0.951289 iter/s, 105.12s/100 iters), loss = 0.000942606
I0602 09:53:56.484489  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0035782 (* 1 = 0.0035782 loss)
I0602 09:53:56.484505  6142 sgd_solver.cpp:105] Iteration 52500, lr = 0.0001
I0602 09:55:41.060513  6142 solver.cpp:218] Iteration 52600 (0.956266 iter/s, 104.573s/100 iters), loss = 0.00076011
I0602 09:55:41.060626  6142 solver.cpp:237]     Train net output #0: Softmax = 7.6781e-05 (* 1 = 7.6781e-05 loss)
I0602 09:55:41.060643  6142 sgd_solver.cpp:105] Iteration 52600, lr = 0.0001
I0602 09:57:25.640995  6142 solver.cpp:218] Iteration 52700 (0.956226 iter/s, 104.578s/100 iters), loss = 0.000400581
I0602 09:57:25.641144  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000505236 (* 1 = 0.000505236 loss)
I0602 09:57:25.641162  6142 sgd_solver.cpp:105] Iteration 52700, lr = 0.0001
I0602 09:59:10.162176  6142 solver.cpp:218] Iteration 52800 (0.956769 iter/s, 104.518s/100 iters), loss = 0.00028795
I0602 09:59:10.162331  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000109022 (* 1 = 0.000109022 loss)
I0602 09:59:10.162348  6142 sgd_solver.cpp:105] Iteration 52800, lr = 0.0001
I0602 09:59:21.682870  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:00:54.669410  6142 solver.cpp:218] Iteration 52900 (0.956897 iter/s, 104.505s/100 iters), loss = 0.000575943
I0602 10:00:54.669565  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000336644 (* 1 = 0.000336644 loss)
I0602 10:00:54.669584  6142 sgd_solver.cpp:105] Iteration 52900, lr = 0.0001
I0602 10:02:38.148234  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_53000.caffemodel
I0602 10:02:38.317692  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_53000.solverstate
I0602 10:02:38.461346  6142 solver.cpp:330] Iteration 53000, Testing net (#0)
I0602 10:02:38.461632  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:02:39.144901  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 10:02:40.176821  6142 solver.cpp:218] Iteration 53000 (0.947825 iter/s, 105.505s/100 iters), loss = 0.000701563
I0602 10:02:40.176892  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00249697 (* 1 = 0.00249697 loss)
I0602 10:02:40.176908  6142 sgd_solver.cpp:105] Iteration 53000, lr = 0.0001
I0602 10:04:24.658789  6142 solver.cpp:218] Iteration 53100 (0.957129 iter/s, 104.479s/100 iters), loss = 0.002365
I0602 10:04:24.658982  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000768615 (* 1 = 0.000768615 loss)
I0602 10:04:24.659001  6142 sgd_solver.cpp:105] Iteration 53100, lr = 0.0001
I0602 10:04:49.205180  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:06:09.145390  6142 solver.cpp:218] Iteration 53200 (0.957086 iter/s, 104.484s/100 iters), loss = 0.0011308
I0602 10:06:09.145558  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000406737 (* 1 = 0.000406737 loss)
I0602 10:06:09.145576  6142 sgd_solver.cpp:105] Iteration 53200, lr = 0.0001
I0602 10:07:53.708899  6142 solver.cpp:218] Iteration 53300 (0.956382 iter/s, 104.561s/100 iters), loss = 0.000851744
I0602 10:07:53.709044  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000462167 (* 1 = 0.000462167 loss)
I0602 10:07:53.709062  6142 sgd_solver.cpp:105] Iteration 53300, lr = 0.0001
I0602 10:09:38.332175  6142 solver.cpp:218] Iteration 53400 (0.955835 iter/s, 104.621s/100 iters), loss = 0.000914749
I0602 10:09:38.332334  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000518111 (* 1 = 0.000518111 loss)
I0602 10:09:38.332351  6142 sgd_solver.cpp:105] Iteration 53400, lr = 0.0001
I0602 10:10:15.985180  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:11:21.853240  6142 solver.cpp:330] Iteration 53500, Testing net (#0)
I0602 10:11:21.853576  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:11:22.526587  6142 solver.cpp:397]     Test net output #0: acc = 0.956
I0602 10:11:23.575922  6142 solver.cpp:218] Iteration 53500 (0.9502 iter/s, 105.241s/100 iters), loss = 0.00124052
I0602 10:11:23.575984  6142 solver.cpp:237]     Train net output #0: Softmax = 6.05762e-05 (* 1 = 6.05762e-05 loss)
I0602 10:11:23.575999  6142 sgd_solver.cpp:105] Iteration 53500, lr = 0.0001
I0602 10:13:08.154881  6142 solver.cpp:218] Iteration 53600 (0.956239 iter/s, 104.576s/100 iters), loss = 0.000406498
I0602 10:13:08.155030  6142 solver.cpp:237]     Train net output #0: Softmax = 8.85213e-05 (* 1 = 8.85213e-05 loss)
I0602 10:13:08.155047  6142 sgd_solver.cpp:105] Iteration 53600, lr = 0.0001
I0602 10:14:52.723778  6142 solver.cpp:218] Iteration 53700 (0.956332 iter/s, 104.566s/100 iters), loss = 0.000930424
I0602 10:14:52.723948  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000117476 (* 1 = 0.000117476 loss)
I0602 10:14:52.723968  6142 sgd_solver.cpp:105] Iteration 53700, lr = 0.0001
I0602 10:15:43.436400  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:16:37.337690  6142 solver.cpp:218] Iteration 53800 (0.955921 iter/s, 104.611s/100 iters), loss = 0.00142538
I0602 10:16:37.337846  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00129466 (* 1 = 0.00129466 loss)
I0602 10:16:37.337863  6142 sgd_solver.cpp:105] Iteration 53800, lr = 0.0001
I0602 10:18:21.884622  6142 solver.cpp:218] Iteration 53900 (0.956533 iter/s, 104.544s/100 iters), loss = 0.00245678
I0602 10:18:21.884718  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00764602 (* 1 = 0.00764602 loss)
I0602 10:18:21.884734  6142 sgd_solver.cpp:105] Iteration 53900, lr = 0.0001
I0602 10:20:05.414180  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_54000.caffemodel
I0602 10:20:05.588002  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_54000.solverstate
I0602 10:20:05.731448  6142 solver.cpp:330] Iteration 54000, Testing net (#0)
I0602 10:20:05.731734  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:20:06.401278  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 10:20:07.448235  6142 solver.cpp:218] Iteration 54000 (0.94732 iter/s, 105.561s/100 iters), loss = 0.000497413
I0602 10:20:07.448310  6142 solver.cpp:237]     Train net output #0: Softmax = 7.1731e-05 (* 1 = 7.1731e-05 loss)
I0602 10:20:07.448325  6142 sgd_solver.cpp:105] Iteration 54000, lr = 0.0001
I0602 10:21:11.219753  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:21:51.987479  6142 solver.cpp:218] Iteration 54100 (0.956602 iter/s, 104.537s/100 iters), loss = 0.000538025
I0602 10:21:51.987643  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000245833 (* 1 = 0.000245833 loss)
I0602 10:21:51.987660  6142 sgd_solver.cpp:105] Iteration 54100, lr = 0.0001
I0602 10:23:36.578972  6142 solver.cpp:218] Iteration 54200 (0.956125 iter/s, 104.589s/100 iters), loss = 0.000629613
I0602 10:23:36.579123  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000583848 (* 1 = 0.000583848 loss)
I0602 10:23:36.579141  6142 sgd_solver.cpp:105] Iteration 54200, lr = 0.0001
I0602 10:25:21.203789  6142 solver.cpp:218] Iteration 54300 (0.955821 iter/s, 104.622s/100 iters), loss = 0.000956525
I0602 10:25:21.203938  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000140901 (* 1 = 0.000140901 loss)
I0602 10:25:21.203958  6142 sgd_solver.cpp:105] Iteration 54300, lr = 0.0001
I0602 10:26:38.072259  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:27:05.783159  6142 solver.cpp:218] Iteration 54400 (0.956235 iter/s, 104.577s/100 iters), loss = 0.000416354
I0602 10:27:05.783221  6142 solver.cpp:237]     Train net output #0: Softmax = 4.41389e-05 (* 1 = 4.41389e-05 loss)
I0602 10:27:05.783237  6142 sgd_solver.cpp:105] Iteration 54400, lr = 0.0001
I0602 10:28:49.268654  6142 solver.cpp:330] Iteration 54500, Testing net (#0)
I0602 10:28:49.268930  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:28:49.950083  6142 solver.cpp:397]     Test net output #0: acc = 0.944
I0602 10:28:50.984244  6142 solver.cpp:218] Iteration 54500 (0.950583 iter/s, 105.199s/100 iters), loss = 0.0215244
I0602 10:28:50.984320  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0625802 (* 1 = 0.0625802 loss)
I0602 10:28:50.984336  6142 sgd_solver.cpp:105] Iteration 54500, lr = 0.0001
I0602 10:30:35.492094  6142 solver.cpp:218] Iteration 54600 (0.956889 iter/s, 104.505s/100 iters), loss = 0.00103772
I0602 10:30:35.492249  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000455868 (* 1 = 0.000455868 loss)
I0602 10:30:35.492267  6142 sgd_solver.cpp:105] Iteration 54600, lr = 0.0001
I0602 10:32:05.383517  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:32:19.993304  6142 solver.cpp:218] Iteration 54700 (0.95695 iter/s, 104.499s/100 iters), loss = 0.00926661
I0602 10:32:19.993381  6142 solver.cpp:237]     Train net output #0: Softmax = 4.91906e-05 (* 1 = 4.91906e-05 loss)
I0602 10:32:19.993397  6142 sgd_solver.cpp:105] Iteration 54700, lr = 0.0001
I0602 10:34:04.519315  6142 solver.cpp:218] Iteration 54800 (0.956723 iter/s, 104.523s/100 iters), loss = 0.000733618
I0602 10:34:04.519464  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000680636 (* 1 = 0.000680636 loss)
I0602 10:34:04.519481  6142 sgd_solver.cpp:105] Iteration 54800, lr = 0.0001
I0602 10:35:48.954723  6142 solver.cpp:218] Iteration 54900 (0.957553 iter/s, 104.433s/100 iters), loss = 0.000805115
I0602 10:35:48.954859  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00019693 (* 1 = 0.00019693 loss)
I0602 10:35:48.954876  6142 sgd_solver.cpp:105] Iteration 54900, lr = 0.0001
I0602 10:37:31.963768  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:37:32.488263  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_55000.caffemodel
I0602 10:37:32.657766  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_55000.solverstate
I0602 10:37:32.807615  6142 solver.cpp:330] Iteration 55000, Testing net (#0)
I0602 10:37:32.807896  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:37:33.477527  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 10:37:34.521893  6142 solver.cpp:218] Iteration 55000 (0.947287 iter/s, 105.565s/100 iters), loss = 0.000835297
I0602 10:37:34.521955  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0025909 (* 1 = 0.0025909 loss)
I0602 10:37:34.521971  6142 sgd_solver.cpp:105] Iteration 55000, lr = 0.0001
I0602 10:39:19.057994  6142 solver.cpp:218] Iteration 55100 (0.95663 iter/s, 104.534s/100 iters), loss = 0.000703547
I0602 10:39:19.058192  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000133667 (* 1 = 0.000133667 loss)
I0602 10:39:19.058210  6142 sgd_solver.cpp:105] Iteration 55100, lr = 0.0001
I0602 10:41:03.563768  6142 solver.cpp:218] Iteration 55200 (0.956909 iter/s, 104.503s/100 iters), loss = 0.000602008
I0602 10:41:03.563922  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00324115 (* 1 = 0.00324115 loss)
I0602 10:41:03.563941  6142 sgd_solver.cpp:105] Iteration 55200, lr = 0.0001
I0602 10:42:48.033959  6142 solver.cpp:218] Iteration 55300 (0.957235 iter/s, 104.468s/100 iters), loss = 0.000460134
I0602 10:42:48.034154  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00108089 (* 1 = 0.00108089 loss)
I0602 10:42:48.034173  6142 sgd_solver.cpp:105] Iteration 55300, lr = 0.0001
I0602 10:42:59.557924  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:44:32.599268  6142 solver.cpp:218] Iteration 55400 (0.956367 iter/s, 104.562s/100 iters), loss = 0.00049665
I0602 10:44:32.599421  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000560437 (* 1 = 0.000560437 loss)
I0602 10:44:32.599439  6142 sgd_solver.cpp:105] Iteration 55400, lr = 0.0001
I0602 10:46:16.150835  6142 solver.cpp:330] Iteration 55500, Testing net (#0)
I0602 10:46:16.151127  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:46:16.840541  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 10:46:17.882757  6142 solver.cpp:218] Iteration 55500 (0.949841 iter/s, 105.281s/100 iters), loss = 0.00042738
I0602 10:46:17.882820  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000302336 (* 1 = 0.000302336 loss)
I0602 10:46:17.882835  6142 sgd_solver.cpp:105] Iteration 55500, lr = 0.0001
I0602 10:48:02.472229  6142 solver.cpp:218] Iteration 55600 (0.956143 iter/s, 104.587s/100 iters), loss = 0.00168609
I0602 10:48:02.472384  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00106544 (* 1 = 0.00106544 loss)
I0602 10:48:02.472404  6142 sgd_solver.cpp:105] Iteration 55600, lr = 0.0001
I0602 10:48:27.062819  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:49:47.044872  6142 solver.cpp:218] Iteration 55700 (0.956297 iter/s, 104.57s/100 iters), loss = 0.00148353
I0602 10:49:47.044996  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000146456 (* 1 = 0.000146456 loss)
I0602 10:49:47.045012  6142 sgd_solver.cpp:105] Iteration 55700, lr = 0.0001
I0602 10:51:31.630125  6142 solver.cpp:218] Iteration 55800 (0.956181 iter/s, 104.583s/100 iters), loss = 0.000788767
I0602 10:51:31.630276  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00145662 (* 1 = 0.00145662 loss)
I0602 10:51:31.630293  6142 sgd_solver.cpp:105] Iteration 55800, lr = 0.0001
I0602 10:53:16.221549  6142 solver.cpp:218] Iteration 55900 (0.956125 iter/s, 104.589s/100 iters), loss = 0.000455023
I0602 10:53:16.221724  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000702577 (* 1 = 0.000702577 loss)
I0602 10:53:16.221742  6142 sgd_solver.cpp:105] Iteration 55900, lr = 0.0001
I0602 10:53:53.887476  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 10:54:59.749053  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_56000.caffemodel
I0602 10:54:59.917475  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_56000.solverstate
I0602 10:55:00.065356  6142 solver.cpp:330] Iteration 56000, Testing net (#0)
I0602 10:55:00.065639  6142 net.cpp:676] Ignoring source layer Softmax
I0602 10:55:00.769182  6142 solver.cpp:397]     Test net output #0: acc = 0.948
I0602 10:55:01.802502  6142 solver.cpp:218] Iteration 56000 (0.947165 iter/s, 105.578s/100 iters), loss = 0.000937837
I0602 10:55:01.802564  6142 solver.cpp:237]     Train net output #0: Softmax = 4.84606e-05 (* 1 = 4.84606e-05 loss)
I0602 10:55:01.802579  6142 sgd_solver.cpp:105] Iteration 56000, lr = 0.0001
I0602 10:56:46.396849  6142 solver.cpp:218] Iteration 56100 (0.956098 iter/s, 104.592s/100 iters), loss = 0.000751772
I0602 10:56:46.397044  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00101432 (* 1 = 0.00101432 loss)
I0602 10:56:46.397063  6142 sgd_solver.cpp:105] Iteration 56100, lr = 0.0001
I0602 10:58:30.979809  6142 solver.cpp:218] Iteration 56200 (0.956203 iter/s, 104.58s/100 iters), loss = 0.000273218
I0602 10:58:30.979980  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000107742 (* 1 = 0.000107742 loss)
I0602 10:58:30.980000  6142 sgd_solver.cpp:105] Iteration 56200, lr = 0.0001
I0602 10:59:21.695942  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:00:15.564327  6142 solver.cpp:218] Iteration 56300 (0.956189 iter/s, 104.582s/100 iters), loss = 0.00187121
I0602 11:00:15.564479  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000612427 (* 1 = 0.000612427 loss)
I0602 11:00:15.564496  6142 sgd_solver.cpp:105] Iteration 56300, lr = 0.0001
I0602 11:02:00.119496  6142 solver.cpp:218] Iteration 56400 (0.956457 iter/s, 104.553s/100 iters), loss = 0.00101929
I0602 11:02:00.119663  6142 solver.cpp:237]     Train net output #0: Softmax = 6.02933e-05 (* 1 = 6.02933e-05 loss)
I0602 11:02:00.119681  6142 sgd_solver.cpp:105] Iteration 56400, lr = 0.0001
I0602 11:03:43.646487  6142 solver.cpp:330] Iteration 56500, Testing net (#0)
I0602 11:03:43.646807  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:03:44.326778  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 11:03:45.371294  6142 solver.cpp:218] Iteration 56500 (0.950127 iter/s, 105.249s/100 iters), loss = 0.000492554
I0602 11:03:45.371357  6142 solver.cpp:237]     Train net output #0: Softmax = 6.31487e-05 (* 1 = 6.31487e-05 loss)
I0602 11:03:45.371372  6142 sgd_solver.cpp:105] Iteration 56500, lr = 0.0001
I0602 11:04:49.218952  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:05:30.006023  6142 solver.cpp:218] Iteration 56600 (0.955729 iter/s, 104.632s/100 iters), loss = 0.000614015
I0602 11:05:30.006129  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000143574 (* 1 = 0.000143574 loss)
I0602 11:05:30.006145  6142 sgd_solver.cpp:105] Iteration 56600, lr = 0.0001
I0602 11:07:14.528761  6142 solver.cpp:218] Iteration 56700 (0.956753 iter/s, 104.52s/100 iters), loss = 0.00107065
I0602 11:07:14.528904  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00048384 (* 1 = 0.00048384 loss)
I0602 11:07:14.528923  6142 sgd_solver.cpp:105] Iteration 56700, lr = 0.0001
I0602 11:08:59.091275  6142 solver.cpp:218] Iteration 56800 (0.95639 iter/s, 104.56s/100 iters), loss = 0.000322604
I0602 11:08:59.091424  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00015224 (* 1 = 0.00015224 loss)
I0602 11:08:59.091442  6142 sgd_solver.cpp:105] Iteration 56800, lr = 0.0001
I0602 11:10:15.925635  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:10:43.615046  6142 solver.cpp:218] Iteration 56900 (0.956744 iter/s, 104.521s/100 iters), loss = 0.000260789
I0602 11:10:43.615113  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000187034 (* 1 = 0.000187034 loss)
I0602 11:10:43.615128  6142 sgd_solver.cpp:105] Iteration 56900, lr = 0.0001
I0602 11:12:27.128674  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_57000.caffemodel
I0602 11:12:27.299731  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_57000.solverstate
I0602 11:12:27.445029  6142 solver.cpp:330] Iteration 57000, Testing net (#0)
I0602 11:12:27.445318  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:12:28.114665  6142 solver.cpp:397]     Test net output #0: acc = 0.956
I0602 11:12:29.164361  6142 solver.cpp:218] Iteration 57000 (0.947448 iter/s, 105.547s/100 iters), loss = 0.00974547
I0602 11:12:29.164425  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0691137 (* 1 = 0.0691137 loss)
I0602 11:12:29.164441  6142 sgd_solver.cpp:105] Iteration 57000, lr = 0.0001
I0602 11:14:13.744753  6142 solver.cpp:218] Iteration 57100 (0.956225 iter/s, 104.578s/100 iters), loss = 0.000739675
I0602 11:14:13.744962  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00373181 (* 1 = 0.00373181 loss)
I0602 11:14:13.744982  6142 sgd_solver.cpp:105] Iteration 57100, lr = 0.0001
I0602 11:15:43.641153  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:15:58.275915  6142 solver.cpp:218] Iteration 57200 (0.956677 iter/s, 104.528s/100 iters), loss = 0.000801461
I0602 11:15:58.276000  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000117448 (* 1 = 0.000117448 loss)
I0602 11:15:58.276016  6142 sgd_solver.cpp:105] Iteration 57200, lr = 0.0001
I0602 11:17:42.833139  6142 solver.cpp:218] Iteration 57300 (0.956438 iter/s, 104.555s/100 iters), loss = 0.00038915
I0602 11:17:42.833282  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00110466 (* 1 = 0.00110466 loss)
I0602 11:17:42.833300  6142 sgd_solver.cpp:105] Iteration 57300, lr = 0.0001
I0602 11:19:27.403787  6142 solver.cpp:218] Iteration 57400 (0.956317 iter/s, 104.568s/100 iters), loss = 0.000262626
I0602 11:19:27.403930  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000158661 (* 1 = 0.000158661 loss)
I0602 11:19:27.403947  6142 sgd_solver.cpp:105] Iteration 57400, lr = 0.0001
I0602 11:21:10.469110  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:21:10.984531  6142 solver.cpp:330] Iteration 57500, Testing net (#0)
I0602 11:21:10.984781  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:21:11.667661  6142 solver.cpp:397]     Test net output #0: acc = 0.968
I0602 11:21:12.715394  6142 solver.cpp:218] Iteration 57500 (0.949587 iter/s, 105.309s/100 iters), loss = 0.000792278
I0602 11:21:12.715456  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00247229 (* 1 = 0.00247229 loss)
I0602 11:21:12.715471  6142 sgd_solver.cpp:105] Iteration 57500, lr = 0.0001
I0602 11:22:57.293316  6142 solver.cpp:218] Iteration 57600 (0.956248 iter/s, 104.575s/100 iters), loss = 0.00112644
I0602 11:22:57.293444  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000109272 (* 1 = 0.000109272 loss)
I0602 11:22:57.293462  6142 sgd_solver.cpp:105] Iteration 57600, lr = 0.0001
I0602 11:24:41.909622  6142 solver.cpp:218] Iteration 57700 (0.955898 iter/s, 104.614s/100 iters), loss = 0.00036933
I0602 11:24:41.909801  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000266475 (* 1 = 0.000266475 loss)
I0602 11:24:41.909821  6142 sgd_solver.cpp:105] Iteration 57700, lr = 0.0001
I0602 11:26:26.457710  6142 solver.cpp:218] Iteration 57800 (0.956522 iter/s, 104.545s/100 iters), loss = 0.000863178
I0602 11:26:26.457859  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000122712 (* 1 = 0.000122712 loss)
I0602 11:26:26.457876  6142 sgd_solver.cpp:105] Iteration 57800, lr = 0.0001
I0602 11:26:37.966105  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:28:11.012158  6142 solver.cpp:218] Iteration 57900 (0.956463 iter/s, 104.552s/100 iters), loss = 0.00161484
I0602 11:28:11.012321  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000285129 (* 1 = 0.000285129 loss)
I0602 11:28:11.012338  6142 sgd_solver.cpp:105] Iteration 57900, lr = 0.0001
I0602 11:29:54.512230  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_58000.caffemodel
I0602 11:29:54.688429  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_58000.solverstate
I0602 11:29:54.831943  6142 solver.cpp:330] Iteration 58000, Testing net (#0)
I0602 11:29:54.832226  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:29:55.514212  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 11:29:56.546334  6142 solver.cpp:218] Iteration 58000 (0.947584 iter/s, 105.532s/100 iters), loss = 0.00521451
I0602 11:29:56.546396  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0397493 (* 1 = 0.0397493 loss)
I0602 11:29:56.546411  6142 sgd_solver.cpp:105] Iteration 58000, lr = 0.0001
I0602 11:31:41.149332  6142 solver.cpp:218] Iteration 58100 (0.956018 iter/s, 104.601s/100 iters), loss = 0.00131306
I0602 11:31:41.149529  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00058281 (* 1 = 0.00058281 loss)
I0602 11:31:41.149549  6142 sgd_solver.cpp:105] Iteration 58100, lr = 0.0001
I0602 11:32:05.756073  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:33:25.736284  6142 solver.cpp:218] Iteration 58200 (0.956166 iter/s, 104.584s/100 iters), loss = 0.000730255
I0602 11:33:25.736446  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000216858 (* 1 = 0.000216858 loss)
I0602 11:33:25.736464  6142 sgd_solver.cpp:105] Iteration 58200, lr = 0.0001
I0602 11:35:10.272186  6142 solver.cpp:218] Iteration 58300 (0.956633 iter/s, 104.533s/100 iters), loss = 0.00146034
I0602 11:35:10.272346  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000374104 (* 1 = 0.000374104 loss)
I0602 11:35:10.272364  6142 sgd_solver.cpp:105] Iteration 58300, lr = 0.0001
I0602 11:36:54.800925  6142 solver.cpp:218] Iteration 58400 (0.956698 iter/s, 104.526s/100 iters), loss = 0.000576299
I0602 11:36:54.801029  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000560163 (* 1 = 0.000560163 loss)
I0602 11:36:54.801045  6142 sgd_solver.cpp:105] Iteration 58400, lr = 0.0001
I0602 11:37:32.444288  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:38:38.332549  6142 solver.cpp:330] Iteration 58500, Testing net (#0)
I0602 11:38:38.332877  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:38:39.005427  6142 solver.cpp:397]     Test net output #0: acc = 0.944
I0602 11:38:40.051420  6142 solver.cpp:218] Iteration 58500 (0.950137 iter/s, 105.248s/100 iters), loss = 0.000778269
I0602 11:38:40.051483  6142 solver.cpp:237]     Train net output #0: Softmax = 4.42135e-05 (* 1 = 4.42135e-05 loss)
I0602 11:38:40.051497  6142 sgd_solver.cpp:105] Iteration 58500, lr = 0.0001
I0602 11:40:24.521466  6142 solver.cpp:218] Iteration 58600 (0.957234 iter/s, 104.468s/100 iters), loss = 0.00139174
I0602 11:40:24.521629  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000987368 (* 1 = 0.000987368 loss)
I0602 11:40:24.521647  6142 sgd_solver.cpp:105] Iteration 58600, lr = 0.0001
I0602 11:42:09.046733  6142 solver.cpp:218] Iteration 58700 (0.95673 iter/s, 104.523s/100 iters), loss = 0.000564215
I0602 11:42:09.046828  6142 solver.cpp:237]     Train net output #0: Softmax = 6.2523e-05 (* 1 = 6.2523e-05 loss)
I0602 11:42:09.046844  6142 sgd_solver.cpp:105] Iteration 58700, lr = 0.0001
I0602 11:42:59.647202  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:43:53.416900  6142 solver.cpp:218] Iteration 58800 (0.958151 iter/s, 104.368s/100 iters), loss = 0.000593843
I0602 11:43:53.417057  6142 solver.cpp:237]     Train net output #0: Softmax = 0.001386 (* 1 = 0.001386 loss)
I0602 11:43:53.417073  6142 sgd_solver.cpp:105] Iteration 58800, lr = 0.0001
I0602 11:45:37.914801  6142 solver.cpp:218] Iteration 58900 (0.95698 iter/s, 104.495s/100 iters), loss = 0.00188337
I0602 11:45:37.914963  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000110825 (* 1 = 0.000110825 loss)
I0602 11:45:37.914981  6142 sgd_solver.cpp:105] Iteration 58900, lr = 0.0001
I0602 11:47:21.333154  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_59000.caffemodel
I0602 11:47:21.503124  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_59000.solverstate
I0602 11:47:21.652626  6142 solver.cpp:330] Iteration 59000, Testing net (#0)
I0602 11:47:21.652915  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:47:22.332967  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 11:47:23.374529  6142 solver.cpp:218] Iteration 59000 (0.948252 iter/s, 105.457s/100 iters), loss = 0.000537338
I0602 11:47:23.374593  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000156981 (* 1 = 0.000156981 loss)
I0602 11:47:23.374608  6142 sgd_solver.cpp:105] Iteration 59000, lr = 0.0001
I0602 11:48:27.151262  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:49:07.908028  6142 solver.cpp:218] Iteration 59100 (0.956654 iter/s, 104.531s/100 iters), loss = 0.00112283
I0602 11:49:07.908191  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000162014 (* 1 = 0.000162014 loss)
I0602 11:49:07.908210  6142 sgd_solver.cpp:105] Iteration 59100, lr = 0.0001
I0602 11:50:52.406054  6142 solver.cpp:218] Iteration 59200 (0.956979 iter/s, 104.495s/100 iters), loss = 0.000806571
I0602 11:50:52.406200  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000601545 (* 1 = 0.000601545 loss)
I0602 11:50:52.406219  6142 sgd_solver.cpp:105] Iteration 59200, lr = 0.0001
I0602 11:52:36.951557  6142 solver.cpp:218] Iteration 59300 (0.956544 iter/s, 104.543s/100 iters), loss = 0.00140652
I0602 11:52:36.951709  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00014035 (* 1 = 0.00014035 loss)
I0602 11:52:36.951727  6142 sgd_solver.cpp:105] Iteration 59300, lr = 0.0001
I0602 11:53:53.786772  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:54:21.491135  6142 solver.cpp:218] Iteration 59400 (0.956598 iter/s, 104.537s/100 iters), loss = 0.000494617
I0602 11:54:21.491199  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000554279 (* 1 = 0.000554279 loss)
I0602 11:54:21.491214  6142 sgd_solver.cpp:105] Iteration 59400, lr = 0.0001
I0602 11:56:04.941949  6142 solver.cpp:330] Iteration 59500, Testing net (#0)
I0602 11:56:04.942265  6142 net.cpp:676] Ignoring source layer Softmax
I0602 11:56:05.510869  6156 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:56:05.616912  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 11:56:06.661145  6142 solver.cpp:218] Iteration 59500 (0.950863 iter/s, 105.168s/100 iters), loss = 0.00864069
I0602 11:56:06.661209  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0652455 (* 1 = 0.0652455 loss)
I0602 11:56:06.661226  6142 sgd_solver.cpp:105] Iteration 59500, lr = 0.0001
I0602 11:57:51.172153  6142 solver.cpp:218] Iteration 59600 (0.956859 iter/s, 104.509s/100 iters), loss = 0.00040478
I0602 11:57:51.172308  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000915748 (* 1 = 0.000915748 loss)
I0602 11:57:51.172325  6142 sgd_solver.cpp:105] Iteration 59600, lr = 0.0001
I0602 11:59:21.096005  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 11:59:35.700412  6142 solver.cpp:218] Iteration 59700 (0.956702 iter/s, 104.526s/100 iters), loss = 0.000908724
I0602 11:59:35.700477  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000281338 (* 1 = 0.000281338 loss)
I0602 11:59:35.700492  6142 sgd_solver.cpp:105] Iteration 59700, lr = 0.0001
I0602 12:01:20.313282  6142 solver.cpp:218] Iteration 59800 (0.955928 iter/s, 104.61s/100 iters), loss = 0.000905309
I0602 12:01:20.313434  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00467403 (* 1 = 0.00467403 loss)
I0602 12:01:20.313453  6142 sgd_solver.cpp:105] Iteration 59800, lr = 0.0001
I0602 12:03:04.814157  6142 solver.cpp:218] Iteration 59900 (0.956953 iter/s, 104.498s/100 iters), loss = 0.000395854
I0602 12:03:04.814318  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00016906 (* 1 = 0.00016906 loss)
I0602 12:03:04.814337  6142 sgd_solver.cpp:105] Iteration 59900, lr = 0.0001
I0602 12:04:47.777536  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:04:48.293011  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_60000.caffemodel
I0602 12:04:48.463116  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_60000.solverstate
I0602 12:04:48.603879  6142 solver.cpp:330] Iteration 60000, Testing net (#0)
I0602 12:04:48.604161  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:04:49.281527  6142 solver.cpp:397]     Test net output #0: acc = 0.972
I0602 12:04:50.329341  6142 solver.cpp:218] Iteration 60000 (0.947754 iter/s, 105.513s/100 iters), loss = 0.00107559
I0602 12:04:50.329411  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00345749 (* 1 = 0.00345749 loss)
I0602 12:04:50.329424  6142 sgd_solver.cpp:46] MultiStep Status: Iteration 60000, step = 3
I0602 12:04:50.329434  6142 sgd_solver.cpp:105] Iteration 60000, lr = 1e-05
I0602 12:06:34.879817  6142 solver.cpp:218] Iteration 60100 (0.956499 iter/s, 104.548s/100 iters), loss = 0.000718369
I0602 12:06:34.879972  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000141285 (* 1 = 0.000141285 loss)
I0602 12:06:34.879992  6142 sgd_solver.cpp:105] Iteration 60100, lr = 1e-05
I0602 12:08:19.412734  6142 solver.cpp:218] Iteration 60200 (0.956661 iter/s, 104.53s/100 iters), loss = 0.000453957
I0602 12:08:19.412910  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000358609 (* 1 = 0.000358609 loss)
I0602 12:08:19.412931  6142 sgd_solver.cpp:105] Iteration 60200, lr = 1e-05
I0602 12:10:03.934021  6142 solver.cpp:218] Iteration 60300 (0.956771 iter/s, 104.518s/100 iters), loss = 0.000519473
I0602 12:10:03.934177  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000191196 (* 1 = 0.000191196 loss)
I0602 12:10:03.934195  6142 sgd_solver.cpp:105] Iteration 60300, lr = 1e-05
I0602 12:10:15.437707  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:11:48.437547  6142 solver.cpp:218] Iteration 60400 (0.956932 iter/s, 104.501s/100 iters), loss = 0.000409598
I0602 12:11:48.437692  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000352775 (* 1 = 0.000352775 loss)
I0602 12:11:48.437711  6142 sgd_solver.cpp:105] Iteration 60400, lr = 1e-05
I0602 12:13:31.871546  6142 solver.cpp:330] Iteration 60500, Testing net (#0)
I0602 12:13:31.871825  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:13:32.555970  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 12:13:33.583158  6142 solver.cpp:218] Iteration 60500 (0.951088 iter/s, 105.143s/100 iters), loss = 0.00028448
I0602 12:13:33.583221  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000393721 (* 1 = 0.000393721 loss)
I0602 12:13:33.583236  6142 sgd_solver.cpp:105] Iteration 60500, lr = 1e-05
I0602 12:15:18.108731  6142 solver.cpp:218] Iteration 60600 (0.956728 iter/s, 104.523s/100 iters), loss = 0.001793
I0602 12:15:18.108882  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000246711 (* 1 = 0.000246711 loss)
I0602 12:15:18.108901  6142 sgd_solver.cpp:105] Iteration 60600, lr = 1e-05
I0602 12:15:42.688071  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:17:02.644544  6142 solver.cpp:218] Iteration 60700 (0.956635 iter/s, 104.533s/100 iters), loss = 0.000989675
I0602 12:17:02.644692  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000286715 (* 1 = 0.000286715 loss)
I0602 12:17:02.644711  6142 sgd_solver.cpp:105] Iteration 60700, lr = 1e-05
I0602 12:18:47.132853  6142 solver.cpp:218] Iteration 60800 (0.95707 iter/s, 104.486s/100 iters), loss = 0.000600185
I0602 12:18:47.132977  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000692878 (* 1 = 0.000692878 loss)
I0602 12:18:47.132995  6142 sgd_solver.cpp:105] Iteration 60800, lr = 1e-05
I0602 12:20:31.649258  6142 solver.cpp:218] Iteration 60900 (0.956812 iter/s, 104.514s/100 iters), loss = 0.000618277
I0602 12:20:31.649432  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000591503 (* 1 = 0.000591503 loss)
I0602 12:20:31.649452  6142 sgd_solver.cpp:105] Iteration 60900, lr = 1e-05
I0602 12:21:09.307155  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:22:15.095646  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_61000.caffemodel
I0602 12:22:15.268239  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_61000.solverstate
I0602 12:22:15.411346  6142 solver.cpp:330] Iteration 61000, Testing net (#0)
I0602 12:22:15.411629  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:22:16.091557  6142 solver.cpp:397]     Test net output #0: acc = 0.96
I0602 12:22:17.138602  6142 solver.cpp:218] Iteration 61000 (0.947988 iter/s, 105.487s/100 iters), loss = 0.000376572
I0602 12:22:17.138662  6142 solver.cpp:237]     Train net output #0: Softmax = 6.69322e-05 (* 1 = 6.69322e-05 loss)
I0602 12:22:17.138677  6142 sgd_solver.cpp:105] Iteration 61000, lr = 1e-05
I0602 12:24:01.657878  6142 solver.cpp:218] Iteration 61100 (0.956785 iter/s, 104.517s/100 iters), loss = 0.000751497
I0602 12:24:01.657981  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000195754 (* 1 = 0.000195754 loss)
I0602 12:24:01.657999  6142 sgd_solver.cpp:105] Iteration 61100, lr = 1e-05
I0602 12:25:46.102977  6142 solver.cpp:218] Iteration 61200 (0.957465 iter/s, 104.443s/100 iters), loss = 0.000586151
I0602 12:25:46.103168  6142 solver.cpp:237]     Train net output #0: Softmax = 4.61508e-05 (* 1 = 4.61508e-05 loss)
I0602 12:25:46.103188  6142 sgd_solver.cpp:105] Iteration 61200, lr = 1e-05
I0602 12:26:36.819347  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:27:30.644145  6142 solver.cpp:218] Iteration 61300 (0.956586 iter/s, 104.538s/100 iters), loss = 0.00124166
I0602 12:27:30.644253  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00636086 (* 1 = 0.00636086 loss)
I0602 12:27:30.644270  6142 sgd_solver.cpp:105] Iteration 61300, lr = 1e-05
I0602 12:29:15.242506  6142 solver.cpp:218] Iteration 61400 (0.956062 iter/s, 104.596s/100 iters), loss = 0.000840721
I0602 12:29:15.242686  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000209855 (* 1 = 0.000209855 loss)
I0602 12:29:15.242704  6142 sgd_solver.cpp:105] Iteration 61400, lr = 1e-05
I0602 12:30:58.751435  6142 solver.cpp:330] Iteration 61500, Testing net (#0)
I0602 12:30:58.751734  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:30:59.442201  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 12:31:00.481532  6142 solver.cpp:218] Iteration 61500 (0.950243 iter/s, 105.236s/100 iters), loss = 0.000418986
I0602 12:31:00.481595  6142 solver.cpp:237]     Train net output #0: Softmax = 9.82241e-05 (* 1 = 9.82241e-05 loss)
I0602 12:31:00.481611  6142 sgd_solver.cpp:105] Iteration 61500, lr = 1e-05
I0602 12:32:04.250695  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:32:44.974059  6142 solver.cpp:218] Iteration 61600 (0.95703 iter/s, 104.49s/100 iters), loss = 0.00380757
I0602 12:32:44.974165  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00359169 (* 1 = 0.00359169 loss)
I0602 12:32:44.974182  6142 sgd_solver.cpp:105] Iteration 61600, lr = 1e-05
I0602 12:34:29.476817  6142 solver.cpp:218] Iteration 61700 (0.956936 iter/s, 104.5s/100 iters), loss = 0.000573126
I0602 12:34:29.476971  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000542729 (* 1 = 0.000542729 loss)
I0602 12:34:29.476990  6142 sgd_solver.cpp:105] Iteration 61700, lr = 1e-05
I0602 12:36:13.994973  6142 solver.cpp:218] Iteration 61800 (0.956796 iter/s, 104.515s/100 iters), loss = 0.000349091
I0602 12:36:13.995142  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000212187 (* 1 = 0.000212187 loss)
I0602 12:36:13.995162  6142 sgd_solver.cpp:105] Iteration 61800, lr = 1e-05
I0602 12:37:30.836676  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:37:58.507298  6142 solver.cpp:218] Iteration 61900 (0.95685 iter/s, 104.51s/100 iters), loss = 0.000212158
I0602 12:37:58.507362  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000729404 (* 1 = 0.000729404 loss)
I0602 12:37:58.507378  6142 sgd_solver.cpp:105] Iteration 61900, lr = 1e-05
I0602 12:39:42.004782  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_62000.caffemodel
I0602 12:39:42.173646  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_62000.solverstate
I0602 12:39:42.314693  6142 solver.cpp:330] Iteration 62000, Testing net (#0)
I0602 12:39:42.314978  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:39:42.998468  6142 solver.cpp:397]     Test net output #0: acc = 0.964
I0602 12:39:44.046500  6142 solver.cpp:218] Iteration 62000 (0.947538 iter/s, 105.537s/100 iters), loss = 0.00913571
I0602 12:39:44.046562  6142 solver.cpp:237]     Train net output #0: Softmax = 0.0659159 (* 1 = 0.0659159 loss)
I0602 12:39:44.046578  6142 sgd_solver.cpp:105] Iteration 62000, lr = 1e-05
I0602 12:41:28.682458  6142 solver.cpp:218] Iteration 62100 (0.955718 iter/s, 104.633s/100 iters), loss = 0.000381251
I0602 12:41:28.682617  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000465757 (* 1 = 0.000465757 loss)
I0602 12:41:28.682636  6142 sgd_solver.cpp:105] Iteration 62100, lr = 1e-05
I0602 12:42:58.539887  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:43:13.160012  6142 solver.cpp:218] Iteration 62200 (0.957163 iter/s, 104.475s/100 iters), loss = 0.00148062
I0602 12:43:13.160073  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000190326 (* 1 = 0.000190326 loss)
I0602 12:43:13.160090  6142 sgd_solver.cpp:105] Iteration 62200, lr = 1e-05
I0602 12:44:57.680155  6142 solver.cpp:218] Iteration 62300 (0.95677 iter/s, 104.518s/100 iters), loss = 0.000498241
I0602 12:44:57.680310  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00190597 (* 1 = 0.00190597 loss)
I0602 12:44:57.680330  6142 sgd_solver.cpp:105] Iteration 62300, lr = 1e-05
I0602 12:46:42.197731  6142 solver.cpp:218] Iteration 62400 (0.956796 iter/s, 104.516s/100 iters), loss = 0.000273223
I0602 12:46:42.197830  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000150868 (* 1 = 0.000150868 loss)
I0602 12:46:42.197847  6142 sgd_solver.cpp:105] Iteration 62400, lr = 1e-05
I0602 12:48:25.165267  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:48:25.692360  6142 solver.cpp:330] Iteration 62500, Testing net (#0)
I0602 12:48:25.692606  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:48:26.365514  6142 solver.cpp:397]     Test net output #0: acc = 0.948
I0602 12:48:27.414494  6142 solver.cpp:218] Iteration 62500 (0.950438 iter/s, 105.215s/100 iters), loss = 0.000674779
I0602 12:48:27.414563  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00274593 (* 1 = 0.00274593 loss)
I0602 12:48:27.414580  6142 sgd_solver.cpp:105] Iteration 62500, lr = 1e-05
I0602 12:50:12.011256  6142 solver.cpp:218] Iteration 62600 (0.956072 iter/s, 104.595s/100 iters), loss = 0.000925755
I0602 12:50:12.011426  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000446296 (* 1 = 0.000446296 loss)
I0602 12:50:12.011446  6142 sgd_solver.cpp:105] Iteration 62600, lr = 1e-05
I0602 12:51:56.619828  6142 solver.cpp:218] Iteration 62700 (0.955966 iter/s, 104.606s/100 iters), loss = 0.000323598
I0602 12:51:56.619982  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000440588 (* 1 = 0.000440588 loss)
I0602 12:51:56.620000  6142 sgd_solver.cpp:105] Iteration 62700, lr = 1e-05
I0602 12:53:41.153215  6142 solver.cpp:218] Iteration 62800 (0.956653 iter/s, 104.531s/100 iters), loss = 0.00074937
I0602 12:53:41.153375  6142 solver.cpp:237]     Train net output #0: Softmax = 7.14997e-05 (* 1 = 7.14997e-05 loss)
I0602 12:53:41.153394  6142 sgd_solver.cpp:105] Iteration 62800, lr = 1e-05
I0602 12:53:52.663456  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 12:55:25.648140  6142 solver.cpp:218] Iteration 62900 (0.957006 iter/s, 104.493s/100 iters), loss = 0.00064865
I0602 12:55:25.648288  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000330131 (* 1 = 0.000330131 loss)
I0602 12:55:25.648305  6142 sgd_solver.cpp:105] Iteration 62900, lr = 1e-05
I0602 12:57:09.100538  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_63000.caffemodel
I0602 12:57:09.269992  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_63000.solverstate
I0602 12:57:09.414831  6142 solver.cpp:330] Iteration 63000, Testing net (#0)
I0602 12:57:09.415159  6142 net.cpp:676] Ignoring source layer Softmax
I0602 12:57:10.104423  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 12:57:11.129045  6142 solver.cpp:218] Iteration 63000 (0.94806 iter/s, 105.479s/100 iters), loss = 0.000372179
I0602 12:57:11.129122  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000386196 (* 1 = 0.000386196 loss)
I0602 12:57:11.129139  6142 sgd_solver.cpp:105] Iteration 63000, lr = 1e-05
I0602 12:58:55.643548  6142 solver.cpp:218] Iteration 63100 (0.956826 iter/s, 104.512s/100 iters), loss = 0.0182542
I0602 12:58:55.643672  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000454594 (* 1 = 0.000454594 loss)
I0602 12:58:55.643690  6142 sgd_solver.cpp:105] Iteration 63100, lr = 1e-05
I0602 12:59:20.212075  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 13:00:40.189429  6142 solver.cpp:218] Iteration 63200 (0.956539 iter/s, 104.544s/100 iters), loss = 0.00241404
I0602 13:00:40.189580  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000221731 (* 1 = 0.000221731 loss)
I0602 13:00:40.189599  6142 sgd_solver.cpp:105] Iteration 63200, lr = 1e-05
I0602 13:02:24.744938  6142 solver.cpp:218] Iteration 63300 (0.956452 iter/s, 104.553s/100 iters), loss = 0.000764306
I0602 13:02:24.745141  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000815091 (* 1 = 0.000815091 loss)
I0602 13:02:24.745160  6142 sgd_solver.cpp:105] Iteration 63300, lr = 1e-05
I0602 13:04:09.342489  6142 solver.cpp:218] Iteration 63400 (0.956068 iter/s, 104.595s/100 iters), loss = 0.000425405
I0602 13:04:09.342640  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000564929 (* 1 = 0.000564929 loss)
I0602 13:04:09.342659  6142 sgd_solver.cpp:105] Iteration 63400, lr = 1e-05
I0602 13:04:46.940284  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 13:05:52.793610  6142 solver.cpp:330] Iteration 63500, Testing net (#0)
I0602 13:05:52.793931  6142 net.cpp:676] Ignoring source layer Softmax
I0602 13:05:53.461655  6142 solver.cpp:397]     Test net output #0: acc = 0.952
I0602 13:05:54.509224  6142 solver.cpp:218] Iteration 63500 (0.950893 iter/s, 105.164s/100 iters), loss = 0.000454002
I0602 13:05:54.509290  6142 solver.cpp:237]     Train net output #0: Softmax = 9.0703e-05 (* 1 = 9.0703e-05 loss)
I0602 13:05:54.509306  6142 sgd_solver.cpp:105] Iteration 63500, lr = 1e-05
I0602 13:07:39.057533  6142 solver.cpp:218] Iteration 63600 (0.956517 iter/s, 104.546s/100 iters), loss = 0.000838296
I0602 13:07:39.057657  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000260225 (* 1 = 0.000260225 loss)
I0602 13:07:39.057675  6142 sgd_solver.cpp:105] Iteration 63600, lr = 1e-05
I0602 13:09:23.613675  6142 solver.cpp:218] Iteration 63700 (0.956446 iter/s, 104.554s/100 iters), loss = 0.000234182
I0602 13:09:23.613852  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000101392 (* 1 = 0.000101392 loss)
I0602 13:09:23.613871  6142 sgd_solver.cpp:105] Iteration 63700, lr = 1e-05
I0602 13:10:14.325620  6151 data_layer.cpp:73] Restarting data prefetching from start.
I0602 13:11:08.193246  6142 solver.cpp:218] Iteration 63800 (0.956232 iter/s, 104.577s/100 iters), loss = 0.000857712
I0602 13:11:08.193411  6142 solver.cpp:237]     Train net output #0: Softmax = 0.00148333 (* 1 = 0.00148333 loss)
I0602 13:11:08.193430  6142 sgd_solver.cpp:105] Iteration 63800, lr = 1e-05
I0602 13:12:52.712735  6142 solver.cpp:218] Iteration 63900 (0.956782 iter/s, 104.517s/100 iters), loss = 0.00158096
I0602 13:12:52.712893  6142 solver.cpp:237]     Train net output #0: Softmax = 0.000146213 (* 1 = 0.000146213 loss)
I0602 13:12:52.712911  6142 sgd_solver.cpp:105] Iteration 63900, lr = 1e-05
I0602 13:14:36.248113  6142 solver.cpp:447] Snapshotting to binary proto file trainedmodels/MnasNet_iter_64000.caffemodel
I0602 13:14:36.417965  6142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file trainedmodels/MnasNet_iter_64000.solverstate
I0602 13:14:36.591378  6142 solver.cpp:310] Iteration 64000, loss = 0.000407378
I0602 13:14:36.591420  6142 solver.cpp:330] Iteration 64000, Testing net (#0)
I0602 13:14:36.591635  6142 net.cpp:676] Ignoring source layer Softmax
I0602 13:14:37.262754  6142 solver.cpp:397]     Test net output #0: acc = 0.94
I0602 13:14:37.262801  6142 solver.cpp:315] Optimization Done.
I0602 13:14:37.262809  6142 caffe.cpp:260] Optimization Done.
